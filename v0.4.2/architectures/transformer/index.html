<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Standard Transformer · GeometricMachineLearning.jl</title><meta name="title" content="Standard Transformer · GeometricMachineLearning.jl"/><meta property="og:title" content="Standard Transformer · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Standard Transformer · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/transformer/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/transformer/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/transformer/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../sympnet/">SympNet</a></li><li><a class="tocitem" href="../volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li class="is-active"><a class="tocitem" href>Standard Transformer</a><ul class="internal"><li><a class="tocitem" href="#Classification-Transformer"><span>Classification Transformer</span></a></li><li><a class="tocitem" href="#The-Upscaling"><span>The Upscaling</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../symplectic_transformer/">Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../../tutorials/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../tutorials/mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../tutorials/matrix_softmax/">Matrix Attention</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/symplectic_transformer/">Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Architectures</a></li><li class="is-active"><a href>Standard Transformer</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Standard Transformer</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/architectures/transformer.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Standard-Transformer"><a class="docs-heading-anchor" href="#Standard-Transformer">Standard Transformer</a><a id="Standard-Transformer-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-Transformer" title="Permalink"></a></h1><p>The transformer is a relatively modern neural network architecture [<a href="../../references/#vaswani2017attention">54</a>] that has come to dominate the field of natural language processing (NLP, [<a href="../../references/#patwardhan2023transformers">87</a>]) and replaced the previously dominant long-short term memory cells (LSTM, [<a href="../../references/#hochreiter1997long">83</a>]). Its success is due to a variety of factors: </p><ul><li>unlike LSTMs it consists of very simple building blocks and hence is easier to interpret mathematically,</li><li>it is very flexible in its application and the data it is fed with do not have to conform to a rigid pattern, </li><li>transformers utilize modern hardware (especially GPUs) very effectively. </li></ul><p>The transformer architecture is sketched below: </p><p><img src="../../tikz/transformer_encoder_light.png" alt="Visualization of the standard transformer. It consists of two components: a mulithead attention layer and a feedforward neural network."/> <img src="../../tikz/transformer_encoder_dark.png" alt="Visualization of the standard transformer. It consists of two components: a mulithead attention layer and a feedforward neural network."/></p><p>It is nothing more than a combination of a <a href="../../layers/multihead_attention_layer/#Multihead-Attention">multihead attention layer</a> and a residual neural network<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> (ResNet).</p><p>As was explained when we talked about the <a href="../../layers/attention_layer/#Reweighting-of-the-Input-Sequence">attention module</a>, the attention layer performs a convex reweighting of the input sequence:</p><p class="math-container">\[\mathrm{Attention}:  Z \equiv [z^{(1)}, \ldots, z^{(T)}]   \mapsto  [\sum_{i=1}^Tp^{(1)}_iz^{(i)}, \ldots, \sum_{i=1}^Tp^{(T)}_iz^{(i)}] = \mathrm{Attention}(Z),\]</p><p>where the coefficients <span>$p^{(i)}$</span> depend on <span>$Z$</span> and are <em>learnable</em>. In the case of <a href="../../layers/multihead_attention_layer/#Multihead-Attention">multihead attention</a> a greater number of these <em>reweighting coefficients</em> are learned, but it is otherwise not much more complicated than single-head attention.</p><p>The green arrow in the figure above indicates that this first <em>add connection</em> can be left out. This can be specified via the keyword argument <code>add_connection</code> in <a href="../../layers/multihead_attention_layer/#GeometricMachineLearning.MultiHeadAttention"><code>MultiHeadAttention</code></a> layer and the <a href="#GeometricMachineLearning.StandardTransformerIntegrator"><code>StandardTransformerIntegrator</code></a>.</p><p>We should also note that such transformers have been used for <a href="../../reduced_order_modeling/reduced_order_modeling/#General-Workflow">the online phase in reduced order modeling</a> before [<a href="../../references/#solera2023beta">85</a>].</p><h2 id="Classification-Transformer"><a class="docs-heading-anchor" href="#Classification-Transformer">Classification Transformer</a><a id="Classification-Transformer-1"></a><a class="docs-heading-anchor-permalink" href="#Classification-Transformer" title="Permalink"></a></h2><p>Instead of using the transformer for integration, it can also be used as a image classifier. In this case it is often referred to as &quot;vision transformer&quot; [<a href="../../references/#dosovitskiy2020image">88</a>]. In this case we append a <a href="../../tutorials/mnist/mnist_tutorial/#GeometricMachineLearning.ClassificationLayer"><code>ClassificationLayer</code></a> to the output of the transformer. This will be used in one of the <a href="../../tutorials/mnist/mnist_tutorial/#MNIST-Tutorial">examples</a>. </p><h2 id="The-Upscaling"><a class="docs-heading-anchor" href="#The-Upscaling">The Upscaling</a><a id="The-Upscaling-1"></a><a class="docs-heading-anchor-permalink" href="#The-Upscaling" title="Permalink"></a></h2><p>When using the transformer one typically also benefits from defining a <code>transformer_dim</code> that is greater than the system dimension and a corresponding <code>upscaling_activation</code> (see the docstring of <a href="#GeometricMachineLearning.StandardTransformerIntegrator"><code>StandardTransformerIntegrator</code></a>).</p><p><img src="../../tikz/transformer_upscaling_light.png" alt="If the transformer dimension is not equal to the system dimension, then we add two more neural network layers. One that maps up to the space whose dimension is the transformer dimension and one that maps down again to the space whose dimension is the system dimension."/> <img src="../../tikz/transformer_upscaling_dark.png" alt="If the transformer dimension is not equal to the system dimension, then we add two more neural network layers. One that maps up to the space whose dimension is the transformer dimension and one that maps down again to the space whose dimension is the system dimension."/></p><p>In the figure above we call </p><p class="math-container">\[    \Psi^\mathrm{up}:\mathbb{R}^{\mathtt{sys\_dim}}\to\mathbb{R}^{\mathtt{transformer\_dim}}\]</p><p>the <em>upscaling layer</em> and </p><p class="math-container">\[    \Psi^\mathrm{down}:\mathbb{R}^{\mathtt{transformer\_dim}}\to\mathbb{R}^{\mathtt{sys\_dim}}\]</p><p>the <em>downscaling layer</em>. Both of these layers are dense layers with the activation function for the downscaling layer being the identity (for better expressivity) and the activation function for the upscaling layer can be specified via the keyword <code>upscaling_activation</code>.</p><p><code>GeometricMachineLearning</code> does not have an implementation of such an upscaling for the <a href="../volume_preserving_transformer/#Volume-Preserving-Transformer">volume-preserving transformer</a> and the <a href="../linear_symplectic_transformer/#Linear-Symplectic-Transformer">linear symplectic transformer</a>. Symplectic liftings have however recently been discussed to learn higher-dimensional Hamiltonian representations of given data [<a href="../../references/#yildiz2024data">72</a>].</p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StandardTransformerIntegrator" href="#GeometricMachineLearning.StandardTransformerIntegrator"><code>GeometricMachineLearning.StandardTransformerIntegrator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">StandardTransformerIntegrator(sys_dim)</code></pre><p>Make an instance of <code>StandardTransformerIntegrator</code> for a specific system dimension.</p><p>Here the standard transformer used as an integrator (see <a href="../neural_network_integrators/#GeometricMachineLearning.TransformerIntegrator"><code>TransformerIntegrator</code></a>). </p><p>It is a composition of <a href="../../layers/multihead_attention_layer/#GeometricMachineLearning.MultiHeadAttention"><code>MultiHeadAttention</code></a> layers and <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a> layers.</p><p><strong>Arguments</strong></p><p>The following are optional keyword arguments:</p><ul><li><code>transformer_dim::Int = sys_dim</code>: this is the dimension <em>after the upscaling</em>.</li><li><code>n_blocks::Int = 1</code> : the number of <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a> blocks.</li><li><code>n_heads::Int = sys_dim</code>: the number of heads in the multihead attention layer.</li><li><code>L::Int = 2</code>: the number of transformer blocks.</li><li><code>upscaling_activation = identity</code>: the activation used in the upscaling layer.</li><li><code>resnet_activation = tanh</code>: the activation used for the <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a>.</li><li><code>attention_activation = GeometricMachineLearning.VectorSoftmax()</code> : the activation used for the <a href="../../layers/multihead_attention_layer/#GeometricMachineLearning.MultiHeadAttention"><code>MultiHeadAttention</code></a> layer.</li><li><code>add_connection:Bool = true</code>: specifies if the input should be added to the output.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/469ed208918b50a7470546e59a8cd4cda5e6cdc3/src/architectures/standard_transformer_integrator.jl#LL8-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Transformer" href="#GeometricMachineLearning.Transformer"><code>GeometricMachineLearning.Transformer</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Transformer(dim, n_heads, L)</code></pre><p>Make an instance of the Transformer with <code>n_heads</code> for dimension <code>dim</code> and <code>L</code> blocks.</p><p><strong>Arguments</strong></p><p><code>Transformer</code> takes the following optional keyword arguments:</p><ul><li><code>activation = tanh</code>: the activation function used for the <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a>.</li><li><code>Stiefel::Bool = false</code>: if the matrices <span>$P^V$</span>, <span>$P^Q$</span> and <span>$P^K$</span> should live on a manifold.</li><li><code>add_connection::Bool = false</code>: if the input should by added to the ouput after the <a href="../../layers/multihead_attention_layer/#GeometricMachineLearning.MultiHeadAttention"><code>MultiHeadAttention</code></a> layer.</li><li><code>use_bias::Bool = true</code>: Specifies if the <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a> should use a bias.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/469ed208918b50a7470546e59a8cd4cda5e6cdc3/src/layers/transformer.jl#LL6-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ClassificationTransformer" href="#GeometricMachineLearning.ClassificationTransformer"><code>GeometricMachineLearning.ClassificationTransformer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ClassificationTransformer(dl)</code></pre><p>Make an instance of the <code>ClassificationTransformer</code> based on an instance of <a href="../../data_loader/data_loader/#GeometricMachineLearning.DataLoader"><code>DataLoader</code></a>.</p><p>This is a transformer neural network for classification purposes. At the moment this is only used for training on MNIST, but can in theory be used for any classification problem.</p><p><strong>Arguments</strong></p><p>The optional keyword arguments are: </p><ul><li><code>n_heads::Int=7</code>: The number of heads in the <code>MultiHeadAttention</code> (mha) layers.</li><li><code>L::Int=16</code>: The number of transformer blocks.</li><li><code>activation=softmax</code>: The activation function.</li><li><code>Stiefel::Bool=true</code>: Whether the matrices in the mha layers are on the <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a>. </li><li><code>add_connection::Bool=true</code>: Whether the input is appended to the output of the mha layer. (skip connection)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/469ed208918b50a7470546e59a8cd4cda5e6cdc3/src/architectures/transformer_neural_network.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_estimate" href="#GeometricMachineLearning.assign_output_estimate"><code>GeometricMachineLearning.assign_output_estimate</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">assign_output_estimate(full_output, prediction_window)</code></pre><p>Crop the output to get the correct number of output vectors.</p><p>The function <code>assign_output_estimate</code> is closely related to the <a href="#GeometricMachineLearning.Transformer"><code>Transformer</code></a>.  It takes the last <code>prediction_window</code> columns of the output and uses them for the prediction.</p><p>i.e.</p><p class="math-container">\[\mathbb{R}^{N\times{}T}\to\mathbb{R}^{N\times\mathtt{pw}}, 
\begin{bmatrix} 
    z^{(1)}_1               &amp; \cdots &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots &amp; \cdots    \\ 
    z^{(1)}_n               &amp; \cdots &amp; z^{(T})_n
    \end{bmatrix} \mapsto 
    \begin{bmatrix} 
    z^{(T - \mathtt{pw})}_1 &amp; \cdots      &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots      &amp; \cdots \\ 
    z^{(T - \mathtt{pw})}_n &amp; \cdots      &amp; z^{(T})_n\end{bmatrix}     \]</p><p>If <code>prediction_window</code> is equal to <code>sequence_length</code>, then this is not needed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/469ed208918b50a7470546e59a8cd4cda5e6cdc3/src/data_loader/tensor_assign.jl#LL35-L58">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[54]</dt><dd><div>A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser and I. Polosukhin. <em>Attention is all you need</em>. Advances in neural information processing systems <strong>30</strong> (2017).</div></dd><dt>[85]</dt><dd><div>A. Solera-Rico, C. S. Vila, M. Gómez, Y. Wang, A. Almashjary, S. Dawson and R. Vinuesa, <em><span>$\beta$</span>-Variational autoencoders and transformers for reduced-order modelling of fluid flows</em>, arXiv preprint arXiv:2304.03571 (2023).</div></dd></dl></div><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>A layer of type <a href="../neural_network_integrators/#GeometricMachineLearning.ResNetLayer">GeometricMachineLearning.ResNetLayer</a> is nothing more than a neural network to whose output we again add the input, i.e. every ResNet is of the form <span>$\mathrm{ResNet}(x) = x + \mathcal{NN}(x)$</span>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../volume_preserving_feedforward/">« Volume-Preserving FeedForward</a><a class="docs-footer-nextpage" href="../volume_preserving_transformer/">Volume-Preserving Transformer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.11.3 on <span class="colophon-date" title="Thursday 15 May 2025 10:29">Thursday 15 May 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
