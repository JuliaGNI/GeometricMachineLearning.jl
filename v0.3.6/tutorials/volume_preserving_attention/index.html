<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Volume-Preserving Attention · GeometricMachineLearning.jl</title><meta name="title" content="Volume-Preserving Attention · GeometricMachineLearning.jl"/><meta property="og:title" content="Volume-Preserving Attention · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Volume-Preserving Attention · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_attention/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_attention/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_attention/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../grassmann_layer/">Grassmann Manifold</a></li><li class="is-active"><a class="tocitem" href>Volume-Preserving Attention</a><ul class="internal"><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li class="toplevel"><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Volume-Preserving Attention</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Volume-Preserving Attention</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/tutorials/volume_preserving_attention.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Comparing-Different-VolumePreservingAttention-Mechanisms"><a class="docs-heading-anchor" href="#Comparing-Different-VolumePreservingAttention-Mechanisms">Comparing Different <code>VolumePreservingAttention</code> Mechanisms</a><a id="Comparing-Different-VolumePreservingAttention-Mechanisms-1"></a><a class="docs-heading-anchor-permalink" href="#Comparing-Different-VolumePreservingAttention-Mechanisms" title="Permalink"></a></h1><p>In the <a href="../../layers/attention_layer/#Volume-Preserving-Attention">section on volume-preserving attention</a> we mentioned two ways of computing volume-preserving attention: one where we compute the correlations with a skew-symmetric matrix and one where we compute the correlations with an arbitrary matrix. Here we compare the two approaches. When calling the <a href="../../layers/attention_layer/#GeometricMachineLearning.VolumePreservingAttention"><code>VolumePreservingAttention</code></a> layer we can specify whether we want to use the skew-symmetric or the arbitrary weighting by setting the keyword <code>skew_sym = true</code> and <code>skew_sym = false</code> respectively. </p><p>In here we demonstrate the differences between the two approaches for computing correlations. For this we first generate a training set consisting of two collections of curves: (i) sine curves and (ii) cosine curve. </p><pre><code class="language-julia hljs">sine_cosine = zeros(1, 1000, 2)
sine_cosine[1, :, 1] .= sin.(0.:.1:99.9)
sine_cosine[1, :, 2] .= cos.(0.:.1:99.9)

const T = Float16
const dl = DataLoader(T.(sine_cosine); suppress_info = true)</code></pre><p>The third axis (i.e. the parameter axis) has length two, meaning we have two different kinds of curves, i.e. the data look like this:</p><object type="image/svg+xml" class="display-light-only" data=../curve_comparison.png></object><object type="image/svg+xml" class="display-dark-only" data=../curve_comparison_dark.png></object><p>We want to train a single neural network on both these curves. We already noted <a href="../../architectures/linear_symplectic_transformer/#Why-use-Transformers-for-Model-Order-Reduction">before</a> that a simple feedforward neural network cannot do this. Here we compare three networks which are of the following form: </p><p class="math-container">\[\mathtt{network} = \mathcal{NN}_d\circ\Psi\circ\mathcal{NN}_u,\]</p><p>where <span>$\mathcal{NN}_u$</span> refers to a neural network that <a href="../../architectures/transformer/#The-Upscaling">scales up</a> and <span>$\mathcal{NN}_d$</span> refers to a neural network that scales down. The up and down scaling is done with simple dense layers: </p><p class="math-container">\[\mathcal{NN}_u(x) = \mathrm{tanh}(a_ux + b_u) \text{ and } \mathcal{NN}_d(x) = a_d^Tx + b_d,\]</p><p>where <span>$a_u, b_u, a_d\in\mathbb{R}^\mathrm{ud}$</span> and <span>$b_d$</span> is a scalar. <code>ud</code> refers to <em>upscaling dimension</em>. For <span>$\Psi$</span> we consider three different choices:</p><ol><li>a volume-preserving attention with skew-symmetric weighting,</li><li>a volume-preserving attention with arbitrary weighting,</li><li>an identity layer.</li></ol><p>We further choose a sequence length 5 (i.e. the network always sees the last 5 time steps) and always predict one step into the future (i.e. the prediction window is set to 1):</p><pre><code class="language-julia hljs">const seq_length = 3
const prediction_window = 1
const upscale_dimension_1 = 2

function set_up_networks(upscale_dimension::Int = upscale_dimension_1)
    model_skew = Chain( Dense(1, upscale_dimension, tanh),
                        VolumePreservingAttention(upscale_dimension, seq_length; skew_sym = true),
                        Dense(upscale_dimension, 1, identity; use_bias = true)
                        )

    model_arb  = Chain( Dense(1, upscale_dimension, tanh),
                        VolumePreservingAttention(upscale_dimension, seq_length; skew_sym = false),
                        Dense(upscale_dimension, 1, identity; use_bias = true)
                        )

    model_comp = Chain( Dense(1, upscale_dimension, tanh),
                        Dense(upscale_dimension, 1, identity; use_bias = true)
                        )

    nn_skew = NeuralNetwork(model_skew, CPU(), T)
    nn_arb  = NeuralNetwork(model_arb,  CPU(), T)
    nn_comp = NeuralNetwork(model_comp, CPU(), T)

    nn_skew, nn_arb, nn_comp
end

nn_skew, nn_arb, nn_comp = set_up_networks()</code></pre><p>We expect the third network to not be able to learn anything useful since it cannot resolve time series data: a regular feedforward network only ever sees one datum at a time. </p><p>Next we train the networks (here we pick a batch size of 30 and train for 1000 epochs):</p><object type="image/svg+xml" class="display-light-only" data=../training_loss_vpa.png></object><object type="image/svg+xml" class="display-dark-only" data=../training_loss_vpa_dark.png></object><p>Looking at the training errors, we can see that the network with the skew-symmetric weighting is stuck at a relatively high error rate, whereas the loss for  the network with the arbitrary weighting is decreasing to a significantly lower level. The feedforward network without the attention mechanism is not able to learn anything useful (as was expected). </p><p>Before we can use the trained neural networks for prediction we have to make them <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.TransformerIntegrator"><code>TransformerIntegrator</code></a>s or <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.NeuralNetworkIntegrator"><code>NeuralNetworkIntegrator</code></a>s<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>:</p><pre><code class="language-julia hljs">initial_condition = dl.input[:, 1:seq_length, 2]

function make_networks_neural_network_integrators(nn_skew, nn_arb, nn_comp)
    nn_skew = NeuralNetwork(GeometricMachineLearning.DummyTransformer(seq_length),
                            nn_skew.model,
                            nn_skew.params,
                            CPU())
    nn_arb  = NeuralNetwork(GeometricMachineLearning.DummyTransformer(seq_length),
                            nn_arb.model,
                            nn_arb.params,
                            CPU())
    nn_comp = NeuralNetwork(GeometricMachineLearning.DummyNNIntegrator(),
                            nn_comp.model,
                            nn_comp.params,
                            CPU())

    nn_skew, nn_arb, nn_comp
end

nn_skew, nn_arb, nn_comp = make_networks_neural_network_integrators(nn_skew, nn_arb, nn_comp)</code></pre><object type="image/svg+xml" class="display-light-only" data=../plot40.png></object><object type="image/svg+xml" class="display-dark-only" data=../plot40_dark.png></object><p>In the plot above we can see that the network with the arbitrary weighting performs much better; even though the red line does not fit the purple line perfectly, it manages to least qualitatively reflect the training data.  We can also plot the predictions for longer time intervals: </p><object type="image/svg+xml" class="display-light-only" data=../plot400.png></object><object type="image/svg+xml" class="display-dark-only" data=../plot400_dark.png></object><p>This advantage of the volume-preserving attention with arbitrary weighting may however be due to the fact that the skew-symmetric attention only has 3 learnable parameters, as opposed to 9 for the arbitrary weighting. We can increase the <em>upscaling dimension</em> and see how it affects the result: </p><pre><code class="language-julia hljs">const upscale_dimension_2 = 10

nn_skew, nn_arb, nn_comp = set_up_networks(upscale_dimension_2)

o_skew, o_arb, o_comp = set_up_optimizers(nn_skew, nn_arb, nn_comp)</code></pre><object type="image/svg+xml" class="display-light-only" data=../training_loss2_vpa.png></object><object type="image/svg+xml" class="display-dark-only" data=../training_loss2_vpa_dark.png></object><pre><code class="language-julia hljs">initial_condition = dl.input[:, 1:seq_length, 2]

nn_skew, nn_arb, nn_comp = make_networks_neural_network_integrators(nn_skew, nn_arb, nn_comp)

fig_dark, fig_light, ax_dark, ax_light = produce_validation_plot(40, nn_skew, nn_arb, nn_comp)</code></pre><object type="image/svg+xml" class="display-light-only" data=../plot40_sine2.png></object><object type="image/svg+xml" class="display-dark-only" data=../plot40_sine2_dark.png></object><p>And for a longer time interval: </p><pre><code class="language-julia hljs">fig_dark, fig_light, ax_dark, ax_light = produce_validation_plot(200, nn_skew, nn_arb, nn_comp)</code></pre><object type="image/svg+xml" class="display-light-only" data=../plot200_sine2.png></object><object type="image/svg+xml" class="display-dark-only" data=../plot200_sine2_dark.png></object><p>Here we see that the arbitrary weighting quickly fails and the skew-symmetric weighting performs better on longer time scales.</p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DummyNNIntegrator" href="#GeometricMachineLearning.DummyNNIntegrator"><code>GeometricMachineLearning.DummyNNIntegrator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DummyNNIntegrator()</code></pre><p>Make an instance of <code>DummyNNIntegrator</code>.</p><p>This <em>dummy architecture</em> can be used if the user wants to define a new <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.NeuralNetworkIntegrator"><code>NeuralNetworkIntegrator</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/523d2b7e994b8b28de33ea11505fabd54569729e/src/architectures/neural_network_integrator.jl#LL120-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DummyTransformer" href="#GeometricMachineLearning.DummyTransformer"><code>GeometricMachineLearning.DummyTransformer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DummyTransformer(seq_length)</code></pre><p>Make an instance of <code>DummyTransformer</code>.</p><p>This <em>dummy architecture</em> can be used if the user wants to define a new <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.TransformerIntegrator"><code>TransformerIntegrator</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/523d2b7e994b8b28de33ea11505fabd54569729e/src/architectures/transformer_integrator.jl#LL15-L21">source</a></section></article><!--<h1 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h1><div class="citation noncanonical"><dl><dt>[7]</dt><dd><div>B. Brantner. <em>Generalizing Adam To Manifolds For Efficiently Training Transformers</em>, arXiv preprint arXiv:2305.16901 (2023).</div></dd><dt>[4]</dt><dd><div>B. Brantner, G. de Romemont, M. Kraus and Z. Li. <em>Volume-Preserving Transformers for Learning Time Series Data with Structure</em>, arXiv preprint arXiv:2312:11166v2 (2024).</div></dd></dl></div>--><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Here we have to use the architectures <a href="#GeometricMachineLearning.DummyTransformer"><code>GeometricMachineLearning.DummyTransformer</code></a> and <a href="#GeometricMachineLearning.DummyNNIntegrator"><code>GeometricMachineLearning.DummyNNIntegrator</code></a> to reformulate the three neural networks defined here as <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.NeuralNetworkIntegrator"><code>NeuralNetworkIntegrator</code></a>s or <a href="../../architectures/neural_network_integrators/#GeometricMachineLearning.TransformerIntegrator"><code>TransformerIntegrator</code></a>s. These <em>dummy architectures</em> can be used if the user wants to specify new neural network integrators that are not yet defined in <code>GeometricMachineLearning</code>. </li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../grassmann_layer/">« Grassmann Manifold</a><a class="docs-footer-nextpage" href="../volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Monday 2 December 2024 15:33">Monday 2 December 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
