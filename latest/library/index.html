<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Library · GeometricMachineLearning.jl</title><meta name="title" content="Library · GeometricMachineLearning.jl"/><meta property="og:title" content="Library · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Library · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../architectures/sympnet/">SympNet</a></li></ul></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../manifolds/inverse_function_theorem/">The Inverse Function Theorem</a></li><li><a class="tocitem" href="../manifolds/submersion_theorem/">The Submersion Theorem</a></li><li><a class="tocitem" href="../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li><li><a class="tocitem" href="../manifolds/stiefel_manifold/">Stiefel</a></li><li><a class="tocitem" href="../manifolds/grassmann_manifold/">Grassmann</a></li><li><a class="tocitem" href="../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li></ul></li><li><span class="tocitem">Arrays</span><ul><li><a class="tocitem" href="../arrays/stiefel_lie_alg_horizontal/">Stiefel Global Tangent Space</a></li><li><a class="tocitem" href="../arrays/grassmann_lie_alg_hor_matrix/">Grassmann Global Tangent Space</a></li></ul></li><li><span class="tocitem">Optimizer Framework</span><ul><li><a class="tocitem" href="../Optimizer/">Optimizers</a></li><li><a class="tocitem" href="../optimizers/general_optimization/">General Optimization</a></li></ul></li><li><span class="tocitem">Optimizer Functions</span><ul><li><a class="tocitem" href="../optimizers/manifold_related/horizontal_lift/">Horizontal Lift</a></li><li><a class="tocitem" href="../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../optimizers/manifold_related/geodesic/">Geodesic Retraction</a></li><li><a class="tocitem" href="../optimizers/manifold_related/cayley/">Cayley Retraction</a></li><li><a class="tocitem" href="../optimizers/adam_optimizer/">Adam Optimizer</a></li><li><a class="tocitem" href="../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../layers/multihead_attention_layer/">Multihead Attention</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../reduced_order_modeling/autoencoder/">POD and Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../tutorials/linear_wave_equation/">Linear Wave Equation</a></li><li><a class="tocitem" href="../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../tutorials/grassmann_layer/">Grassmann manifold</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li class="is-active"><a class="tocitem" href>Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Library</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Library</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/library.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="GeometricMachineLearning-Library-Functions"><a class="docs-heading-anchor" href="#GeometricMachineLearning-Library-Functions">GeometricMachineLearning Library Functions</a><a id="GeometricMachineLearning-Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#GeometricMachineLearning-Library-Functions" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{GSympNet{AT, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{GSympNet{AT, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>Chain</code> can also be called with a neural network as input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL57-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL113-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL95-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL76-L78">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL131-L133">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractCache" href="#GeometricMachineLearning.AbstractCache"><code>GeometricMachineLearning.AbstractCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractCache has subtypes: </p><ul><li>AdamCache</li><li>MomentumCache</li><li>GradientCache</li><li>BFGSCache</li></ul><p>All of them can be initialized with providing an array (also supporting manifold types).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/optimizer_caches.jl#LL1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractLieAlgHorMatrix" href="#GeometricMachineLearning.AbstractLieAlgHorMatrix"><code>GeometricMachineLearning.AbstractLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>AbstractLieAlgHorMatrix</code> is a supertype for various horizontal components of Lie algebras. We usually call this <span>$\mathfrak{g}^\mathrm{hor}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/abstract_lie_algebra_horizontal.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractRetraction" href="#GeometricMachineLearning.AbstractRetraction"><code>GeometricMachineLearning.AbstractRetraction</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractRetraction is a type that comprises all retraction methods for manifolds. For every manifold layer one has to specify a retraction method that takes the layer and elements of the (global) tangent space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/manifold_related/retraction_types.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayer" href="#GeometricMachineLearning.ActivationLayer"><code>GeometricMachineLearning.ActivationLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>ActivationLayer</code> is the <code>struct</code> corresponding to the constructors <code>ActivationLayerQ</code> and <code>ActivationLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL28-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q \\ p + \mathrm{diag}(a)\sigma(q)
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL85-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q + \mathrm{diag}(a)\sigma(p) \\ p
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL68-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamOptimizer" href="#GeometricMachineLearning.AdamOptimizer"><code>GeometricMachineLearning.AdamOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines the Adam Optimizer. Algorithm and suggested defaults are taken from (Goodfellow et al., 2016, page 301), except for δ, because single precision is used!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/adam_optimizer.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Attention" href="#GeometricMachineLearning.Attention"><code>GeometricMachineLearning.Attention</code></a> — <span class="docstring-category">Type</span></header><section><div><p>MultiHeadAttention (MHA) serves as a preprocessing step in the transformer. It reweights the input vectors bases on correlations within those data. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/attention_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSCache" href="#GeometricMachineLearning.BFGSCache"><code>GeometricMachineLearning.BFGSCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The cache for the BFGS optimizer.</p><p>It stores an array for the previous time step <code>B</code> and the inverse of the Hessian matrix <code>H</code>.</p><p>It is important to note that setting up this cache already requires a derivative! This is not the case for the other optimizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/bfgs_cache.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSDummyCache" href="#GeometricMachineLearning.BFGSDummyCache"><code>GeometricMachineLearning.BFGSDummyCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>In order to initialize <code>BGGSCache</code> we first need gradient information. This is why we initially have this <code>BFGSDummyCache</code> until gradient information is available.</p><p>NOTE: we may not need this. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/bfgs_cache.jl#LL17-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSOptimizer" href="#GeometricMachineLearning.BFGSOptimizer"><code>GeometricMachineLearning.BFGSOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is an implementation of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) optimizer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/bfgs_optimizer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Batch" href="#GeometricMachineLearning.Batch"><code>GeometricMachineLearning.Batch</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong><code>Batch</code> constructor</strong></p><p><code>Batch</code> is a struct with an associated functor that acts on an instance of <code>DataLoader</code>. </p><p>The constructor of <code>Batch</code> takes <code>batch_size</code> (an integer) as input argument. Optionally we can provide <code>seq_length</code> if we deal with time series data and want to draw batches of a certain <em>length</em> (i.e. a range contained in the second dimension of the input array).</p><p><strong><code>Batch functor</code></strong></p><p>For a snapshot matrix (or a <code>NamedTuple</code> of the form <code>(q=A, p=B)</code> where <code>A</code> and <code>B</code> are matrices), the functor for <code>Batch</code> is called on an instance of <code>DataLoader</code>. It then returns a tuple of batch indices: </p><ul><li>for <code>autoencoder=true</code>: <span>$(\mathcal{I}_1, \ldots, \mathcal{I}_{\lceil\mathtt{n\_params/batch\_size}\rceil})$</span>, where the index runs from 1 to the number of batches, which is the number of columns in the snapshot matrix divided by the batch size (rounded up).</li><li>for <code>autoencoder=false</code>: <span>$(\mathcal{I}_1, \ldots, \mathcal{I}_{\lceil\mathtt{dl.input\_time\_steps/batch\_size}\rceil})$</span>, where the index runs from 1 to the number of batches, which is the number of columns in the snapshot matrix (minus one) divided by the batch size (rounded up).</li></ul><p>The functor for batch is called with an instance on <code>DataLoader</code>. It then returns a tuple of batch indices: <span>$(\mathcal{I}_1, \ldots, \mathcal{I}_{\lceil\mathtt{dl.n\_params/batch\_size}\rceil})$</span>, where the index runs from 1 to the number of batches, which is the number of parameters divided by the batch size (rounded up).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL17-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BiasLayer" href="#GeometricMachineLearning.BiasLayer"><code>GeometricMachineLearning.BiasLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <em>bias layer</em> that does nothing more than add a vector to the input. This is needed for <em>LA-SympNets</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/bias_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Classification" href="#GeometricMachineLearning.Classification"><code>GeometricMachineLearning.Classification</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Classification Layer that takes a matrix as an input and returns a vector that is used for MNIST classification. </p><p>It has the following arguments: </p><ul><li><code>M</code>: input dimension </li><li><code>N</code>: output dimension </li><li><code>activation</code>: the activation function </li></ul><p>And the following optional argument: </p><ul><li><code>average</code>: If this is set to <code>true</code>, then the output is computed as <span>$\frac{1}{N}\sum_{i=1}^N[input]_{\bullet{}i}$</span>. If set to <code>false</code> (the default) it picks the last column of the input. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/classification.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ClassificationTransformer" href="#GeometricMachineLearning.ClassificationTransformer"><code>GeometricMachineLearning.ClassificationTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a transformer neural network for classification purposes. At the moment this is only used for training on MNIST, but can in theory be used for any classification problem.</p><p>It has to be called with a <code>DataLoader</code> that stores an input and an output tensor. The optional arguments are: </p><ul><li><code>n_heads</code>: The number of heads in the <code>MultiHeadAttention</code> (mha) layers. Default: <code>7</code>.</li><li><code>n_layers</code>: The number of transformer layers. Default: <code>16</code>.</li><li><code>activation</code>: The activation function. Default: <code>softmax</code>.</li><li><code>Stiefel</code>: Wheter the matrices in the mha layers are on the <strong>Stiefel manifold</strong>. </li><li><code>add_connection</code>: Whether the input is appended to the output of the mha layer. (skip connection)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/transformer_neural_network.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader" href="#GeometricMachineLearning.DataLoader"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p>The fields of the struct are the following: </p><ul><li><code>data</code>: The input data with axes (i) system dimension, (ii) number of parameters and (iii) number of time steps.</li><li><code>output</code>: The tensor that contains the output (supervised learning) - this may be of type Nothing if the constructor is only called with one tensor (unsupervised learning).</li><li><code>input_dim</code>: The <em>dimension</em> of the system, i.e. what is taken as input by a regular neural network.</li><li><code>input_time_steps</code>: The length of the entire time series of the data</li><li><code>n_params</code>: The number of parameters that are present in the data set (length of third axis)</li><li><code>output_dim</code>: The dimension of the output tensor (first axis). </li><li><code>output_time_steps</code>: The size of the second axis of the output tensor (also called <code>prediction_window</code>, <code>output_time_steps=1</code> in most cases)</li></ul><p>If for the output we have a tensor whose second axis has length 1, we still store it as a tensor and not a matrix for consistency. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/data_loader.jl#LL16-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p>The fields of the struct are the following: </p><ul><li><code>data</code>: The input data with axes (i) system dimension, (ii) number of parameters and (iii) number of time steps.</li><li><code>output</code>: The tensor that contains the output (supervised learning) - this may be of type Nothing if the constructor is only called with one tensor (unsupervised learning).</li><li><code>input_dim</code>: The <em>dimension</em> of the system, i.e. what is taken as input by a regular neural network.</li><li><code>input_time_steps</code>: The length of the entire time series of the data</li><li><code>n_params</code>: The number of parameters that are present in the data set (length of third axis)</li><li><code>output_dim</code>: The dimension of the output tensor (first axis). </li><li><code>output_time_steps</code>: The size of the second axis of the output tensor (also called <code>prediction_window</code>, <code>output_time_steps=1</code> in most cases)</li></ul><p>If for the output we have a tensor whose second axis has length 1, we still store it as a tensor and not a matrix for consistency. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/data_loader.jl#LL78-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.DataLoader-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The constructor for the data loader, when called on a matrix, also takes an optional argument <code>autoencoder</code>. If set to true than the data loader assumes we are dealing with an <em>autoencoder problem</em> and the field <code>n_params</code> in the <code>DataLoader</code> object will be set to the number of columns of our input matrix.  If <code>autoencoder=false</code>, then the field <code>input_time_steps</code> of the <code>DataLoader</code> object will be set to the <em>number of columns minus 1</em>. This is because in this case the data are used to train a neural network integrator and we need to leave at least one time step after the last one free in order to have something that we can compare the prediction to.  So we have that for an input of form <span>$(z^{(0)}, \ldots, z^{(T)})$</span> <code>input_time_steps</code> is <span>$T$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/data_loader.jl#LL44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GSympNet" href="#GeometricMachineLearning.GSympNet"><code>GeometricMachineLearning.GSympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GSympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>upscaling_dimension::Int</code>: The <em>upscaling dimension</em> of the gradient layer. See the documentation for <code>GradientLayerQ</code> and <code>GradientLayerP</code> for further explanation. The default is <code>2*dim</code>.</li><li><code>nhidden::Int</code>: The number of hidden layers (i.e. layers that are <strong>not</strong> input or output layers). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper::Bool</code>: Initialize the gradient layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL34-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GlobalSection" href="#GeometricMachineLearning.GlobalSection"><code>GeometricMachineLearning.GlobalSection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This implements global sections for the Stiefel manifold and the Symplectic Stiefel manifold. </p><p>In practice this is implemented using Householder reflections, with the auxiliary column vectors given by:  |0| |0| |.| |1| ith spot for i in (n+1) to N (or with random columns) |0| |.| |0|</p><p>Maybe consider dividing the output in the check functions by n!</p><p>Implement a general global section here!!!! Tₓ𝔐 → G×𝔤 !!!!!! (think about random initialization!)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/manifold_related/global_sections.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayer" href="#GeometricMachineLearning.GradientLayer"><code>GeometricMachineLearning.GradientLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GradientLayer</code> is the <code>struct</code> corresponding to the constructors <code>GradientLayerQ</code> and <code>GradientLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL8-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerP-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.GradientLayerP-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.GradientLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \mathbb{O} \\ \nabla{}V &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL53-L63">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerQ-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.GradientLayerQ-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.GradientLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \nabla{}V \\ \mathbb{O} &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL38-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientOptimizer" href="#GeometricMachineLearning.GradientOptimizer"><code>GeometricMachineLearning.GradientOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Define the Gradient optimizer, i.e. W ← W - η*∇f(W) Or the riemannian manifold equivalent, if applicable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/gradient_optimizer.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLayer" href="#GeometricMachineLearning.GrassmannLayer"><code>GeometricMachineLearning.GrassmannLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Grassmann manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/grassmann_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This implements the horizontal component of a Lie algebra that is isomorphic to the Grassmann manifold. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/grassmann_lie_algebra_horizontal.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannManifold" href="#GeometricMachineLearning.GrassmannManifold"><code>GeometricMachineLearning.GrassmannManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>GrassmannManifold</code> is based on the <code>StiefelManifold</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/manifolds/grassmann_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LASympNet" href="#GeometricMachineLearning.LASympNet"><code>GeometricMachineLearning.LASympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LASympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>depth::Int</code>: The number of linear layers that are applied. The default is 5.</li><li><code>nhidden::Int</code>: The number of hidden layers (i.e. layers that are <strong>not</strong> input or output layers). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper_linear::Bool</code>: Initialize the linear layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li><li><code>init_upper_act::Bool</code>: Initialize the activation layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL9-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LayerWithManifold" href="#GeometricMachineLearning.LayerWithManifold"><code>GeometricMachineLearning.LayerWithManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Additional types to make handling manifolds more readable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/manifold_related/retractions.jl#LL9-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayer" href="#GeometricMachineLearning.LinearLayer"><code>GeometricMachineLearning.LinearLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LinearLayer</code> is the <code>struct</code> corresponding to the constructors <code>LinearLayerQ</code> and <code>LinearLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerP-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerP-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; \mathbb{O} \\ 
B &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL117-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerQ-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerQ-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; B \\ 
\mathbb{O} &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL103-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Manifold" href="#GeometricMachineLearning.Manifold"><code>GeometricMachineLearning.Manifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>rand</code> is implemented for manifolds that use the initialization of the <code>StiefelManifold</code> and the <code>GrassmannManifold</code> by default. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/manifolds/abstract_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ManifoldLayer" href="#GeometricMachineLearning.ManifoldLayer"><code>GeometricMachineLearning.ManifoldLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This defines a manifold layer that only has one matrix-valued manifold <span>$A$</span> associated with it does <span>$x\mapsto{}Ax$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/manifold_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MomentumOptimizer" href="#GeometricMachineLearning.MomentumOptimizer"><code>GeometricMachineLearning.MomentumOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Define the Momentum optimizer, i.e.  V ← α<em>V - ∇f(W) W ← W + η</em>V Or the riemannian manifold equivalent, if applicable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/momentum_optimizer.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MultiHeadAttention" href="#GeometricMachineLearning.MultiHeadAttention"><code>GeometricMachineLearning.MultiHeadAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p>MultiHeadAttention (MHA) serves as a preprocessing step in the transformer. It reweights the input vectors bases on correlations within those data. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/multi_head_attention.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer" href="#GeometricMachineLearning.Optimizer"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Optimizer struct that stores the &#39;method&#39; (i.e. Adam with corresponding hyperparameters), the cache and the optimization step.</p><p>It takes as input an optimization method and the parameters of a network. </p><p>For <em>technical reasons</em> we first specify an OptimizerMethod that stores all the hyperparameters of the optimizer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/optimizer.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, Any}" href="#GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, Any}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>A functor for <code>Optimizer</code>. It is called with:     - <code>nn::NeuralNetwork</code>     - <code>dl::DataLoader</code>     - <code>batch::Batch</code>     - <code>n_epochs::Int</code>     - <code>loss</code></p><p>The last argument is a function through which <code>Zygote</code> differentiates. This argument is optional; if it is not supplied <code>GeometricMachineLearning</code> defaults to an appropriate loss for the <code>DataLoader</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL245-L254">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}" href="#GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Typically the Optimizer is not initialized with the network parameters, but instead with a NeuralNetwork struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/optimizer.jl#LL18-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.PSDLayer" href="#GeometricMachineLearning.PSDLayer"><code>GeometricMachineLearning.PSDLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a PSD-like layer used for symplectic autoencoders.  One layer has the following shape:</p><p class="math-container">\[A = \begin{bmatrix} \Phi &amp; \mathbb{O} \\ \mathbb{O} &amp; \Phi \end{bmatrix},\]</p><p>where <span>$\Phi$</span> is an element of the Stiefel manifold <span>$St(n, N)$</span>.</p><p>The constructor of PSDLayer is called by <code>PSDLayer(M, N; retraction=retraction)</code>: </p><ul><li><code>M</code> is the input dimension.</li><li><code>N</code> is the output dimension. </li><li><code>retraction</code> is an instance of a struct with supertype <code>AbstractRetraction</code>. The only options at the moment are <code>Geodesic()</code> and <code>Cayley()</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/psd_like_layer.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ReducedSystem" href="#GeometricMachineLearning.ReducedSystem"><code>GeometricMachineLearning.ReducedSystem</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ReducedSystem computes the reconstructed dynamics in the full system based on the reduced one. Optionally it can be compared to the FOM solution.</p><p>It can be called using the following constructor: ReducedSystem(N, n, encoder, decoder, full<em>vector</em>field, reduced<em>vector</em>field, params, tspan, tstep, ics, projection_error) where </p><ul><li>encoder: a function <span>$\mathbb{R}^{2N}\mapsto{}\mathbb{R}^{2n}$</span></li><li>decoder: a (differentiable) function <span>$\mathbb{R}^{2n}\mapsto\mathbb{R}^{2N}$</span></li><li>full<em>vector</em>field: a (differentiable) mapping defined the same way as in GeometricIntegrators </li><li>reduced<em>vector</em>field: a (differentiable) mapping defined the same way as in GeometricIntegrators </li><li>params: a NamedTuple that parametrizes the vector fields (the same for full<em>vector</em>field and reduced<em>vector</em>field)</li><li>tspan: a tuple (t₀, tₗ) that specifies start and end point of the time interval over which integration is performed. </li><li>tstep: the time step </li><li>ics: the initial condition for the big system.</li><li>projection_error: the error <span>$||M - \mathcal{R}\circ\mathcal{P}(M)||$</span> where <span>$M$</span> is the snapshot matrix; <span>$\mathcal{P}$</span> and <span>$\mathcal{R}$</span> are the reduction and reconstruction respectively.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/reduced_system/reduced_system.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLayer" href="#GeometricMachineLearning.StiefelLayer"><code>GeometricMachineLearning.StiefelLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Stiefel manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/stiefel_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>StiefelLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric). The projection here is: (\pi:S \to SE ) where </p><p class="math-container">\[E = \begin{pmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{pmatrix}.\]</p><p>The matrix (E) is implemented under <code>StiefelProjection</code> in <code>GeometricMachineLearning</code>.</p><p>An element of StiefelLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where (A) is skew-symmetric (this is <code>SkewSymMatrix</code> in <code>GeometricMachineLearning</code>).</p><p>If the constructor is called with a big (N\times{}N) matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\mathrm{skew}(A) &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>The operation <span>$\mathrm{skew}:\mathbb{R}^{n\times{}n}\to\mathcal{S}_\mathrm{skew}(n)$</span> is the skew-symmetrization operation. This is equivalent to calling the constructor of <code>SkewSymMatrix</code> with an (n\times{}n) matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/stiefel_lie_algebra_horizontal.jl#LL1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelManifold" href="#GeometricMachineLearning.StiefelManifold"><code>GeometricMachineLearning.StiefelManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An implementation of the Stiefel manifold. It has various convenience functions associated with it:</p><ul><li>check </li><li>rand </li><li>rgrad</li><li>metric</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/manifolds/stiefel_manifold.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Outer constructor for <code>StiefelProjection</code>. This works with two integers as input and optionally the type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/stiefel_projection.jl#LL39-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An array that essentially does <code>vcat(I(n), zeros(N-n, n))</code> with GPU support. It has <strong>three inner constructors</strong>. The <strong>first one</strong> is called with the following arguments: </p><ol><li><code>backend</code>: backends as supported by <code>KernelAbstractions</code>.</li><li><code>T::Type</code></li><li><code>N::Integer</code></li><li><code>n::Integer</code></li></ol><p>The <strong>second constructor</strong> is called by supplying a matrix as input. The constructor will then extract the backend, the type and the dimensions of that matrix. </p><p>The <strong>third constructor</strong> is called by supplying an instance of <code>StiefelLieAlgHorMatrix</code>.  </p><p>Technically this should be a subtype of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/stiefel_projection.jl#LL1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymmetricMatrix" href="#GeometricMachineLearning.SymmetricMatrix"><code>GeometricMachineLearning.SymmetricMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <code>SymmetricMatrix</code> <span>$A$</span> is a matrix <span>$A^T = A$</span>.</p><p>If the constructor is called with a matrix as input it returns a symmetric matrix via the projection:</p><p class="math-container">\[A \mapsto \frac{1}{2}(A + A^T).\]</p><p>This is a projection defined via the canonical metric <span>$(A,B) \mapsto \mathrm{tr}(A^TB)$</span>.</p><p>Internally the <code>struct</code> saves a vector <span>$S$</span> of size <span>$n(n+1)\div2$</span>. The conversion is done the following way: </p><p class="math-container">\[[A]_{ij} = \begin{cases} S[( (i-1) i ) \div 2 + j] &amp; \text{if $i\geq{}j$}\\ 
                         S[( (j-1) j ) \div 2 + i] &amp; \text{else}. \end{cases}\]</p><p>So <span>$S$</span> stores a string of vectors taken from <span>$A$</span>: <span>$S = [\tilde{a}_1, \tilde{a}_2, \ldots, \tilde{a}_n]$</span> with <span>$\tilde{a}_i = [[A]_{i1},[A]_{i2},\ldots,[A]_{ii}]$</span>.</p><p>TODO: </p><ul><li>[x] Overload Adjoint operation for SymmetricMatrix!! (Aᵀ = A)</li><li>[ ] implement matrix and vector products (to also work on GPU)</li><li>[x] implement zero initialization (for optimizer)</li><li>[ ] perform some tests (also with Zygote)</li><li>[x] update the constructor (to work better for GPU)</li><li>[ ] implement multiplication with a tensor</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/symmetric.jl#LL1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNet" href="#GeometricMachineLearning.SympNet"><code>GeometricMachineLearning.SympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p>SympNet type encompasses GSympNets and LASympnets.</p><p>TODO:  -[ ] add bias to <code>LASympNet</code>!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer" href="#GeometricMachineLearning.SympNetLayer"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Implements the various layers from the SympNet paper: (https://www.sciencedirect.com/science/article/abs/pii/S0893608020303063). This is a super type of <code>Gradient</code>, <code>Activation</code> and <code>Linear</code>.</p><p>For the linear layer, the activation and the bias are left out, and for the activation layer <span>$K$</span> and <span>$b$</span> are left out!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, Any}" href="#GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, Any}"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This is called when a SympnetLayer is applied to a <code>NamedTuple</code>. It calls <code>apply_layer_to_nt_and_return_array</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL247-L249">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SystemType" href="#GeometricMachineLearning.SystemType"><code>GeometricMachineLearning.SystemType</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Can specify a special type of the system, to be used with ReducedSystem. For now the only option is Symplectic (and NoStructure).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/reduced_system/system_type.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TrainingData" href="#GeometricMachineLearning.TrainingData"><code>GeometricMachineLearning.TrainingData</code></a> — <span class="docstring-category">Type</span></header><section><div><p>TrainingData stores: </p><pre><code class="nohighlight hljs"> - problem 

 - shape 

 - get 

 - symbols 

 - dim 

 - noisemaker</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data/data_training.jl#LL4-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, AT} where AT&lt;:(AbstractArray{T}))}" href="#AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, AT} where AT&lt;:(AbstractArray{T}))}"><code>AbstractNeuralNetworks.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for an entire neural networks with BFGS. What is different in this case is that we still have to initialize the cache.</p><p>If <code>o.step == 1</code>, then we initialize the cache</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/bfgs_optimizer.jl#LL13-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.vec-Tuple{SkewSymMatrix}" href="#Base.vec-Tuple{SkewSymMatrix}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>If <code>vec</code> is applied onto <code>SkewSymMatrix</code>, then the output is the associated vector.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/skew_symmetric.jl#LL184-L186">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ChainRules._adjoint_mat_pullback-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Any}} where T" href="#ChainRules._adjoint_mat_pullback-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Any}} where T"><code>ChainRules._adjoint_mat_pullback</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This has to be extended to tensors; you should probably do a PR in ChainRules for this.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/multi_head_attention.jl#LL128-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Gradient" href="#GeometricMachineLearning.Gradient"><code>GeometricMachineLearning.Gradient</code></a> — <span class="docstring-category">Function</span></header><section><div><p>This is an old constructor and will be depricated. For <code>change_q=true</code> it is equivalent to <code>GradientLayerQ</code>; for <code>change_q=false</code> it is equivalent to <code>GradientLayerP</code>.</p><p>If <code>full_grad=false</code> then <code>ActivationLayer</code> is called</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL131-L135">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Iterate_Sympnet-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:SympNet}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractVector{T}}" href="#GeometricMachineLearning.Iterate_Sympnet-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:SympNet}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractVector{T}}"><code>GeometricMachineLearning.Iterate_Sympnet</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function computes a trajectory for a SympNet that has already been trained for valuation purposes.</p><p>It takes as input: </p><ul><li><code>nn</code>: a <code>NeuralNetwork</code> (that has been trained).</li><li><code>ics</code>: initial conditions (a <code>NamedTuple</code> of two vectors)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/architectures/sympnet.jl#LL149-L155">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymplecticPotential" href="#GeometricMachineLearning.SymplecticPotential"><code>GeometricMachineLearning.SymplecticPotential</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>SymplecticPotential(n)</code></p><p>Returns a symplectic matrix of size 2n x 2n</p><p class="math-container">\[\begin{pmatrix}
\mathbb{O} &amp; \mathbb{I} \\
\mathbb{O} &amp; -\mathbb{I} \\
\end{pmatrix}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/symplectic.jl#LL2-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.Transformer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The architecture for a &quot;transformer encoder&quot; is essentially taken from arXiv:2010.11929, but with the difference that <strong>no</strong> layer normalization is employed. This is because we still need to find a generalization of layer normalization to manifolds. </p><p>The transformer is called with the following inputs: </p><ul><li><code>dim</code>: the dimension of the transformer </li><li><code>n_heads</code>: the number of heads </li><li><code>L</code>: the number of <strong>transformer blocks</strong></li></ul><p>In addition we have the following optional arguments: </p><ul><li><code>activation</code>: the activation function used for the <code>ResNet</code> (<code>tanh</code> by default)</li><li><code>Stiefel::Bool</code>: if the matrices <span>$P^V$</span>, <span>$P^Q$</span> and <span>$P^K$</span> should live on a manifold (<code>false</code> by default)</li><li><code>retraction</code>: which retraction should be used (<code>Geodesic()</code> by default)</li><li><code>add_connection::Bool</code>: if the input should by added to the ouput after the <code>MultiHeadAttention</code> layer is used (<code>true</code> by default)</li><li><code>use_bias::Bool</code>: If the <code>ResNet</code> should use a bias (<code>true</code> by default)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/transformer.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}" href="#GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}"><code>GeometricMachineLearning.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the accuracy (as opposed to the loss) of a neural network classifier. </p><p>It takes as input:</p><ul><li><code>model::Chain</code>:</li><li><code>ps</code>: parameters of the network</li><li><code>dl::DataLoader</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/data_loader.jl#LL100-L107">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_layer_to_nt_and_return_array-Union{Tuple{M}, Tuple{AbstractArray, GeometricMachineLearning.SympNetLayer{M, M}, Any}} where M" href="#GeometricMachineLearning.apply_layer_to_nt_and_return_array-Union{Tuple{M}, Tuple{AbstractArray, GeometricMachineLearning.SympNetLayer{M, M}, Any}} where M"><code>GeometricMachineLearning.apply_layer_to_nt_and_return_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function is used in the wrappers where the input to the SympNet layers is not a <code>NamedTuple</code> (as it should be) but an <code>AbstractArray</code>.</p><p>It converts the Array to a <code>NamedTuple</code> (via <code>assign_q_and_p</code>), then calls the SympNet routine(s) and converts back to an <code>AbstractArray</code> (with <code>vcat</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL235-L239">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_batch_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input a <em>batch tensor</em> (to which the data are assigned), the whole data tensor and two vectors <em>params</em> and <em>time_steps</em> that include the specific parameters and time steps we want to assign. </p><p>Note that this assigns sequential data! For e.g. being processed by a transformer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/tensor_assign.jl#LL9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T" href="#GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T"><code>GeometricMachineLearning.assign_output_estimate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The function <code>assign_output_estimate</code> is closely related to the transformer. It takes the last <code>prediction_window</code> columns of the output and uses them for the final prediction. i.e.</p><p class="math-container">\[\mathbb{R}^{N\times\mathtt{pw}}\to\mathbb{R}^{N\times\mathtt{pw}}, 
\begin{bmatrix} 
    z^{(1)}_1               &amp; \cdots &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots &amp; \cdots    \\ 
    z^{(1)}_n               &amp; \cdots &amp; z^{(T})_n
    \end{bmatrix} \mapsto 
    \begin{bmatrix} 
    z^{(T - \mathtt{pw})}_1 &amp; \cdots      &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots      &amp; \cdots \\ 
    z^{(T - \mathtt{pw})}_n &amp; \cdots      &amp; z^{(T})_n\end{bmatrix}     \]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/tensor_assign.jl#LL37-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_output_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_output_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This should be used together with <code>assign_batch_kernel!</code>. It assigns the corresponding output (i.e. target).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/tensor_assign.jl#LL21-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}" href="#GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}"><code>GeometricMachineLearning.assign_q_and_p</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Allocates two new arrays <code>q</code> and <code>p</code> whose first dimension is half of that of the input <code>x</code>. This should also be supplied through the second argument <code>N</code>.</p><p>The output is a <code>Tuple</code> containing <code>q</code> and <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/kernels/assign_q_and_p.jl#LL35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}" href="#GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}"><code>GeometricMachineLearning.augment_zeros_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Used for differentiating assign<em>output</em>estimate (this appears in the loss). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/tensor_assign.jl#LL62-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.batch_over_one_axis-Tuple{Batch, Int64}" href="#GeometricMachineLearning.batch_over_one_axis-Tuple{Batch, Int64}"><code>GeometricMachineLearning.batch_over_one_axis</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function is called when either dealing with a matrix or a tensor where we always consider the entire time series. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL38-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}" href="#GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}"><code>GeometricMachineLearning.compute_output_of_mha</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Applies MHA to an abstract matrix. This is the same independent of whether the input is added to the output or not. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/multi_head_attention.jl#LL78-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array (NamedTuples). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL147-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL175-L177">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}" href="#GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}"><code>GeometricMachineLearning.custom_mat_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Multiplies a matrix with a vector, a matrix or a tensor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/sympnets.jl#LL185-L187">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.draw_batch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the batch if the data are in form of a matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/matrix_assign.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}" href="#GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}"><code>GeometricMachineLearning.init_optimizer_cache</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Wrapper for the functions <code>setup_adam_cache</code>, <code>setup_momentum_cache</code>, <code>setup_gradient_cache</code>, <code>setup_bfgs_cache</code>. These appear outside of <code>optimizer_caches.jl</code> because the <code>OptimizerMethods</code> first have to be defined.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/init_optimizer_cache.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.initialize_hessian_inverse</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This initializes the inverse of the Hessian for various arrays. This requires an implementation of a <em>vectorization operation</em> <code>vec</code>. This is important for custom arrays.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/bfgs_cache.jl#LL33-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.loss-Tuple{NeuralNetwork, Vararg{Any}}" href="#GeometricMachineLearning.loss-Tuple{NeuralNetwork, Vararg{Any}}"><code>GeometricMachineLearning.loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Wrapper if we deal with a neural network.</p><p>You can supply an instance of <code>NeuralNetwork</code> instead of the two arguments model (of type <code>Union{Chain, AbstractExplicitLayer}</code>) and parameters (of type <code>Union{Tuple, NamedTuple}</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/loss/loss_routines.jl#LL72-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, AT, BT}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}" href="#GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, AT, BT}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}"><code>GeometricMachineLearning.loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the loss for a neural network and a data set.  The computed loss is </p><p class="math-container">\[||output - \mathcal{NN}(input)||_F/||output||_F,\]</p><p>where <span>$||A||_F := \sqrt{\sum_{i_1,\ldots,i_k}|a_{i_1,\ldots,i_k}^2}|^2$</span> is the Frobenius norm.</p><p>It takes as input: </p><ul><li><code>model::Union{Chain, AbstractExplicitLayer}</code></li><li><code>ps::Union{Tuple, NamedTuple}</code></li><li><code>input::Union{Array, NamedTuple}</code></li><li><code>output::Uniont{Array, NamedTuple}</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/loss/loss_routines.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, DataLoader{T, AT, BT}}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}" href="#GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, DataLoader{T, AT, BT}}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}"><code>GeometricMachineLearning.loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Alternative call of the loss function. This takes as input: </p><ul><li><code>model</code></li><li><code>ps</code></li><li><code>dl::DataLoader</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/loss/loss_routines.jl#LL50-L55">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, BT}} where {T, BT&lt;:(AbstractArray{T})}" href="#GeometricMachineLearning.loss-Union{Tuple{BT}, Tuple{T}, Tuple{Union{AbstractNeuralNetworks.AbstractExplicitLayer, Chain}, Union{Tuple, NamedTuple}, BT}} where {T, BT&lt;:(AbstractArray{T})}"><code>GeometricMachineLearning.loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The <em>autoencoder loss</em>:</p><p class="math-container">\[||output - \mathcal{NN}(input)||_F/||output||_F.\]</p><p>It takes as input: </p><ul><li><code>model::Union{Chain, AbstractExplicitLayer}</code></li><li><code>ps::Union{Tuple, NamedTuple}</code></li><li><code>input::Union{Array, NamedTuple}</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/loss/loss_routines.jl#LL20-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}" href="#GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}"><code>GeometricMachineLearning.map_index_for_symplectic_potential</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the right index for the symplectic potential. To be used with <code>assign_ones_for_symplectic_potential_kernel!</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/arrays/symplectic.jl#LL34-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by the adjoint of an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/multi_head_attention.jl#LL135-L137">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/layers/multi_head_attention.jl#LL142-L144">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}" href="#GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Implements the canonical Riemannian metric for the Stiefel manifold:</p><p class="math-container">\[g_Y: (\Delta_1, \Delta_2) \mapsto \mathrm{tr}(\Delta_1^T(\mathbb{I} - \frac{1}{2}YY^T)\Delta_2).\]</p><p>It is called with: </p><ul><li><code>Y::StiefelManifold</code></li><li><code>Δ₁::AbstractMatrix</code></li><li><code>Δ₂::AbstractMatrix</code>`</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/manifolds/stiefel_manifold.jl#LL37-L46">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.number_of_batches-Union{Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT}, Batch}} where {T, BT&lt;:AbstractMatrix{T}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}}" href="#GeometricMachineLearning.number_of_batches-Union{Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT}, Batch}} where {T, BT&lt;:AbstractMatrix{T}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}}"><code>GeometricMachineLearning.number_of_batches</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Gives the number of bathces. Inputs are of type <code>DataLoader</code> and <code>Batch</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL72-L74">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer" href="#GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer"><code>GeometricMachineLearning.onehotbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><p>One-hot-batch encoding of a vector of integers: <span>$input\in\{0,1,\ldots,9\}^\ell$</span>.  The output is a tensor of shape <span>$10\times1\times\ell$</span>. </p><p class="math-container">\[0 \mapsto \begin{bmatrix} 1 &amp; 0 &amp; \ldots &amp; 0 \end{bmatrix}.\]</p><p>In more abstract terms: <span>$i \mapsto e_i$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/mnist_utils.jl#LL6-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Chain, Tuple, Tuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Chain, Tuple, Tuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for an entire neural networks, the way this function should be called. </p><p>inputs: </p><ul><li><code>o::Optimizer</code></li><li><code>model::Chain</code></li><li><code>ps::Tuple</code></li><li><code>dx::Tuple</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/optimizer.jl#LL51-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Union{AbstractNeuralNetworks.AbstractExplicitCell, AbstractNeuralNetworks.AbstractExplicitLayer}, NamedTuple, NamedTuple, NamedTuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Union{AbstractNeuralNetworks.AbstractExplicitCell, AbstractNeuralNetworks.AbstractExplicitLayer}, NamedTuple, NamedTuple, NamedTuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for a single layer. </p><p>inputs: </p><ul><li><code>o::Optimizer</code></li><li><code>d::Union{AbstractExplicitLayer, AbstractExplicitCell}</code></li><li><code>ps::NamedTuple</code>: the parameters </li><li><code>C::NamedTuple</code>: NamedTuple of the caches </li><li><code>dx::NamedTuple</code>: NamedTuple of the derivatives (output of AD routine)</li></ul><p><code>ps</code>, <code>C</code> and <code>dx</code> must have the same keys. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/optimizers/optimizer.jl#LL30-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{AT}, Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT}, Batch, Any}} where {T, AT&lt;:NamedTuple}" href="#GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{AT}, Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT}, Batch, Any}} where {T, AT&lt;:NamedTuple}"><code>GeometricMachineLearning.optimize_for_one_epoch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This routine is called if a <code>DataLoader</code> storing <em>symplectic data</em> (i.e. a <code>NamedTuple</code>) is supplied.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL225-L227">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT, BT}, Batch, Any}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}" href="#GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT, BT}, Batch, Any}} where {T, T1, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T1, 3}}"><code>GeometricMachineLearning.optimize_for_one_epoch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimize for an entire epoch. For this you have to supply: </p><ul><li>an instance of the optimizer.</li><li>the neural network model </li><li>the parameters of the model </li><li>the data (in form of <code>DataLoader</code>)</li><li>in instance of <code>Batch</code> that contains <code>batch_size</code> (and optionally <code>seq_length</code>)</li></ul><p>With the optional argument:</p><ul><li>the loss, which takes the <code>model</code>, the parameters <code>ps</code> and an instance of <code>DataLoader</code> as input.</li></ul><p>The output of <code>optimize_for_one_epoch!</code> is the average loss over all batches of the epoch:</p><p class="math-container">\[output = \frac{1}{\mathtt{steps\_per\_epoch}}\sum_{t=1}^\mathtt{steps\_per\_epoch}loss(\theta^{(t-1)}).\]</p><p>This is done because any <strong>reverse differentiation</strong> routine always has two outputs: a pullback and the value of the function it is differentiating. In the case of zygote: <code>loss_value, pullback = Zygote.pullback(ps -&gt; loss(ps), ps)</code> (if the loss only depends on the parameters).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/batch.jl#LL87-L103">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer" href="#GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer"><code>GeometricMachineLearning.patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the batch index (for MNIST data set for now).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/mnist_utils.jl#LL22-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.reduced_vector_field_from_full_explicit_vector_field-Tuple{Any, Any, Integer, Integer}" href="#GeometricMachineLearning.reduced_vector_field_from_full_explicit_vector_field-Tuple{Any, Any, Integer, Integer}"><code>GeometricMachineLearning.reduced_vector_field_from_full_explicit_vector_field</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function is needed if we obtain a GeometricIntegrators-like vector field from an explicit vector field <span>$V:\mathbb{R}^{2N}\to\mathbb{R}^{2N}$</span>.  We need this function because build<em>reduced</em>vector_field is not working in conjunction with implicit integrators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/reduced_system/reduced_system.jl#LL48-L51">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}" href="#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the Riemannian gradient for the Stiefel manifold given an element <span>$Y\in{}St(N,n)$</span> and a matrix <span>$\nabla{}L\in\mathbb{R}^{N\times{}n}$</span> (the Euclidean gradient). It computes the Riemannian gradient with respect to the canonical metric (see the documentation for the function <code>metric</code> for an explanation of this). The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - Y(\nabla{}L)^TY\]</p><p>It is called with inputs:</p><ul><li><code>Y::StiefelManifold</code></li><li><code>e_grad::AbstractMatrix</code>: i.e. the Euclidean gradient (what was called <span>$\nabla{}L$</span>) above.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/manifolds/stiefel_manifold.jl#LL23-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T" href="#GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T"><code>GeometricMachineLearning.split_and_flatten</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>split_and_flatten</code> takes a tensor as input and produces another one as output (essentially rearranges the input data in an intricate way) so that it can easily be processed with a transformer.</p><p>The optional arguments are: </p><ul><li><code>patch_length</code>: by default this is 7. </li><li><code>number_of_patches</code>: by default this is 16.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/mnist_utils.jl#LL51-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!" href="#GeometricMachineLearning.train!"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train!(...)</code></pre><p>Perform a training of a neural networks on data using given method a training Method</p><p>Different ways of use:</p><pre><code class="nohighlight hljs">train!(neuralnetwork, data, optimizer = GradientOptimizer(1e-2), training_method; nruns = 1000, batch_size = default(data, type), showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data</code> : the data (see <a href="#GeometricMachineLearning.TrainingData"><code>TrainingData</code></a>)</li><li><code>optimizer = GradientOptimizer</code>: the optimization method (see <a href="../Optimizer/#Optimizer"><code>Optimizer</code></a>)</li><li><code>training_method</code> : specify the loss function used </li><li><code>nruns</code> : number of iteration through the process with default value </li><li><code>batch_size</code> : size of batch of data used for each step</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/training/train.jl#LL16-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}" href="#GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(neuralnetwork, data, optimizer, training_method; nruns = 1000, batch_size, showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data::AbstractTrainingData</code> : the data</li><li>``</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/training/train.jl#LL84-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer" href="#GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer"><code>GeometricMachineLearning.within_patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the index within the batch</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/data_loader/mnist_utils.jl#LL31-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.write_ones_kernel!-Tuple{Any}" href="#GeometricMachineLearning.write_ones_kernel!-Tuple{Any}"><code>GeometricMachineLearning.write_ones_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Kernel that is needed for functions relating to <code>SymmetricMatrix</code> and <code>SkewSymMatrix</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/2bd1a46e91bac7058b66376c8fc8b93a8239f74e/src/utils.jl#LL66-L68">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../references/">« References</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Tuesday 9 April 2024 12:18">Tuesday 9 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
