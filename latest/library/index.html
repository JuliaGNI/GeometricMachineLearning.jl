<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Library · GeometricMachineLearning.jl</title><meta name="title" content="Library · GeometricMachineLearning.jl"/><meta property="og:title" content="Library · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Library · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Optimizers</span><ul><li><a class="tocitem" href="../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../layers/sympnet_gradient/">Sympnet Gradient Layers</a></li><li><a class="tocitem" href="../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../reduced_order_modeling/autoencoder/">POD and Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../tutorials/grassmann_layer/">Grassmann manifold</a></li><li><a class="tocitem" href="../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li class="is-active"><a class="tocitem" href>Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Library</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Library</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/library.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="GeometricMachineLearning-Library-Functions"><a class="docs-heading-anchor" href="#GeometricMachineLearning-Library-Functions">GeometricMachineLearning Library Functions</a><a id="GeometricMachineLearning-Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#GeometricMachineLearning-Library-Functions" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Tuple{GSympNet}" href="#AbstractNeuralNetworks.Chain-Tuple{GSympNet}"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>Chain</code> can also be called with a neural network as input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL55-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL110-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL92-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL73-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL128-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.Matrix-Tuple{GlobalSection}" href="#Base.Matrix-Tuple{GlobalSection}"><code>Base.Matrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Matrix(λY::GlobalSection)</code></pre><p>Put <code>λY</code> into matrix form. </p><p>This is not recommended if speed is important!</p><p>Use <a href="#GeometricMachineLearning.apply_section-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>apply_section</code></a> and <a href="../arrays/global_tangent_spaces/#GeometricMachineLearning.global_rep-arrays-global_tangent_spaces"><code>global_rep</code></a> instead!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL37-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractCache" href="#GeometricMachineLearning.AbstractCache"><code>GeometricMachineLearning.AbstractCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractCache has subtypes:</p><ul><li><a href="#GeometricMachineLearning.AdamCache"><code>AdamCache</code></a></li><li><a href="#GeometricMachineLearning.MomentumCache"><code>MomentumCache</code></a></li><li><a href="#GeometricMachineLearning.GradientCache"><code>GradientCache</code></a></li><li><a href="#GeometricMachineLearning.BFGSCache"><code>BFGSCache</code></a></li></ul><p>All of them can be initialized with providing an array (also supporting manifold types).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_caches.jl#LL1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractLieAlgHorMatrix" href="#GeometricMachineLearning.AbstractLieAlgHorMatrix"><code>GeometricMachineLearning.AbstractLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>AbstractLieAlgHorMatrix</code> is a supertype for various horizontal components of Lie algebras. We usually call this <span>$\mathfrak{g}^\mathrm{hor}$</span>.</p><p>See <a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a> and <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/abstract_lie_algebra_horizontal.jl#LL1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractRetraction" href="#GeometricMachineLearning.AbstractRetraction"><code>GeometricMachineLearning.AbstractRetraction</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractRetraction is a type that comprises all retraction methods for manifolds. For every manifold layer one has to specify a retraction method that takes the layer and elements of the (global) tangent space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retraction_types.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractTriangular" href="#GeometricMachineLearning.AbstractTriangular"><code>GeometricMachineLearning.AbstractTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><p>See <a href="#GeometricMachineLearning.UpperTriangular"><code>UpperTriangular</code></a> and <a href="#GeometricMachineLearning.LowerTriangular"><code>LowerTriangular</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/triangular.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayer" href="#GeometricMachineLearning.ActivationLayer"><code>GeometricMachineLearning.ActivationLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>ActivationLayer</code> is the <code>struct</code> corresponding to the constructors <code>ActivationLayerQ</code> and <code>ActivationLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL51-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q \\ p + \mathrm{diag}(a)\sigma(q)
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL86-L98">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q + \mathrm{diag}(a)\sigma(p) \\ p
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL69-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamCache" href="#GeometricMachineLearning.AdamCache"><code>GeometricMachineLearning.AdamCache</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdamCache(Y)</code></pre><p>Store the first and second moment for <code>Y</code> (initialized as zeros).</p><p>First and second moments are called <code>B₁</code> and <code>B₂</code>.</p><p>If the cache is called with an instance of a homogeneous space, e.g. the <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> <span>$St(n,N)$</span> it initializes the moments as elements of <span>$\mathfrak{g}^\mathrm{hor}$</span> (<a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a>).</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = rand(StiefelManifold, 5, 3)
AdamCache(Y).B₁

# output

5×5 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, Matrix{Float64}}:
 0.0  -0.0  -0.0  -0.0  -0.0
 0.0   0.0  -0.0  -0.0  -0.0
 0.0   0.0   0.0  -0.0  -0.0
 0.0   0.0   0.0   0.0   0.0
 0.0   0.0   0.0   0.0   0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_caches.jl#LL15-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamOptimizer" href="#GeometricMachineLearning.AdamOptimizer"><code>GeometricMachineLearning.AdamOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdamOptimizer(η, ρ₁, ρ₂, δ)</code></pre><p>Make an instance of the Adam Optimizer.</p><p>Here the cache consists of first and second moments that are updated as </p><p class="math-container">\[B_1 \gets ((\rho_1 - \rho_1^t)/(1 - \rho_1^t))\cdot{}B_1 + (1 - \rho_1)/(1 - \rho_1^t)\cdot{}\nabla{}L,\]</p><p>and</p><p class="math-container">\[B_2 \gets ((\rho_2 - \rho_1^t)/(1 - \rho_2^t))\cdot{}B_2 + (1 - \rho_2)/(1 - \rho_2^t)\cdot\nabla{}L\odot\nabla{}L.\]</p><p>The final velocity is computed as:</p><p class="math-container">\[\mathrm{velocity} \gets -\eta{}B_1/\sqrt{B_2 + \delta}.\]</p><p><strong>Implementation</strong></p><p>The <em>velocity</em> is stored in the input to save memory.</p><p>Algorithm and suggested defaults are taken from [<a href="../references/#goodfellow2016deep">20</a>, page 301].</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/adam_optimizer.jl#LL1-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamOptimizerWithDecay" href="#GeometricMachineLearning.AdamOptimizerWithDecay"><code>GeometricMachineLearning.AdamOptimizerWithDecay</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AdamOptimizerWithDecay(n_epochs, η₁=1f-2, η₂=1f-6, ρ₁=9f-1, ρ₂=9.9f-1, δ=1f-8)</code></pre><p>Make an instance of the Adam Optimizer with weight decay.</p><p>All except the first argument (the number of epochs) have defaults.</p><p>The difference to the standard <a href="#GeometricMachineLearning.AdamOptimizer"><code>AdamOptimizer</code></a> is that we change the learning reate <span>$\eta$</span> in each step. Apart from the <em>time dependency</em> of <span>$\eta$</span> the two algorithms are however equivalent! <span>$\eta(0)$</span> starts with a high value <span>$\eta_1$</span> and then exponentially decrease until it reaches <span>$\eta_2$</span> with</p><p class="math-container">\[ \eta(t) = \gamma^t\eta_1,\]</p><p>where <span>$\gamma = \exp(\log(\eta_1 / \eta_2) / \mathtt{n\_epochs}).$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/adam_optimizer_with_learning_rate_decay.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AutoEncoder" href="#GeometricMachineLearning.AutoEncoder"><code>GeometricMachineLearning.AutoEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The autoencoder architecture</strong></p><p>An autoencoder [<a href="../references/#goodfellow2016deep">20</a>] is a neural network consisting of an encoder <span>$\Psi^e$</span> and a decoder <span>$\Psi^d$</span>. In the simplest case they are trained on some data set <span>$\mathcal{D}$</span> to reduce the following error: </p><p class="math-container">\[||\Psi^d\circ\Psi^e(\mathcal{D}) - \mathcal{D}||,\]</p><p>which we call the <em>reconstruction error</em> or <em>autoencoder error</em> (see the docs for <a href="#GeometricMachineLearning.AutoEncoderLoss">AutoEncoderLoss</a>) and <span>$||\cdot||$</span> is some norm.</p><p><strong>Implementation details.</strong></p><p>Abstract <code>AutoEncoder</code> type. If a custom <code>&lt;:AutoEncoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code>, <code>n_encoder_blocks</code> and <code>n_decoder_blocks</code>. Further the routines <code>encoder</code>, <code>decoder</code>, <code>encoder_parameters</code> and <code>decoder_parameters</code> should be extended.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AutoEncoderLoss" href="#GeometricMachineLearning.AutoEncoderLoss"><code>GeometricMachineLearning.AutoEncoderLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This loss should always be used together with a neural network of type <a href="#GeometricMachineLearning.AutoEncoder">AutoEncoder</a> (and it is also the default for training such a network). </p><p>It simply computes: </p><p class="math-container">\[\mathtt{AutoEncoderLoss}(nn\mathtt{::Loss}, input) = ||nn(input) - input||.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/loss/losses.jl#LL83-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSCache" href="#GeometricMachineLearning.BFGSCache"><code>GeometricMachineLearning.BFGSCache</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BFGSCache(B)</code></pre><p>Make the cache for the BFGS optimizer based on the array <code>B</code>.</p><p>It stores an array for the gradient of the previous time step <code>B</code> and the inverse of the Hessian matrix <code>H</code>.</p><p>The cache for the inverse of the Hessian is initialized with the idendity. The cache for the previous gradient information is initialized with the zero vector.</p><p>Note that the cache for <code>H</code> is changed iteratively, whereas the cache for <code>B</code> is newly assigned at every time step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/bfgs_cache.jl#LL1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSOptimizer" href="#GeometricMachineLearning.BFGSOptimizer"><code>GeometricMachineLearning.BFGSOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BFGSOptimizer(η, δ)</code></pre><p>Make an instance of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) optimizer. </p><p><code>η</code> is the <em>learning rate</em>. <code>δ</code> is a stabilization parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/bfgs_optimizer.jl#LL1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Batch" href="#GeometricMachineLearning.Batch"><code>GeometricMachineLearning.Batch</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>Batch</code> is a struct whose functor acts on an instance of <code>DataLoader</code> to produce a sequence of training samples for training for one epoch. </p><p><strong>The Constructor</strong></p><p>The constructor for <code>Batch</code> is called with: </p><ul><li><code>batch_size::Int</code></li><li><code>seq_length::Int</code> (optional)</li><li><code>prediction_window::Int</code> (optional)</li></ul><p>The first one of these arguments is required; it indicates the number of training samples in a batch. If we deal with time series data then we can additionaly supply a <em>sequence length</em> and a <em>prediction window</em> as input arguments to <code>Batch</code>. These indicate the number of input vectors and the number of output vectors.</p><p><strong>The functor</strong></p><p>An instance of <code>Batch</code> can be called on an instance of <code>DataLoader</code> to produce a sequence of samples that contain all the input data, i.e. for training for one epoch. The output of applying <code>batch:Batch</code> to <code>dl::DataLoader</code> is a tuple of vectors of integers. Each of these vectors contains two integers: the first is the <em>time index</em> and the second one is the <em>parameter index</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/batch.jl#LL18-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BiasLayer" href="#GeometricMachineLearning.BiasLayer"><code>GeometricMachineLearning.BiasLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <em>bias layer</em> that does nothing more than add a vector to the input. This is needed for <em>LA-SympNets</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/bias_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Classification" href="#GeometricMachineLearning.Classification"><code>GeometricMachineLearning.Classification</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Classification Layer that takes a matrix as an input and returns a vector that is used for MNIST classification. </p><p>It has the following arguments: </p><ul><li><code>M</code>: input dimension </li><li><code>N</code>: output dimension </li><li><code>activation</code>: the activation function </li></ul><p>And the following optional argument: </p><ul><li><code>average</code>: If this is set to <code>true</code>, then the output is computed as <span>$\frac{1}{N}\sum_{i=1}^N[input]_{\bullet{}i}$</span>. If set to <code>false</code> (the default) it picks the last column of the input. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/classification.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ClassificationTransformer" href="#GeometricMachineLearning.ClassificationTransformer"><code>GeometricMachineLearning.ClassificationTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a transformer neural network for classification purposes. At the moment this is only used for training on MNIST, but can in theory be used for any classification problem.</p><p>It has to be called with a <code>DataLoader</code> that stores an input and an output tensor. The optional arguments are: </p><ul><li><code>n_heads</code>: The number of heads in the <code>MultiHeadAttention</code> (mha) layers. Default: <code>7</code>.</li><li><code>n_layers</code>: The number of transformer layers. Default: <code>16</code>.</li><li><code>activation</code>: The activation function. Default: <code>softmax</code>.</li><li><code>Stiefel</code>: Wheter the matrices in the mha layers are on the <strong>Stiefel manifold</strong>. </li><li><code>add_connection</code>: Whether the input is appended to the output of the mha layer. (skip connection)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/transformer_neural_network.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader" href="#GeometricMachineLearning.DataLoader"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p><strong>Constructor</strong></p><p>The data loader can be called with various inputs:</p><ul><li><strong>A single vector</strong>: If the data loader is called with a single vector (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the second axis indicates parameter values and/or time steps and the system has a single degree of freedom (i.e. the system dimension is one).</li><li><strong>A single matrix</strong>: If the data loader is called with a single matrix (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the first axis is assumed to indicate the degrees of freedom of the system and the second axis indicates parameter values and/or time steps. </li><li><strong>A single tensor</strong>: If the data loader is called with a single tensor, then this is interpreted as an <em>integration problem</em> with the second axis indicating the time step and the third one indicating the parameters.</li><li><strong>A tensor and a vector</strong>: This is a special case (MNIST classification problem). For the MNIST problem for example the input are <span>$n_p$</span> matrices (first input argument) and <span>$n_p$</span> integers (second input argument).</li><li><strong>A <code>NamedTuple</code> with fields <code>q</code> and <code>p</code></strong>: The <code>NamedTuple</code> contains (i) two matrices or (ii) two tensors. </li><li><strong>An <code>EnsembleSolution</code></strong>: The <code>EnsembleSolution</code> typically comes from <code>GeometricProblems</code>.</li></ul><p>When we supply a single vector or a single matrix as input to <code>DataLoader</code> and further set <code>autoencoder = false</code> (keyword argument), then the data are stored as an <em>integration problem</em> and the second axis is assumed to indicate time steps.</p><p><strong>Fields of <code>DataLoader</code></strong></p><p>The fields of the <code>DataLoader</code> struct are the following: </p><ul><li><code>input</code>: The input data with axes (i) system dimension, (ii) number of time steps and (iii) number of parameters.</li><li><code>output</code>: The tensor that contains the output (supervised learning) - this may be of type <code>Nothing</code> if the constructor is only called with one tensor (unsupervised learning).</li><li><code>input_dim</code>: The <em>dimension</em> of the system, i.e. what is taken as input by a regular neural network.</li><li><code>input_time_steps</code>: The length of the entire time series (length of the second axis).</li><li><code>n_params</code>: The number of parameters that are present in the data set (length of third axis)</li><li><code>output_dim</code>: The dimension of the output tensor (first axis). If <code>output</code> is of type <code>Nothing</code>, then this is also of type <code>Nothing</code>.</li><li><code>output_time_steps</code>: The size of the second axis of the output tensor. If <code>output</code> is of type <code>Nothing</code>, then this is also of type <code>Nothing</code>.</li></ul><p><strong>The <code>input</code> and <code>output</code> fields of <code>DataLoader</code></strong></p><p>Even though the arguments to the Constructor may be vectors or matrices, internally <code>DataLoader</code> always stores tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/data_loader.jl#LL17-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p><strong>Constructor</strong></p><p>The data loader can be called with various inputs:</p><ul><li><strong>A single vector</strong>: If the data loader is called with a single vector (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the second axis indicates parameter values and/or time steps and the system has a single degree of freedom (i.e. the system dimension is one).</li><li><strong>A single matrix</strong>: If the data loader is called with a single matrix (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the first axis is assumed to indicate the degrees of freedom of the system and the second axis indicates parameter values and/or time steps. </li><li><strong>A single tensor</strong>: If the data loader is called with a single tensor, then this is interpreted as an <em>integration problem</em> with the second axis indicating the time step and the third one indicating the parameters.</li><li><strong>A tensor and a vector</strong>: This is a special case (MNIST classification problem). For the MNIST problem for example the input are <span>$n_p$</span> matrices (first input argument) and <span>$n_p$</span> integers (second input argument).</li><li><strong>A <code>NamedTuple</code> with fields <code>q</code> and <code>p</code></strong>: The <code>NamedTuple</code> contains (i) two matrices or (ii) two tensors. </li><li><strong>An <code>EnsembleSolution</code></strong>: The <code>EnsembleSolution</code> typically comes from <code>GeometricProblems</code>.</li></ul><p>When we supply a single vector or a single matrix as input to <code>DataLoader</code> and further set <code>autoencoder = false</code> (keyword argument), then the data are stored as an <em>integration problem</em> and the second axis is assumed to indicate time steps.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/data_loader.jl#LL86-L100">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT, ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT}})}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT, ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT}})}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Constructor for <code>EnsembleSolution</code> from package <code>GeometricSolutions</code> with field <code>q</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/data_loader.jl#LL130-L132">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT&lt;:(GeometricSolutions.DataSeries{T, AT} where AT&lt;:Union{AbstractArray{T}, T}), ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT, p::DT}})}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT&lt;:(GeometricSolutions.DataSeries{T, AT} where AT&lt;:Union{AbstractArray{T}, T}), ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT, p::DT}})}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Constructor for <code>EnsembleSolution</code> form package <code>GeometricSolutions</code> with fields <code>q</code> and <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/data_loader.jl#LL148-L150">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Decoder" href="#GeometricMachineLearning.Decoder"><code>GeometricMachineLearning.Decoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract <code>Decoder</code> type. If a custom <code>&lt;:Decoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_decoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL23-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Encoder" href="#GeometricMachineLearning.Encoder"><code>GeometricMachineLearning.Encoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract <code>Encoder</code> type. If a custom <code>&lt;:Encoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_encoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL18-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.FeedForwardLoss" href="#GeometricMachineLearning.FeedForwardLoss"><code>GeometricMachineLearning.FeedForwardLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FeedForwardLoss()</code></pre><p>Make an instance of a loss for feedforward neural networks.</p><p>This doesn&#39;t have any parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/loss/losses.jl#LL74-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GSympNet" href="#GeometricMachineLearning.GSympNet"><code>GeometricMachineLearning.GSympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GSympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>upscaling_dimension::Int</code>: The <em>upscaling dimension</em> of the gradient layer. See the documentation for <code>GradientLayerQ</code> and <code>GradientLayerP</code> for further explanation. The default is <code>2*dim</code>.</li><li><code>n_layers::Int</code>: The number of layers (i.e. the total number of <a href="#GeometricMachineLearning.GradientLayerQ"><code>GradientLayerQ</code></a> and <a href="#GeometricMachineLearning.GradientLayerP"><code>GradientLayerP</code></a>). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper::Bool</code>: Initialize the gradient layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL31-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GlobalSection" href="#GeometricMachineLearning.GlobalSection"><code>GeometricMachineLearning.GlobalSection</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalSection(Y::AbstractMatrix)</code></pre><p>Construct a global section for <code>Y</code>.  </p><p>A global section <span>$\lambda$</span> is a mapping from a homogeneous space <span>$\mathcal{M}$</span> to the corresponding Lie group <span>$G$</span> such that </p><p class="math-container">\[\lambda(Y)E = Y,\]</p><p>Also see <a href="#GeometricMachineLearning.apply_section-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>apply_section</code></a> and <a href="../arrays/global_tangent_spaces/#GeometricMachineLearning.global_rep-arrays-global_tangent_spaces"><code>global_rep</code></a>.</p><p><strong>Implementation</strong></p><p>For an implementation of <code>GlobalSection</code> for a custom array (especially manifolds), the function <a href="../arrays/global_tangent_spaces/#GeometricMachineLearning.global_section-arrays-global_tangent_spaces"><code>global_section</code></a> has to be generalized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientCache" href="#GeometricMachineLearning.GradientCache"><code>GeometricMachineLearning.GradientCache</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GradientCache(Y)</code></pre><p>Do not store anything.</p><p>The cache for the <a href="#GeometricMachineLearning.GradientOptimizer"><code>GradientOptimizer</code></a> does not consider past information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_caches.jl#LL81-L87">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayer" href="#GeometricMachineLearning.GradientLayer"><code>GeometricMachineLearning.GradientLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GradientLayer</code> is the <code>struct</code> corresponding to the constructors <a href="#GeometricMachineLearning.GradientLayerQ"><code>GradientLayerQ</code></a> and <a href="#GeometricMachineLearning.GradientLayerP"><code>GradientLayerP</code></a>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL8-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerP" href="#GeometricMachineLearning.GradientLayerP"><code>GeometricMachineLearning.GradientLayerP</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \mathbb{O} \\ \nabla{}V &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL29-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerQ" href="#GeometricMachineLearning.GradientLayerQ"><code>GeometricMachineLearning.GradientLayerQ</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \nabla{}V \\ \mathbb{O} &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL16-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientOptimizer" href="#GeometricMachineLearning.GradientOptimizer"><code>GeometricMachineLearning.GradientOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GradientOptimizer(η)</code></pre><p>Make an instance of a gradient optimizer. </p><p>This is the simplest neural network optimizer. It has no cache and computes the final velocity as:</p><p class="math-container">\[    \mathrm{velocity} \gets - \eta\nabla_\mathrm{weight}L.\]</p><p><strong>Implementation</strong></p><p>The operations are done as memory efficiently as possible. This means the provided <span>$\nabla_WL$</span> is mutated via:</p><pre><code class="language-julia hljs">    rmul!(∇L, -method.η)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/gradient_optimizer.jl#LL1-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLayer" href="#GeometricMachineLearning.GrassmannLayer"><code>GeometricMachineLearning.GrassmannLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Grassmann manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/grassmann_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GrassmannLieAlgHorMatrix(B::AbstractMatrix{T}, N::Integer, n::Integer) where T</code></pre><p>Build an instance of <code>GrassmannLieAlgHorMatrix</code> based on an arbitrary matrix <code>B</code> of size <span>$(N-n)\times{}n$</span>.</p><p><code>GrassmannLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric). The projection here is: <span>$\pi:S \to SE/\sim$</span> where </p><p class="math-container">\[E = \begin{pmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{pmatrix},\]</p><p>and the equivalence relation is </p><p class="math-container">\[V_1 \sim V_2 \iff \exists A\in\mathcal{S}_\mathrm{skew}(n) \text{such that } V_2 = V_1 + \begin{pmatrix} A \\ \mathbb{O} \end{pmatrix}\]</p><p>An element of GrassmannLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
\bar{\mathbb{O}} &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where <span>$\bar{\mathbb{O}}\in\mathbb{R}^{n\times{}n}$</span> and <span>$\mathbb{O}\in\mathbb{R}^{(N - n)\times{}n}.$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/grassmann_lie_algebra_horizontal.jl#LL1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GrassmannLieAlgHorMatrix(D::AbstractMatrix, n::Integer)</code></pre><p>Take a big matrix as input and build an instance of <code>GrassmannLieAlgHorMatrix</code> belonging to the GrassmannManifold <span>$Gr(n, N)$</span> where <span>$N$</span> is the number of rows of <code>D</code>.</p><p>If the constructor is called with a big <span>$N\times{}N$</span> matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\bar{\mathbb{O}} &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>This can also be seen as the operation:</p><p class="math-container">\[D \mapsto \Omega(E, DE - EE^TDE),\]</p><p>where <span>$\Omega$</span> is the horizontal lift <a href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/grassmann_lie_algebra_horizontal.jl#LL40-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannManifold" href="#GeometricMachineLearning.GrassmannManifold"><code>GeometricMachineLearning.GrassmannManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>GrassmannManifold</code> is based on the <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/grassmann_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.HRedSys" href="#GeometricMachineLearning.HRedSys"><code>GeometricMachineLearning.HRedSys</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>HRedSys</code> computes the reconstructed dynamics in the full system based on the reduced one. Optionally it can be compared to the FOM solution.</p><p>It can be called using the following constructor: <code>HRedSys(N, n; encoder, decoder, v_full, f_full, v_reduced, f_reduced, parameters, tspan, tstep, ics, projection_error)</code> where </p><ul><li><code>encoder</code>: a function <span>$\mathbb{R}^{2N}\mapsto{}\mathbb{R}^{2n}$</span></li><li><code>decoder</code>: a (differentiable) function <span>$\mathbb{R}^{2n}\mapsto\mathbb{R}^{2N}$</span></li><li><code>v_full</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>f_full</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>v_reduced</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>f_reduced</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>parameters</code>: a NamedTuple that parametrizes the vector fields (the same for full<em>vector</em>field and reduced<em>vector</em>field)</li><li><code>tspan</code>: a tuple <code>(t₀, tₗ)</code> that specifies start and end point of the time interval over which integration is performed. </li><li><code>tstep</code>: the time step </li><li><code>ics</code>: the initial condition for the big system.</li><li><code>projection_error</code>: the error <span>$||M - \mathcal{R}\circ\mathcal{P}(M)||$</span> where <span>$M$</span> is the snapshot matrix; <span>$\mathcal{P}$ and $\mathcal{R}$</span> are the reduction and reconstruction respectively.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/reduced_system/reduced_system.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LASympNet" href="#GeometricMachineLearning.LASympNet"><code>GeometricMachineLearning.LASympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LASympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>depth::Int</code>: The number of linear layers that are applied. The default is 5.</li><li><code>nhidden::Int</code>: The number of hidden layers (i.e. layers that are <strong>not</strong> input or output layers). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper_linear::Bool</code>: Initialize the linear layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li><li><code>init_upper_act::Bool</code>: Initialize the activation layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL6-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LayerWithManifold" href="#GeometricMachineLearning.LayerWithManifold"><code>GeometricMachineLearning.LayerWithManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LayerWithManifold</code> is a subtype of <code>AbstractExplicitLayer</code> that contains manifolds as weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LayerWithOptionalManifold" href="#GeometricMachineLearning.LayerWithOptionalManifold"><code>GeometricMachineLearning.LayerWithOptionalManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LayerWithOptionalManifold</code> is a subtype of <code>AbstractExplicitLayer</code> that can contain manifolds as weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL6-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayer" href="#GeometricMachineLearning.LinearLayer"><code>GeometricMachineLearning.LinearLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LinearLayer</code> is the <code>struct</code> corresponding to the constructors <code>LinearLayerQ</code> and <code>LinearLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL42-L44">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerP-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerP-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; \mathbb{O} \\ 
B &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL118-L127">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerQ-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerQ-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; B \\ 
\mathbb{O} &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL104-L113">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearSymplecticAttention" href="#GeometricMachineLearning.LinearSymplecticAttention"><code>GeometricMachineLearning.LinearSymplecticAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Implements the linear symplectic attention layers. Analogous to <a href="#GeometricMachineLearning.GradientLayer"><code>GradientLayer</code></a> it performs mappings that only change the <span>$Q$</span> or the <span>$P$</span> part. For more information see <a href="#GeometricMachineLearning.LinearSymplecticAttentionQ"><code>LinearSymplecticAttentionQ</code></a> and <a href="#GeometricMachineLearning.LinearSymplecticAttentionP"><code>LinearSymplecticAttentionP</code></a>.</p><p><strong>Constructor</strong></p><p>For the constructors simply call </p><pre><code class="language-julia hljs">LinearSymplecticAttentionQ(sys_dim, seq_length)</code></pre><p>or </p><pre><code class="language-julia hljs">LinearSymplecticAttentionP(sys_dim, seq_length)</code></pre><p>where <code>sys_dim</code> is the system dimension and <code>seq_length</code> is the sequence length.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/linear_symplectic_attention.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearSymplecticAttentionP" href="#GeometricMachineLearning.LinearSymplecticAttentionP"><code>GeometricMachineLearning.LinearSymplecticAttentionP</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Performs: </p><p class="math-container">\[\begin{pmatrix} Q \\ P \end{pmatrix} \mapsto \begin{pmatrix} Q + \nabla_PF \\ P \end{pmatrix},\]</p><p>where <span>$Q,\, P\in\mathbb{R}^{n\times{}T}$</span> and <span>$F(P) = \frac{1}{2}\mathrm{Tr}(P A P^T)$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/linear_symplectic_attention.jl#LL32-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearSymplecticAttentionQ" href="#GeometricMachineLearning.LinearSymplecticAttentionQ"><code>GeometricMachineLearning.LinearSymplecticAttentionQ</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Performs: </p><p class="math-container">\[\begin{pmatrix} Q \\ P \end{pmatrix} \mapsto \begin{pmatrix} Q + \nabla_PF \\ P \end{pmatrix},\]</p><p>where <span>$Q,\, P\in\mathbb{R}^{n\times{}T}$</span> and <span>$F(P) = \frac{1}{2}\mathrm{Tr}(P A P^T)$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/linear_symplectic_attention.jl#LL22-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearSymplecticTransformer" href="#GeometricMachineLearning.LinearSymplecticTransformer"><code>GeometricMachineLearning.LinearSymplecticTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Realizes the linear Symplectic Transformer.</p><p><strong>Constructor:</strong></p><p>The constructor is called with the following arguments</p><ol><li><code>dim::Int</code>: System dimension </li><li><code>seq_length::Int</code>: Number of time steps that the transformer considers. </li></ol><p>Optional keyword arguments:</p><ul><li><code>n_sympnet::Int=2</code>: The number of sympnet layers in the transformer.</li><li><code>upscaling_dimension::Int=2*dim</code>: The upscaling that is done by the gradient layer. </li><li><code>L::Int=1</code>: The number of transformer units. </li><li><code>activation=tanh</code>: The activation function for the SympNet layers. </li><li><code>init_upper::Bool=true</code>: Specifies if the first layer is a <span>$Q$</span>-type layer (<code>init_upper=true</code>) or if it is a <span>$P$</span>-type layer (<code>init_upper=false</code>).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/linear_symplectic_transformer.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LowerTriangular" href="#GeometricMachineLearning.LowerTriangular"><code>GeometricMachineLearning.LowerTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LowerTriangular(S::AbstractVector, n::Int)</code></pre><p>Build a lower-triangular matrix from a vector.</p><p>A lower-triangular matrix is an <span>$n\times{}n$</span> matrix that has ones on the diagonal and zeros on the upper triangular.</p><p>The data are stored in a vector <span>$S$</span> similarly to other matrices. See <a href="#GeometricMachineLearning.UpperTriangular"><code>UpperTriangular</code></a>, <a href="#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> and <a href="#GeometricMachineLearning.SymmetricMatrix"><code>SymmetricMatrix</code></a>.</p><p>The struct two fields: <code>S</code> and <code>n</code>. The first stores all the entries of the matrix in a sparse fashion (in a vector) and the second is the dimension <span>$n$</span> for <span>$A\in\mathbb{R}^{n\times{}n}$</span>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
S = [1, 2, 3, 4, 5, 6]
LowerTriangular(S, 4)

# output

4×4 LowerTriangular{Int64, Vector{Int64}}:
 0  0  0  0
 1  0  0  0
 2  3  0  0
 4  5  6  0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/lower_triangular.jl#LL1-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LowerTriangular-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.LowerTriangular-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.LowerTriangular</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">LowerTriangular(A::AbstractMatrix)</code></pre><p>Build a lower-triangular matrix from a matrix.</p><p>This is done by taking the lower left of that matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
M = [1 2 3 4; 5 6 7 8; 9 10 11 12; 13 14 15 16]
LowerTriangular(M)

# output

4×4 LowerTriangular{Int64, Vector{Int64}}:
  0   0   0  0
  5   0   0  0
  9  10   0  0
 13  14  15  0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/lower_triangular.jl#LL32-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Manifold" href="#GeometricMachineLearning.Manifold"><code>GeometricMachineLearning.Manifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A manifold in <code>GeometricMachineLearning</code> is a sutype of <code>AbstractMatrix</code>. All manifolds are matrix manifolds and therefore stored as matrices. More details can be found in the docstrings for the <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> and the <a href="#GeometricMachineLearning.GrassmannManifold"><code>GrassmannManifold</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/abstract_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ManifoldLayer" href="#GeometricMachineLearning.ManifoldLayer"><code>GeometricMachineLearning.ManifoldLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This defines a manifold layer that only has one matrix-valued manifold <span>$A$</span> associated with it does <span>$x\mapsto{}Ax$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/manifold_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MomentumCache" href="#GeometricMachineLearning.MomentumCache"><code>GeometricMachineLearning.MomentumCache</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MomentumCache(Y)</code></pre><p>Store the moment for <code>Y</code> (initialized as zeros).</p><p>The moment is called <code>B</code>.</p><p>If the cache is called with an instance of a homogeneous space, e.g. the <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> <span>$St(n,N)$</span> it initializes the moments as elements of <span>$\mathfrak{g}^\mathrm{hor}$</span> (<a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a>).</p><p>See <a href="#GeometricMachineLearning.AdamCache"><code>AdamCache</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_caches.jl#LL58-L68">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MomentumOptimizer" href="#GeometricMachineLearning.MomentumOptimizer"><code>GeometricMachineLearning.MomentumOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MomentumOptimizer(η, α)</code></pre><p>Make an instance of the momentum optimizer.</p><p>The momentum optimizer is similar to the <a href="#GeometricMachineLearning.GradientOptimizer"><code>GradientOptimizer</code></a>. It however has a nontrivial cache that stores past history (see <a href="#GeometricMachineLearning.MomentumCache"><code>MomentumCache</code></a>). The cache is updated via:</p><p class="math-container">\[    B^{\mathrm{cache}} \gets \alpha{}B^{\mathrm{cache}} + \nabla_\mathrm{weights}L\]</p><p>and then the final velocity is computed as</p><p class="math-container">\[    \mathrm{velocity} \gets  - \eta{}B^{\mathrm{cache}}.\]</p><p>Or the riemannian manifold equivalent, if applicable.</p><p><strong>Implementation</strong></p><p>To save memory the <em>velocity</em> is stored in the input <span>$\nabla_WL$</span>. This is similar to the case of the <a href="#GeometricMachineLearning.GradientOptimizer"><code>GradientOptimizer</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/momentum_optimizer.jl#LL1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MultiHeadAttention" href="#GeometricMachineLearning.MultiHeadAttention"><code>GeometricMachineLearning.MultiHeadAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p>MultiHeadAttention (MHA) serves as a preprocessing step in the transformer. It reweights the input vectors bases on correlations within those data. </p><p><strong>Constructor</strong></p><p>Takes input arguments: </p><ul><li><code>dim::Int</code>: The system dimension </li><li><code>n_heads::Int</code>: The number of heads. </li><li><code>Stiefel::Bool=true</code> (keyword argument): whether the weights should be put on the Stiefel manifold. </li><li><code>retraction::AbstractRetraction</code> (keyword argument): what kind of retraction should be used. By default this is the geodesic retraction. </li><li><code>add_connection::Bool=true</code> (keyword argument): determines if the input should be added to the output for the final result. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/multi_head_attention.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.NetworkLoss" href="#GeometricMachineLearning.NetworkLoss"><code>GeometricMachineLearning.NetworkLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An abstract type for all the neural network losses.  If you want to implement <code>CustomLoss &lt;: NetworkLoss</code> you need to define a functor:</p><pre><code class="language-julia hljs">    (loss::CustomLoss)(model, ps, input, output)</code></pre><p>where <code>model</code> is an instance of an <code>AbstractExplicitLayer</code> or a <code>Chain</code> and <code>ps</code> the parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/loss/losses.jl#LL1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.NeuralNetworkIntegrator" href="#GeometricMachineLearning.NeuralNetworkIntegrator"><code>GeometricMachineLearning.NeuralNetworkIntegrator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a super type of various neural network architectures such as <a href="#GeometricMachineLearning.SympNet"><code>SympNet</code></a> and <a href="#GeometricMachineLearning.ResNet"><code>ResNet</code></a> whose purpose is to approximate the flow of an ordinary differential equation (ODE).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/neural_network_integrator.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer" href="#GeometricMachineLearning.Optimizer"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Optimizer(method, cache, step, retraction)</code></pre><p>Store the <code>method</code> (e.g. <a href="#GeometricMachineLearning.AdamOptimizer"><code>AdamOptimizer</code></a> with corresponding hyperparameters), the <code>cache</code> (e.g. <a href="#GeometricMachineLearning.AdamCache"><code>AdamCache</code></a>), the optimization step and the retraction.</p><p>It takes as input an optimization method and the parameters of a network. </p><p>For <em>technical reasons</em> we first specify an <a href="#GeometricMachineLearning.OptimizerMethod"><code>OptimizerMethod</code></a> that stores all the hyperparameters of the optimizer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, GeometricMachineLearning.NetworkLoss}" href="#GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, GeometricMachineLearning.NetworkLoss}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>A functor for <code>Optimizer</code>. It is called with:     - <code>nn::NeuralNetwork</code>     - <code>dl::DataLoader</code>     - <code>batch::Batch</code>     - <code>n_epochs::Int</code>     - <code>loss</code></p><p>The last argument is a function through which <code>Zygote</code> differentiates. This argument is optional; if it is not supplied <code>GeometricMachineLearning</code> defaults to an appropriate loss for the <code>DataLoader</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/optimize.jl#LL38-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}" href="#GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Optimizer(method, nn::NeuralNetwork)</code></pre><p>Allocate the cache for a specific <code>method</code> and a <code>NeuralNetwork</code> for an instance of <code>Optimizer</code>.</p><p>Internally this calls <code>Optimizer(method, nn.params)</code>.</p><p>Typically the Optimizer is not initialized with the network parameters, but instead with a NeuralNetwork struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL32-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, Union{Tuple, NamedTuple}}" href="#GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, Union{Tuple, NamedTuple}}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Optimizer(method, nn_params)</code></pre><p>Allocate the cache for a specific <code>method</code> and <code>nn_params</code> for an instance of <code>Optimizer</code>.</p><p>Internally this calls <a href="#GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}"><code>init_optimizer_cache</code></a>.</p><p><strong>Arguments</strong></p><p>The optional keyword argument is the retraction. By default this is <a href="#GeometricMachineLearning.cayley-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>cayley</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL17-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.OptimizerMethod" href="#GeometricMachineLearning.OptimizerMethod"><code>GeometricMachineLearning.OptimizerMethod</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Each <code>Optimizer</code> has to be called with an <code>OptimizerMethod</code>. This specifies how the neural network weights are updated in each optimization step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_method.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.PSDArch" href="#GeometricMachineLearning.PSDArch"><code>GeometricMachineLearning.PSDArch</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The architecture</strong></p><p>Proper symplectic decomposition (PSD) can be seen as a <a href="#GeometricMachineLearning.SymplecticAutoencoder">SymplecticAutoencoder</a> for which the decoder and the encoder are both PSD-like matrices (see the docs for <a href="#GeometricMachineLearning.PSDLayer">PSDLayer</a>. </p><p><strong>Training</strong></p><p>For optimizing the parameters in this architecture no neural network training is necessary (see the docs for <a href="#GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}">solve!</a>).</p><p><strong>The constructor</strong></p><p>The constructor only takes two arguments as input:</p><ul><li><code>full_dim::Integer</code></li><li><code>reduced_dim::Integer</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/psd.jl#LL1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.PSDLayer" href="#GeometricMachineLearning.PSDLayer"><code>GeometricMachineLearning.PSDLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a PSD-like layer used for symplectic autoencoders.  One layer has the following shape:</p><p class="math-container">\[A = \begin{bmatrix} \Phi &amp; \mathbb{O} \\ \mathbb{O} &amp; \Phi \end{bmatrix},\]</p><p>where <span>$\Phi$</span> is an element of the Stiefel manifold <span>$St(n, N)$</span>.</p><p>The constructor of PSDLayer is called by <code>PSDLayer(M, N; retraction=retraction)</code>: </p><ul><li><code>M</code> is the input dimension.</li><li><code>N</code> is the output dimension. </li><li><code>retraction</code> is an instance of a struct with supertype <code>AbstractRetraction</code>. The only options at the moment are <code>Geodesic()</code> and <code>Cayley()</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/psd_like_layer.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ResNet" href="#GeometricMachineLearning.ResNet"><code>GeometricMachineLearning.ResNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A ResNet is a neural network that realizes a mapping of the form: <span>$x = \mathcal{NN}(x) + x$</span>, so the input is again added to the output (a so-called add connection). In <code>GeometricMachineLearning</code> the specific ResNet that we use consists of a series of simple <a href="#GeometricMachineLearning.ResNetLayer"><code>ResNetLayer</code></a>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/resnet.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ResNetLayer" href="#GeometricMachineLearning.ResNetLayer"><code>GeometricMachineLearning.ResNetLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>ResNetLayer</code> is a simple feedforward neural network to which we add the input after applying it, i.e. it realizes <span>$x \mapsto x + \sigma(Ax + b)$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/resnet.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SkewSymMatrix" href="#GeometricMachineLearning.SkewSymMatrix"><code>GeometricMachineLearning.SkewSymMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SkewSymMatrix(S::AbstractVector, n::Integer)</code></pre><p>Instantiate a skew-symmetric matrix with information stored in vector <code>S</code>.</p><p>A skew-symmetric matrix <span>$A$</span> is a matrix <span>$A^T = -A$</span>.</p><p>Internally the <code>struct</code> saves a vector <span>$S$</span> of size <span>$n(n-1)\div2$</span>. The conversion is done the following way: </p><p class="math-container">\[[A]_{ij} = \begin{cases} 0                             &amp; \text{if $i=j$} \\
                         S[( (i-2) (i-1) ) \div 2 + j] &amp; \text{if $i&gt;j$}\\ 
                         S[( (j-2) (j-1) ) \div 2 + i] &amp; \text{else}. \end{cases}\]</p><p>Also see <a href="#GeometricMachineLearning.SymmetricMatrix"><code>SymmetricMatrix</code></a>, <a href="#GeometricMachineLearning.LowerTriangular"><code>LowerTriangular</code></a> and <a href="#GeometricMachineLearning.UpperTriangular"><code>UpperTriangular</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
S = [1, 2, 3, 4, 5, 6]
SkewSymMatrix(S, 4)

# output

4×4 SkewSymMatrix{Int64, Vector{Int64}}:
 0  -1  -2  -4
 1   0  -3  -5
 2   3   0  -6
 4   5   6   0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/skew_symmetric.jl#LL1-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SkewSymMatrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.SkewSymMatrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.SkewSymMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SkewSymMatrix(A::AbstractMatrix)</code></pre><p>Perform <code>0.5 * (A - A&#39;)</code> and store the matrix in an efficient way (as a vector with <span>$n(n-1)/2$</span> entries).</p><p>If the constructor is called with a matrix as input it returns a skew-symmetric matrix via the projection:</p><p class="math-container">\[A \mapsto \frac{1}{2}(A - A^T).\]</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
M = [1 2 3 4; 5 6 7 8; 9 10 11 12; 13 14 15 16]
SkewSymMatrix(M)

# output

4×4 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0  -1.5  -3.0  -4.5
 1.5   0.0  -1.5  -3.0
 3.0   1.5   0.0  -1.5
 4.5   3.0   1.5   0.0</code></pre><p><strong>Extend help</strong></p><p>Note that the constructor is designed in such a way that it always returns matrices of type <code>SkewSymMatrix{&lt;:AbstractFloat}</code> when called with a matrix, even if this matrix is of type <code>AbstractMatrix{&lt;:Integer}</code>.</p><p>If the user wishes to allocate a matrix <code>SkewSymMatrix{&lt;:Integer}</code> the constructor <code>SkewSymMatrix(::AbstractVector, n::Integer)</code> has to be called.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/skew_symmetric.jl#LL42-L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StandardTransformerIntegrator" href="#GeometricMachineLearning.StandardTransformerIntegrator"><code>GeometricMachineLearning.StandardTransformerIntegrator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The regular transformer used as an integrator (multi-step method). </p><p>The constructor is called with one argument: </p><ul><li><code>sys_dim::Int</code></li></ul><p>The following are keyword arguments:</p><ul><li><code>transformer_dim::Int</code>: the default is <code>transformer_dim = sys_dim</code>.</li><li><code>n_blocks::Int</code>: The default is <code>1</code>.</li><li><code>n_heads::Int</code>: the number of heads in the multihead attentio layer (default is <code>n_heads = sys_dim</code>)</li><li><code>L::Int</code> the number of transformer blocks (default is <code>L = 2</code>).</li><li><code>upscaling_activation</code>: by default identity</li><li><code>resnet_activation</code>: by default tanh</li><li><code>add_connection:Bool=true</code>: if the input should be added to the output.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/standard_transformer_integrator.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLayer" href="#GeometricMachineLearning.StiefelLayer"><code>GeometricMachineLearning.StiefelLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Stiefel manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/stiefel_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StiefelLieAlgHorMatrix(A::SkewSymMatrix{T}, B::AbstractMatrix{T}, N::Integer, n::Integer) where T</code></pre><p>Build an instance of <code>StiefelLieAlgHorMatrix</code> based on a skew-symmetric matrix <code>A</code> and an arbitrary matrix <code>B</code>.</p><p><code>StiefelLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric). The projection here is: <span>$\pi:S \to SE$</span> where </p><p class="math-container">\[E = \begin{pmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{pmatrix}.\]</p><p>The matrix <span>$E$</span> is implemented under <a href="#GeometricMachineLearning.StiefelProjection"><code>StiefelProjection</code></a> in <code>GeometricMachineLearning</code>.</p><p>An element of StiefelLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where <span>$A$</span> is skew-symmetric (this is <a href="#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> in <code>GeometricMachineLearning</code>).</p><p>Also see <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_lie_algebra_horizontal.jl#LL1-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix-Tuple{AbstractMatrix, Integer}" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix-Tuple{AbstractMatrix, Integer}"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">StiefelLieAlgHorMatrix(D::AbstractMatrix, n::Integer)</code></pre><p>Take a big matrix as input and build an instance of <code>StiefelLieAlgHorMatrix</code> belonging to the StiefelManifold <span>$St(n, N)$</span> where <span>$N$</span> is the number of rows of <code>D</code>.</p><p>If the constructor is called with a big <span>$N\times{}N$</span> matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\mathrm{skew}(A) &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>The operation <span>$\mathrm{skew}:\mathbb{R}^{n\times{}n}\to\mathcal{S}_\mathrm{skew}(n)$</span> is the skew-symmetrization operation. This is equivalent to calling of <a href="#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> with an <span>$n\times{}n$</span> matrix.</p><p>This can also be seen as the operation:</p><p class="math-container">\[D \mapsto \Omega(E, DE) = \mathrm{skew}\left(2 \left(\mathbb{I} - \frac{1}{2} E E^T \right) DE E^T\right).\]</p><p>Also see <a href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_lie_algebra_horizontal.jl#LL38-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelManifold" href="#GeometricMachineLearning.StiefelManifold"><code>GeometricMachineLearning.StiefelManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An implementation of the Stiefel manifold [<a href="../references/#hairer2006geometric">7</a>]. The Stiefel manifold is the collection of all matrices <span>$Y\in\mathbb{R}^{N\times{}n}$</span> whose columns are orthonormal, i.e. </p><p class="math-container">\[    St(n, N) = \{Y: Y^TY = \mathbb{I}_n \}.\]</p><p>The Stiefel manifold can be shown to have manifold structure (as the name suggests) and this is heavily used in <code>GeometricMachineLearning</code>. It is further a compact space.  More information can be found in the docstrings for <code>rgrad(::StiefelManifold, ::AbstractMatrix)</code><code>and</code>metric(::StiefelManifold, ::AbstractMatrix, ::AbstractMatrix)`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/stiefel_manifold.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Outer constructor for <code>StiefelProjection</code>. This works with two integers as input and optionally the type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_projection.jl#LL69-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StiefelProjection(backend, T, N, n)</code></pre><p>Make a matrix of the form <span>$\begin{bmatrix} \mathbb{I} &amp; \mathbb{O} \end{bmatrix}^T$</span> for a specific backend and data type.</p><p>An array that essentially does <code>vcat(I(n), zeros(N-n, n))</code> with GPU support. </p><p><strong>Extend help</strong></p><p>Technically this should be a subtype of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_projection.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.StiefelProjection-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">StiefelProjection(A::AbstractMatrix)</code></pre><p>Extract necessary information from <code>A</code> and build an instance of <code>StiefelProjection</code>. </p><p>Necessary information here referes to the backend, the data type and the size of the matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_projection.jl#LL24-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection-Union{Tuple{GeometricMachineLearning.AbstractLieAlgHorMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.StiefelProjection-Union{Tuple{GeometricMachineLearning.AbstractLieAlgHorMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">StiefelProjection(B::AbstractLieAlgHorMatrix)</code></pre><p>Extract necessary information from <code>B</code> and build an instance of <code>StiefelProjection</code>. </p><p>Necessary information here referes to the backend, the data type and the size of the matrix.</p><p>The size is queried through <code>B.N</code> and <code>B.n</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

B₁ = rand(StiefelLieAlgHorMatrix, 5, 2)
B₂ = rand(GrassmannLieAlgHorMatrix, 5, 2)
E = [1. 0.; 0. 1.; 0. 0.; 0. 0.; 0. 0.]

StiefelProjection(B₁) ≈ StiefelProjection(B₂) ≈ E 

# output

true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/stiefel_projection.jl#LL35-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymmetricMatrix" href="#GeometricMachineLearning.SymmetricMatrix"><code>GeometricMachineLearning.SymmetricMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SymmetricMatrix(S::AbstractVector, n::Integer)</code></pre><p>Instantiate a symmetric matrix with information stored in vector <code>S</code>.</p><p>A <code>SymmetricMatrix</code> <span>$A$</span> is a matrix <span>$A^T = A$</span>.</p><p>Internally the <code>struct</code> saves a vector <span>$S$</span> of size <span>$n(n+1)\div2$</span>. The conversion is done the following way: </p><p class="math-container">\[[A]_{ij} = \begin{cases} S[( (i-1) i ) \div 2 + j] &amp; \text{if $i\geq{}j$}\\ 
                         S[( (j-1) j ) \div 2 + i] &amp; \text{else}. \end{cases}\]</p><p>So <span>$S$</span> stores a string of vectors taken from <span>$A$</span>: <span>$S = [\tilde{a}_1, \tilde{a}_2, \ldots, \tilde{a}_n]$</span> with <span>$\tilde{a}_i = [[A]_{i1},[A]_{i2},\ldots,[A]_{ii}]$</span>.</p><p>Also see <a href="#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a>, <a href="#GeometricMachineLearning.LowerTriangular"><code>LowerTriangular</code></a> and <a href="#GeometricMachineLearning.UpperTriangular"><code>UpperTriangular</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
S = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
SymmetricMatrix(S, 4)

# output

4×4 SymmetricMatrix{Int64, Vector{Int64}}:
 1  2  4   7
 2  3  5   8
 4  5  6   9
 7  8  9  10</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/symmetric.jl#LL1-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymmetricMatrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.SymmetricMatrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.SymmetricMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SymmetricMatrix(A::AbstractMatrix)</code></pre><p>Perform <code>0.5 * (A + A&#39;)</code> and store the matrix in an efficient way (as a vector with <span>$n(n+1)/2$</span> entries).</p><p>If the constructor is called with a matrix as input it returns a symmetric matrix via the projection:</p><p class="math-container">\[A \mapsto \frac{1}{2}(A + A^T).\]</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
M = [1 2 3 4; 5 6 7 8; 9 10 11 12; 13 14 15 16]
SymmetricMatrix(M)

# output

4×4 SymmetricMatrix{Float64, Vector{Float64}}:
 1.0   3.5   6.0   8.5
 3.5   6.0   8.5  11.0
 6.0   8.5  11.0  13.5
 8.5  11.0  13.5  16.0</code></pre><p><strong>Extend help</strong></p><p>Note that the constructor is designed in such a way that it always returns matrices of type <code>SymmetricMatrix{&lt;:AbstractFloat}</code> when called with a matrix, even if this matrix is of type <code>AbstractMatrix{&lt;:Integer}</code>.</p><p>If the user wishes to allocate a matrix <code>SymmetricMatrix{&lt;:Integer}</code> the constructor <code>SymmetricMatrix(::AbstractVector, n::Integer)</code> has to be called.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/symmetric.jl#LL43-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNet" href="#GeometricMachineLearning.SympNet"><code>GeometricMachineLearning.SympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>SympNet</code> type encompasses <a href="#GeometricMachineLearning.GSympNet"><code>GSympNet</code></a>s and <a href="#GeometricMachineLearning.LASympNet"><code>LASympNet</code></a>s. SympNets are universal approximators of <em>symplectic flows</em>, i.e. maps <span>$\varphi:\mathbb{R}^{2n}\to\mathbb{R}^{2n}$</span> for which <span>$(\nabla\varphi)^T\mathbb{J}\nabla\varphi = \mathbb{J}$</span> holds.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/sympnet.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer" href="#GeometricMachineLearning.SympNetLayer"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Implements the various layers from the SympNet paper [<a href="../references/#jin2020sympnets">39</a>]. This is a super type of <a href="#GeometricMachineLearning.GradientLayer"><code>GradientLayer</code></a>, <a href="#GeometricMachineLearning.ActivationLayer"><code>ActivationLayer</code></a> and <a href="#GeometricMachineLearning.LinearLayer"><code>LinearLayer</code></a>.</p><p>For the linear layer, the activation and the bias are left out, and for the activation layer <span>$K$</span> and <span>$b$</span> are left out!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, NamedTuple}" href="#GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, NamedTuple}"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This is called when a SympnetLayer is applied to a <code>NamedTuple</code>. It calls <code>apply_layer_to_nt_and_return_array</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL248-L250">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymplecticAutoencoder" href="#GeometricMachineLearning.SymplecticAutoencoder"><code>GeometricMachineLearning.SymplecticAutoencoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The architecture</strong></p><p>The symplectic autoencoder architecture was introduced in [<a href="../references/#brantner2023symplectic">49</a>]. Like any other autoencoder it consists of an <em>encoder</em> <span>$\Psi^e:\mathbb{R}^{2N}\to\mathbb{R}^{2n}$</span> and a <em>decoder</em> <span>$\Psi^d:\mathbb{R}^{2n}\to\mathbb{R}^{2N}$</span> with <span>$n\ll{}N$</span>. These satisfy the following properties: </p><p class="math-container">\[\nabla_z\Psi^e\mathbb{J}_{2N}(\nabla_z\Psi^e\mathbb{J}_{2N})^T = \mathbb{J}_{2n} \text{ and } (\nabla_\xi\Psi^d)^T\mathbb{J}_{2N}\nabla_\xi\Psi^d = \mathbb{J}_{2n}.\]</p><p>Because the decoder has this particular property, the reduced system can be described by the Hamiltonian <span>$H\circ\Psi^d$</span>: </p><p class="math-container">\[\mathbb{J}_{2n}\nabla_\xi(H\circ\Psi^d) = \mathbb{J}_{2n}(\nabla_\xi\Psi^d)^T\nabla_{\Psi^d(\xi)}H = \mathbb{J}_{2n}(\nabla_\xi\Psi^d)^T\mathbb{J}_{2N}^T\mathbb{J}_{2N}\nabla_{\Psi^d(\xi)}H = (\nabla_\xi\Psi^d)^+X_H(\Psi^d(\xi)),\]</p><p>where <span>$(\nabla_\xi\Psi^d)^+$</span> is the pseudoinverse of <span>$\nabla_\xi\Psi^d$</span> (for more details see the docs on the <a href="#GeometricMachineLearning.AutoEncoder">AutoEncoder</a> type).</p><p><strong>The constructor</strong></p><p>The constructor is called with</p><ul><li><code>full_dim::Integer</code> </li><li><code>reduced_dim::Integer</code> </li><li><code>n_encoder_layers::Integer = 4</code> (keyword argument)</li><li><code>n_encoder_blocks::Integer = 2</code> (keyword argument)</li><li><code>n_decoder_layers::Integer = 1</code> (keyword argument)</li><li><code>n_decoder_blocks::Integer = 3</code> (keyword argument)</li><li><code>sympnet_upscale::Integer = 5</code> (keyword argument)</li><li><code>activation = tanh</code> (keyword argument)</li><li><code>encoder_init_q::Bool = true</code> (keyword argument)</li><li><code>decoder_init_q::Bool = true</code> (keyword argument)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/symplectic_autoencoder.jl#LL1-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymplecticPotential" href="#GeometricMachineLearning.SymplecticPotential"><code>GeometricMachineLearning.SymplecticPotential</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>SymplecticPotential(n)</code></p><p>Returns a symplectic matrix of size 2n x 2n</p><p class="math-container">\[\begin{pmatrix}
\mathbb{O} &amp; \mathbb{I} \\
\mathbb{O} &amp; -\mathbb{I} \\
\end{pmatrix}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/symplectic.jl#LL2-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TrainingData" href="#GeometricMachineLearning.TrainingData"><code>GeometricMachineLearning.TrainingData</code></a> — <span class="docstring-category">Type</span></header><section><div><p>TrainingData stores: </p><pre><code class="nohighlight hljs"> - problem 

 - shape 

 - get 

 - symbols 

 - dim 

 - noisemaker</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data/data_training.jl#LL4-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TransformerIntegrator" href="#GeometricMachineLearning.TransformerIntegrator"><code>GeometricMachineLearning.TransformerIntegrator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Encompasses various transformer architectures, such as the structure-preserving transformer and the linear symplectic transformer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/transformer_integrator.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TransformerLoss" href="#GeometricMachineLearning.TransformerLoss"><code>GeometricMachineLearning.TransformerLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TransformerLoss(seq_length, prediction_window)</code></pre><p>Make an instance of the transformer loss. </p><p>This is the loss for a transformer network (especially a transformer integrator). </p><p><strong>Parameters</strong></p><p>The <code>prediction_window</code> specifies how many time steps are predicted into the future. It defaults to the value specified for <code>seq_length</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/loss/losses.jl#LL28-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.UpperTriangular" href="#GeometricMachineLearning.UpperTriangular"><code>GeometricMachineLearning.UpperTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LowerTriangular(S::AbstractVector, n::Int)</code></pre><p>Build a lower-triangular matrix from a vector.</p><p>A lower-triangular matrix is an <span>$n\times{}n$</span> matrix that has ones on the diagonal and zeros on the upper triangular.</p><p>The data are stored in a vector <span>$S$</span> similarly to other matrices. See <a href="#GeometricMachineLearning.LowerTriangular"><code>LowerTriangular</code></a>, <a href="#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> and <a href="#GeometricMachineLearning.SymmetricMatrix"><code>SymmetricMatrix</code></a>.</p><p>The struct two fields: <code>S</code> and <code>n</code>. The first stores all the entries of the matrix in a sparse fashion (in a vector) and the second is the dimension <span>$n$</span> for <span>$A\in\mathbb{R}^{n\times{}n}$</span>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
S = [1, 2, 3, 4, 5, 6]
UpperTriangular(S, 4)

# output

4×4 UpperTriangular{Int64, Vector{Int64}}:
 0  1  2  4
 0  0  3  5
 0  0  0  6
 0  0  0  0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/upper_triangular.jl#LL1-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.UpperTriangular-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.UpperTriangular-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.UpperTriangular</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">UpperTriangular(A::AbstractMatrix)</code></pre><p>Build a lower-triangular matrix from a matrix.</p><p>This is done by taking the lower left of that matrix.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
M = [1 2 3 4; 5 6 7 8; 9 10 11 12; 13 14 15 16]
UpperTriangular(M)

# output

4×4 UpperTriangular{Int64, Vector{Int64}}:
 0  2  3   4
 0  0  7   8
 0  0  0  12
 0  0  0   0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/upper_triangular.jl#LL32-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingAttention" href="#GeometricMachineLearning.VolumePreservingAttention"><code>GeometricMachineLearning.VolumePreservingAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>Volume-preserving attention (single head attention)</strong></p><p>Drawbacks: </p><ul><li>the super fast activation is only implemented for sequence lengths of 2, 3, 4 and 5.</li><li>other sequence lengths only work on CPU for now (lu decomposition has to be implemented to work for tensors in parallel).</li></ul><p><strong>Constructor</strong></p><p>The constructor is called with: </p><ul><li><code>dim::Int</code>: The system dimension </li><li><code>seq_length::Int</code>: The sequence length to be considered. The default is zero, i.e. arbitrary sequence lengths; this works for all sequence lengths but doesn&#39;t apply the super-fast activation. </li><li><code>skew_sym::Bool</code> (keyword argument): specifies if we the weight matrix is skew symmetric or arbitrary (default is false).</li></ul><p><strong>Functor</strong></p><p>Applying a layer of type <code>VolumePreservingAttention</code> does the following: </p><ul><li>First we perform the operation <span>$X \mapsto X^T A X =: C$</span>, where <span>$X\in\mathbb{R}^{N\times\mathtt{seq\_length}}$</span> is a vector containing time series data and <span>$A$</span> is the skew symmetric matrix associated with the layer. </li><li>In a second step we compute the Cayley transform of <span>$C$</span>; <span>$\Lambda = \mathrm{Cayley}(C)$</span>.</li><li>The output of the layer is then <span>$X\Lambda$</span>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/volume_preserving_attention.jl#LL1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingFeedForward" href="#GeometricMachineLearning.VolumePreservingFeedForward"><code>GeometricMachineLearning.VolumePreservingFeedForward</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Realizes a volume-preserving neural network as a combination of <code>VolumePreservingLowerLayer</code> and <code>VolumePreservingUpperLayer</code>. </p><p><strong>Constructor</strong></p><p>The constructor is called with the following arguments: </p><ul><li><code>sys_dim::Int</code>: The system dimension. </li><li><code>n_blocks::Int</code>: The number of blocks in the neural network (containing linear layers and nonlinear layers). Default is <code>1</code>.</li><li><code>n_linear::Int</code>: The number of linear <code>VolumePreservingLowerLayer</code>s and <code>VolumePreservingUpperLayer</code>s in one block. Default is <code>1</code>.</li><li><code>activation</code>: The activation function for the nonlinear layers in a block. </li><li><code>init_upper::Bool=false</code> (keyword argument): Specifies if the first layer is lower or upper. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/volume_preserving_feedforward.jl#LL10-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingFeedForwardLayer" href="#GeometricMachineLearning.VolumePreservingFeedForwardLayer"><code>GeometricMachineLearning.VolumePreservingFeedForwardLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Super-type of <code>VolumePreservingLowerLayer</code> and <code>VolumePreservingUpperLayer</code>. The layers do the following: </p><p class="math-container">\[x \mapsto \begin{cases} \sigma(Lx + b) &amp; \text{where $L$ is }\mathtt{LowerTriangular} \\ \sigma(Ux + b) &amp; \text{where $U$ is }\mathtt{UpperTriangular}. \end{cases}\]</p><p>The functor can be applied to a vecotr, a matrix or a tensor. </p><p><strong>Constructor</strong></p><p>The constructors are called with:</p><ul><li><code>sys_dim::Int</code>: the system dimension. </li><li><code>activation=tanh</code>: the activation function. </li><li><code>include_bias::Bool=true</code> (keyword argument): specifies whether a bias should be used. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/volume_preserving_feedforward.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingLowerLayer" href="#GeometricMachineLearning.VolumePreservingLowerLayer"><code>GeometricMachineLearning.VolumePreservingLowerLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>See the documentation for <code>VolumePreservingFeedForwardLayer</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/volume_preserving_feedforward.jl#LL19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingTransformer" href="#GeometricMachineLearning.VolumePreservingTransformer"><code>GeometricMachineLearning.VolumePreservingTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The volume-preserving transformer with the Cayley activation function and built-in upscaling.</p><p><strong>Constructor</strong></p><p>The arguments for the constructor are: </p><ol><li><code>sys_dim::Int</code></li><li><code>seq_length::Int</code>: The sequence length of the data fed into the transformer.</li></ol><p>The following are keyword argumetns:</p><ul><li><code>n_blocks::Int=1</code>: The number of blocks in one transformer unit (containing linear layers and nonlinear layers). Default is <code>1</code>.</li><li><code>n_linear::Int=1</code>: The number of linear <code>VolumePreservingLowerLayer</code>s and <code>VolumePreservingUpperLayer</code>s in one block. Default is <code>1</code>.</li><li><code>L::Int=1</code>: The number of transformer units. </li><li><code>activation=tanh</code>: The activation function.</li><li><code>init_upper::Bool=false</code>: Specifies if the network first acts on the <span>$q$</span> component. </li><li><code>skew_sym::Bool=false</code>: specifies if we the weight matrix is skew symmetric or arbitrary.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/volume_preserving_transformer.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingUpperLayer" href="#GeometricMachineLearning.VolumePreservingUpperLayer"><code>GeometricMachineLearning.VolumePreservingUpperLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>See the documentation for <code>VolumePreservingFeedForwardLayer</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/volume_preserving_feedforward.jl#LL34-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.update!-Tuple{Any, Any, AbstractArray}" href="#AbstractNeuralNetworks.update!-Tuple{Any, Any, AbstractArray}"><code>AbstractNeuralNetworks.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update!(o, cache, dx::AbstractArray)</code></pre><p>Update the <code>cache</code> based on the gradient information <code>dx</code>, compute the final velocity and store it in <code>dx</code>.</p><p>The optimizer <code>o</code> is needed because some updating schemes (such as <a href="#GeometricMachineLearning.AdamOptimizer"><code>AdamOptimizer</code></a>) also need information on the current time step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_method.jl#LL13-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.update!-Tuple{Optimizer, AbstractCache, AbstractArray}" href="#AbstractNeuralNetworks.update!-Tuple{Optimizer, AbstractCache, AbstractArray}"><code>AbstractNeuralNetworks.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update!(o, cache, B)</code></pre><p>First update the <code>cache</code> and then update the array <code>B</code> based on the optimizer <code>o</code>. </p><p>Note that <span>$B\in\mathfrak{g}^\mathrm{hor}$</span> in general.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL47-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, BT, HT} where {BT&lt;:(AbstractArray{T}), HT&lt;:AbstractMatrix{T}})}" href="#AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, BT, HT} where {BT&lt;:(AbstractArray{T}), HT&lt;:AbstractMatrix{T}})}"><code>AbstractNeuralNetworks.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update!(o::Optimizer{&lt;:BFGSOptimizer}, C, B)</code></pre><p>Peform an update with the BFGS optimizer. </p><p><code>C</code> is the cache, <code>B</code> contains the gradient information (the output of <a href="../arrays/global_tangent_spaces/#GeometricMachineLearning.global_rep-arrays-global_tangent_spaces"><code>global_rep</code></a> in general).</p><p>First we compute the <em>final velocity</em> with</p><pre><code class="language-julia hljs">    vecS = -o.method.η * C.H * vec(B)</code></pre><p>and then we update <code>H</code></p><pre><code class="language-julia hljs">    C.H .= (𝕀 - ρ * SY) * C.H * (𝕀 - ρ * SY&#39;) + ρ * vecS * vecS&#39;</code></pre><p>where <code>SY</code> is <code>vecS * Y&#39;</code> and <code>𝕀</code> is the idendity. </p><p><strong>Implementation</strong></p><p>For stability we use <code>δ</code> for computing <code>ρ</code>:</p><pre><code class="language-julia hljs">    ρ = 1. / (vecS&#39; * Y + o.method.δ)</code></pre><p>This is similar to the <a href="#GeometricMachineLearning.AdamOptimizer"><code>AdamOptimizer</code></a></p><p><strong>Extend Help</strong></p><p>If we have weights on a <a href="#GeometricMachineLearning.Manifold"><code>Manifold</code></a> than the updates are slightly more difficult. In this case the <a href="#Base.vec-Tuple{GeometricMachineLearning.AbstractTriangular}"><code>vec</code></a> operation has to be generalized to the corresponding <em>global tangent space</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/bfgs_optimizer.jl#LL18-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:*-Tuple{GlobalSection, Manifold}" href="#Base.:*-Tuple{GlobalSection, Manifold}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">*(λY, Y)</code></pre><p>Apply the element <code>λY</code> onto <code>Y</code>.</p><p>Here <code>λY</code> is an element of a Lie group and <code>Y</code> is an element of a homogeneous space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL50-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.iterate-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:TransformerIntegrator}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractMatrix{T}}" href="#Base.iterate-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:TransformerIntegrator}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractMatrix{T}}"><code>Base.iterate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function computes a trajectory for a Transformer that has already been trained for valuation purposes.</p><p>It takes as input: </p><ul><li><code>nn</code>: a <code>NeuralNetwork</code> (that has been trained).</li><li><code>ics</code>: initial conditions (a matrix in <span>$\mathbb{R}^{2n\times\mathtt{seq\_length}}$</span> or <code>NamedTuple</code> of two matrices in <span>$\mathbb{R}^{n\times\mathtt{seq\_length}}$</span>)</li><li><code>n_points::Int=100</code> (keyword argument): The number of steps for which we run the prediction. </li><li><code>prediction_window::Int=size(ics.q, 2)</code>: The prediction window (i.e. the number of steps we predict into the future) is equal to the sequence length (i.e. the number of input time steps) by default.  </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/transformer_integrator.jl#LL10-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.iterate-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:NeuralNetworkIntegrator}, BT}} where {T, AT&lt;:AbstractVector{T}, BT&lt;:@NamedTuple{q::AT, p::AT}}" href="#Base.iterate-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:NeuralNetworkIntegrator}, BT}} where {T, AT&lt;:AbstractVector{T}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>Base.iterate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function computes a trajectory for a SympNet that has already been trained for valuation purposes.</p><p>It takes as input: </p><ul><li><code>nn</code>: a <code>NeuralNetwork</code> (that has been trained).</li><li><code>ics</code>: initial conditions (a <code>NamedTuple</code> of two vectors)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/neural_network_integrator.jl#LL31-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.rand-Union{Tuple{MT}, Tuple{KernelAbstractions.Backend, Type{MT}, Integer, Integer}} where MT&lt;:Manifold" href="#Base.rand-Union{Tuple{MT}, Tuple{KernelAbstractions.Backend, Type{MT}, Integer, Integer}} where MT&lt;:Manifold"><code>Base.rand</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rand(backend::KernelAbstractions.Backend, manifold_type::Type{MT}, N::Integer, n::Integer) where MT &lt;: Manifold)</code></pre><p>Draw random elements for a specific device.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round # hide
import Random
Random.seed!(123)

N, n = 5, 3
Y = rand(CPU(), StiefelManifold{Float32}, N, n)
_round(Y; digits = 5) # hide

# output

5×3 StiefelManifold{Float32, Matrix{Float32}}:
 -0.27575   0.32991   0.77275
 -0.62485  -0.33224  -0.0686
 -0.69333   0.36724  -0.18988
 -0.09295  -0.73145   0.46064
  0.2102    0.33301   0.38717</code></pre><p>Random elements of the manifold can also be allocated on GPU, via e.g. ...</p><pre><code class="language-julia hljs">rand(CUDABackend(), StiefelManifold{Float32}, N, n)</code></pre><p>... for drawing elements on a <code>CUDA</code> device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/abstract_manifold.jl#LL53-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.rand-Union{Tuple{MT}, Tuple{Type{MT}, Integer, Integer}} where MT&lt;:Manifold" href="#Base.rand-Union{Tuple{MT}, Tuple{Type{MT}, Integer, Integer}} where MT&lt;:Manifold"><code>Base.rand</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rand(manifold_type::Type{MT}, N::Integer, n::Integer) where MT &lt;: Manifold</code></pre><p>Draw random elements from the Stiefel and the Grassmann manifold. </p><p>Because both of these manifolds are compact spaces we can sample them uniformly [<a href="../references/#mezzadri2006generate">8</a>].</p><p><strong>Examples</strong></p><p>When we call ...</p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round # hide
import Random
Random.seed!(123)

N, n = 5, 3
Y = rand(StiefelManifold{Float32}, N, n)
_round(Y; digits = 5) # hide

# output

5×3 StiefelManifold{Float32, Matrix{Float32}}:
 -0.27575   0.32991   0.77275
 -0.62485  -0.33224  -0.0686
 -0.69333   0.36724  -0.18988
 -0.09295  -0.73145   0.46064
  0.2102    0.33301   0.38717</code></pre><p>... the sampling is done by first allocating a random matrix of size <span>$N\times{}n$</span> via <code>Y = randn(Float32, N, n)</code>. We then perform a QR decomposition <code>Q, R = qr(Y)</code> with the <code>qr</code> function from the <code>LinearAlgebra</code> package (this is using Householder reflections internally).  The final output are then the first <code>n</code> columns of the <code>Q</code> matrix. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/abstract_manifold.jl#LL91-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.vec-Tuple{GeometricMachineLearning.AbstractTriangular}" href="#Base.vec-Tuple{GeometricMachineLearning.AbstractTriangular}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>If <code>vec</code> is applied onto <code>Triangular</code>, then the output is the associated vector.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/triangular.jl#LL101-L103">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.vec-Tuple{SkewSymMatrix}" href="#Base.vec-Tuple{SkewSymMatrix}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>If <code>vec</code> is applied onto <code>SkewSymMatrix</code>, then the output is the associated vector.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/skew_symmetric.jl#LL227-L229">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ChainRulesCore.rrule-Union{Tuple{T}, Tuple{typeof(GeometricMachineLearning.tensor_transpose_mat_mul), AbstractArray{T, 3}, AbstractMatrix{T}}} where T" href="#ChainRulesCore.rrule-Union{Tuple{T}, Tuple{typeof(GeometricMachineLearning.tensor_transpose_mat_mul), AbstractArray{T, 3}, AbstractMatrix{T}}} where T"><code>ChainRulesCore.rrule</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This implements the custom pullback for tensor<em>transpose</em>mat_mul</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/kernel_ad_routines/tensor_transpose_mat_mul.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Gradient" href="#GeometricMachineLearning.Gradient"><code>GeometricMachineLearning.Gradient</code></a> — <span class="docstring-category">Function</span></header><section><div><p>This is an old constructor and will be depricated. For <code>change_q=true</code> it is equivalent to <code>GradientLayerQ</code>; for <code>change_q=false</code> it is equivalent to <code>GradientLayerP</code>.</p><p>If <code>full_grad=false</code> then <code>ActivationLayer</code> is called</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL132-L136">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.Transformer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The architecture for a &quot;transformer encoder&quot; is essentially taken from arXiv:2010.11929, but with the difference that <strong>no</strong> layer normalization is employed. This is because we still need to find a generalization of layer normalization to manifolds. </p><p>The transformer is called with the following inputs: </p><ul><li><code>dim</code>: the dimension of the transformer </li><li><code>n_heads</code>: the number of heads </li><li><code>L</code>: the number of <strong>transformer blocks</strong></li></ul><p>In addition we have the following optional arguments: </p><ul><li><code>activation</code>: the activation function used for the <code>ResNet</code> (<code>tanh</code> by default)</li><li><code>Stiefel::Bool</code>: if the matrices <span>$P^V$</span>, <span>$P^Q$</span> and <span>$P^K$</span> should live on a manifold (<code>false</code> by default)</li><li><code>retraction</code>: which retraction should be used (<code>Geodesic()</code> by default)</li><li><code>add_connection::Bool</code>: if the input should by added to the ouput after the <code>MultiHeadAttention</code> layer is used (<code>true</code> by default)</li><li><code>use_bias::Bool</code>: If the <code>ResNet</code> should use a bias (<code>true</code> by default)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/transformer.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}" href="#GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}"><code>GeometricMachineLearning.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the accuracy (as opposed to the loss) of a neural network classifier. </p><p>It takes as input:</p><ul><li><code>model::Chain</code></li><li><code>ps</code>: parameters of the network</li><li><code>dl::DataLoader</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/data_loader.jl#LL167-L174">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_layer_to_nt_and_return_array-Tuple{AbstractArray, AbstractNeuralNetworks.AbstractExplicitLayer, NamedTuple}" href="#GeometricMachineLearning.apply_layer_to_nt_and_return_array-Tuple{AbstractArray, AbstractNeuralNetworks.AbstractExplicitLayer, NamedTuple}"><code>GeometricMachineLearning.apply_layer_to_nt_and_return_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function is used in the wrappers where the input to the SympNet layers is not a <code>NamedTuple</code> (as it should be) but an <code>AbstractArray</code>.</p><p>It converts the Array to a <code>NamedTuple</code> (via <code>assign_q_and_p</code>), then calls the SympNet routine(s) and converts back to an <code>AbstractArray</code> (with <code>vcat</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL236-L240">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_section!-Union{Tuple{AT}, Tuple{T}, Tuple{AT, GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}" href="#GeometricMachineLearning.apply_section!-Union{Tuple{AT}, Tuple{T}, Tuple{AT, GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>GeometricMachineLearning.apply_section!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">apply_section!(Y::AT, λY::GlobalSection{T, AT}, Y₂::AT) where {T, AT&lt;:StiefelManifold{T}}</code></pre><p>Apply <code>λY</code> to <code>Y₂</code> and store the result in <code>Y</code>.</p><p>The inplace version of <a href="#GeometricMachineLearning.apply_section-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>apply_section</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL75-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_section-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}" href="#GeometricMachineLearning.apply_section-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>GeometricMachineLearning.apply_section</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">apply_section(λY::GlobalSection{T, AT}, Y₂::AT) where {T, AT &lt;: StiefelManifold{T}}</code></pre><p>Apply <code>λY</code> to <code>Y₂</code>.</p><p>Mathematically this is the group action of the element <span>$\lambda{}Y\in{}G$</span> on the element <span>$Y_2$</span> of the homogeneous space <span>$\mathcal{M}$</span>.</p><p>Internally it calls the inplace version <a href="#GeometricMachineLearning.apply_section!-Union{Tuple{AT}, Tuple{T}, Tuple{AT, GlobalSection{T, AT}, AT}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>apply_section!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL59-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_batch_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input a <em>batch tensor</em> (to which the data are assigned), the whole data tensor and two vectors <em>params</em> and <em>time_steps</em> that include the specific parameters and time steps we want to assign. </p><p>Note that this assigns sequential data! For e.g. being processed by a transformer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/tensor_assign.jl#LL9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T" href="#GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T"><code>GeometricMachineLearning.assign_output_estimate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The function <code>assign_output_estimate</code> is closely related to the transformer. It takes the last <code>prediction_window</code> columns of the output and uses them for the final prediction. i.e.</p><p class="math-container">\[\mathbb{R}^{N\times\mathtt{pw}}\to\mathbb{R}^{N\times\mathtt{pw}}, 
\begin{bmatrix} 
    z^{(1)}_1               &amp; \cdots &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots &amp; \cdots    \\ 
    z^{(1)}_n               &amp; \cdots &amp; z^{(T})_n
    \end{bmatrix} \mapsto 
    \begin{bmatrix} 
    z^{(T - \mathtt{pw})}_1 &amp; \cdots      &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots      &amp; \cdots \\ 
    z^{(T - \mathtt{pw})}_n &amp; \cdots      &amp; z^{(T})_n\end{bmatrix}     \]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/tensor_assign.jl#LL37-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_output_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_output_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This should be used together with <code>assign_batch_kernel!</code>. It assigns the corresponding output (i.e. target).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/tensor_assign.jl#LL21-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}" href="#GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}"><code>GeometricMachineLearning.assign_q_and_p</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Allocates two new arrays <code>q</code> and <code>p</code> whose first dimension is half of that of the input <code>x</code>. This should also be supplied through the second argument <code>N</code>.</p><p>The output is a <code>Tuple</code> containing <code>q</code> and <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/assign_q_and_p.jl#LL35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}" href="#GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}"><code>GeometricMachineLearning.augment_zeros_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Used for differentiating assign<em>output</em>estimate (this appears in the loss). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/tensor_assign.jl#LL62-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.build_v_reduced-Tuple{Any, Any, NeuralNetwork{&lt;:GeometricMachineLearning.SymplecticDecoder}}" href="#GeometricMachineLearning.build_v_reduced-Tuple{Any, Any, NeuralNetwork{&lt;:GeometricMachineLearning.SymplecticDecoder}}"><code>GeometricMachineLearning.build_v_reduced</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Builds the reduced vector field based on the full vector field for a Hamiltonian system. We derive the reduced vector field via the reduced Hamiltonian: <span>$\tilde{H} := H\circ\Psi^\mathrm{dec}$</span>.  We then get </p><p class="math-container">\[\mathbb{J}_{2n}\nabla_\xi\tilde{H} = \mathbb{J}_{2n}(\nabla\Psi^\mathrm{dec})^T\mathbb{J}_{2N}^T\mathbb{J}_{2N}\nabla_z{}H = \mathbb{J}_{2n}(\nabla\Psi^\mathrm{dec})^T\mathbb{J}_{2N}^T \begin{pmatrix} v(z) \\ f(z) \end{pmatrix} = \begin{pmatrix} - (\nabla_p\Psi_q)^Tf(z) + (\nabla_p\Psi_p)^Tv(z) \\ (\nabla_q\Psi_q)^Tf(z) - (\nabla_q\Psi_p)^Tv(z) \end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/reduced_system/reduced_system.jl#LL74-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.cayley-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cayley(B::GrassmannLieAlgHorMatrix)</code></pre><p>Compute the Cayley retraction of <code>B</code> and multiply it with <code>E</code> (the distinct element of the Stiefel manifold).</p><p>See <a href="#GeometricMachineLearning.cayley-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>cayley(::StiefelLieAlgHorMatrix)</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL116-L122">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Union{Tuple{StiefelLieAlgHorMatrix{T, AT, ST} where {AT&lt;:(SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}), ST&lt;:AbstractMatrix{T}}}, Tuple{T}} where T" href="#GeometricMachineLearning.cayley-Union{Tuple{StiefelLieAlgHorMatrix{T, AT, ST} where {AT&lt;:(SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}), ST&lt;:AbstractMatrix{T}}}, Tuple{T}} where T"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cayley(B::StiefelLieAlgHorMatrix)</code></pre><p>Compute the Cayley retraction of <code>B</code> and multiply it with <code>E</code> (the distinct element of the Stiefel manifold).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.cayley-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cayley(Y::Manifold, Δ)</code></pre><p>Take as input an element of a manifold <code>Y</code> and a tangent vector in <code>Δ</code> in the corresponding tangent space and compute the Cayley retraction.</p><p>In different notation: take as input an element <span>$x$</span> of <span>$\mathcal{M}$</span> and an element of <span>$T_x\mathcal{M}$</span> and return <span>$\mathrm{Cayley}(v_x).$</span> For example: </p><pre><code class="language-julia hljs">Y = rand(StiefelManifold{Float64}, N, n)
Δ = rgrad(Y, rand(N, n))
cayley(Y, Δ)</code></pre><p>See the docstring for <a href="#GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}"><code>rgrad</code></a> for details on this function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL75-L89">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_iterations-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.compute_iterations-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.compute_iterations</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function gives iterations from the full dimension to the reduced dimension (i.e. the intermediate steps). The iterations are given in ascending order. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL60-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_iterations_for_symplectic_system-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.compute_iterations_for_symplectic_system-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.compute_iterations_for_symplectic_system</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function gives iterations from the full dimension to the reduced dimension (i.e. the intermediate steps). The iterations are given in ascending order. Only even steps are allowed here.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/symplectic_autoencoder.jl#LL78-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}" href="#GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}"><code>GeometricMachineLearning.compute_output_of_mha</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Applies MHA to an abstract matrix. This is the same independent of whether the input is added to the output or not. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/multi_head_attention.jl#LL86-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array (NamedTuples). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/batch.jl#LL121-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/batch.jl#LL147-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.crop_array_for_transformer_loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T2}, Tuple{T}, Tuple{AT, BT}} where {T, T2, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T2, 3}}" href="#GeometricMachineLearning.crop_array_for_transformer_loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T2}, Tuple{T}, Tuple{AT, BT}} where {T, T2, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T2, 3}}"><code>GeometricMachineLearning.crop_array_for_transformer_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This crops the output array of the neural network so that it conforms with the output it should be compared to. This is needed for the transformer loss. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/loss/losses.jl#LL47-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}" href="#GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}"><code>GeometricMachineLearning.custom_mat_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Multiplies a matrix with a vector, a matrix or a tensor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/sympnets.jl#LL186-L188">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.decoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}" href="#GeometricMachineLearning.decoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}"><code>GeometricMachineLearning.decoder_layers_from_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input the autoencoder architecture and a vector of integers specifying the layer dimensions in the decoder. Has to return a tuple of <code>AbstractExplicitLayer</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL82-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.draw_batch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the batch if the data are in form of a matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/matrix_assign.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.encoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}" href="#GeometricMachineLearning.encoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}"><code>GeometricMachineLearning.encoder_layers_from_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input the autoencoder architecture and a vector of integers specifying the layer dimensions in the encoder. Has to return a tuple of <code>AbstractExplicitLayer</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/autoencoder.jl#LL77-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.geodesic-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">geodesic(B::GrassmannLieAlgHorMatrix)</code></pre><p>Compute the geodesic of an element in <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p><p>See <a href="#GeometricMachineLearning.geodesic-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>geodesic(::StiefelLieAlgHorMatrix)</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL57-L63">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Union{Tuple{StiefelLieAlgHorMatrix{T, AT, ST} where {AT&lt;:(SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}), ST&lt;:AbstractMatrix{T}}}, Tuple{T}} where T" href="#GeometricMachineLearning.geodesic-Union{Tuple{StiefelLieAlgHorMatrix{T, AT, ST} where {AT&lt;:(SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}), ST&lt;:AbstractMatrix{T}}}, Tuple{T}} where T"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">geodesic(B::StiefelLieAlgHorMatrix)</code></pre><p>Compute the geodesic of an element in <a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a>.</p><p><strong>Implementation</strong></p><p>This is using a computationally efficient version of the matrix exponential. See <a href="#GeometricMachineLearning.𝔄-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.𝔄</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL39-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.geodesic-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">geodesic(Y::Manifold, Δ)</code></pre><p>Take as input an element of a manifold <code>Y</code> and a tangent vector in <code>Δ</code> in the corresponding tangent space and compute the geodesic (exponential map).</p><p>In different notation: take as input an element <span>$x$</span> of <span>$\mathcal{M}$</span> and an element of <span>$T_x\mathcal{M}$</span> and return <span>$\mathtt{geodesic}(x, v_x) = \exp(v_x).$</span> For example: </p><pre><code class="language-julia hljs">Y = rand(StiefelManifold{Float64}, N, n)
Δ = rgrad(Y, rand(N, n))
geodesic(Y, Δ)</code></pre><p>See the docstring for <a href="#GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}"><code>rgrad</code></a> for details on this function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/retractions.jl#LL16-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_rep-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AbstractMatrix{T}}} where {T, AT&lt;:(GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T})}" href="#GeometricMachineLearning.global_rep-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AbstractMatrix{T}}} where {T, AT&lt;:(GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>GeometricMachineLearning.global_rep</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">global_rep(λY::GlobalSection{T, AT}, Δ::AbstractMatrix{T}) where {T, AT&lt;:GrassmannManifold{T}}</code></pre><p>Express <code>Δ</code> (an the tangent space of <code>Y</code>) as an instance of <code>GrassmannLieAlgHorMatrix</code>.</p><p>The method <code>global_rep</code> for <a href="#GeometricMachineLearning.GrassmannManifold"><code>GrassmannManifold</code></a> is similar to that for <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round
import Random 

Random.seed!(123)

Y = rand(GrassmannManifold, 6, 3)
Δ = rgrad(Y, randn(6, 3))
λY = GlobalSection(Y)

_round(global_rep(λY, Δ); digits = 3)

# output

6×6 GrassmannLieAlgHorMatrix{Float64, Matrix{Float64}}:
  0.0     0.0     0.0     0.981  -2.058   0.4
  0.0     0.0     0.0    -0.424   0.733  -0.919
  0.0     0.0     0.0    -1.815   1.409   1.085
 -0.981   0.424   1.815   0.0     0.0     0.0
  2.058  -0.733  -1.409   0.0     0.0     0.0
 -0.4     0.919  -1.085   0.0     0.0     0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL194-L226">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_rep-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AbstractMatrix{T}}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}" href="#GeometricMachineLearning.global_rep-Union{Tuple{AT}, Tuple{T}, Tuple{GlobalSection{T, AT}, AbstractMatrix{T}}} where {T, AT&lt;:(StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T})}"><code>GeometricMachineLearning.global_rep</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">global_rep(λY::GlobalSection{T, AT}, Δ::AbstractMatrix{T}) where {T, AT&lt;:StiefelManifold{T}}</code></pre><p>Express <code>Δ</code> (an the tangent space of <code>Y</code>) as an instance of <code>StiefelLieAlgHorMatrix</code>.</p><p>This maps an element from <span>$T_Y\mathcal{M}$</span> to an element of <span>$\mathfrak{g}^\mathrm{hor}$</span>. </p><p>These two spaces are isomorphic where the isomorphism where the isomorphism is established through <span>$\lambda(Y)\in{}G$</span> via:</p><p class="math-container">\[T_Y\mathcal{M} \to \mathfrak{g}^{\mathrm{hor}}, \Delta \mapsto \lambda(Y)^{-1}\Omega(Y, \Delta)\lambda(Y).\]</p><p>Also see <a href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round
import Random 

Random.seed!(123)

Y = rand(StiefelManifold, 6, 3)
Δ = rgrad(Y, randn(6, 3))
λY = GlobalSection(Y)

_round(global_rep(λY, Δ); digits = 3)

# output

6×6 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, Matrix{Float64}}:
  0.0     0.679   1.925   0.981  -2.058   0.4
 -0.679   0.0     0.298  -0.424   0.733  -0.919
 -1.925  -0.298   0.0    -1.815   1.409   1.085
 -0.981   0.424   1.815   0.0     0.0     0.0
  2.058  -0.733  -1.409   0.0     0.0     0.0
 -0.4     0.919  -1.085   0.0     0.0     0.0</code></pre><p><strong>Implementation</strong></p><p>The function <code>global_rep</code> does in fact not perform the entire map <span>$\lambda(Y)^{-1}\Omega(Y, \Delta)\lambda(Y)$</span> but only</p><p class="math-container">\[\Delta \mapsto \mathrm{skew}(Y^T\Delta),\]</p><p>to get the small skew-symmetric matrix and </p><p class="math-container">\[\Delta \mapsto (\lambda(Y)_{[1:N, n:N]}^T \Delta)_{[1:(N-n), 1:n]},\]</p><p>for the arbitrary matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/global_sections.jl#LL127-L183">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_section-Union{Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.global_section-Union{Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.global_section</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">global_section(Y::GrassmannManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>The method <code>global_section</code> for the Grassmann manifold is equivalent to that for the <a href="#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> (we represent the Grassmann manifold as an embedding in the Stiefel manifold). </p><p>See the documentation for <a href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>global_section(Y::StiefelManifold{T}) where T</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/grassmann_manifold.jl#LL63-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.global_section</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">global_section(Y::StiefelManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>This matrix is also called <span>$Y_\perp$</span> [<a href="../references/#absil2004riemannian">6</a>, <a href="../references/#absil2008optimization">10</a>, <a href="../references/#bendokat2020grassmann">11</a>].</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: global_section
import Random

Random.seed!(123)

Y = StiefelManifold([1. 0.; 0. 1.; 0. 0.; 0. 0.])

round.(Matrix(global_section(Y)); digits = 3)

# output

4×2 Matrix{Float64}:
 0.0    -0.0
 0.0     0.0
 0.936  -0.353
 0.353   0.936</code></pre><p>Further note that we convert the <code>QRCompactWYQ</code> object to a <code>Matrix</code> before we display it.</p><p><strong>Implementation</strong></p><p>The implementation is done with a QR decomposition (<code>LinearAlgebra.qr!</code>). Internally we do: </p><pre><code class="language-julia hljs">A = randn(N, N - n) # or the gpu equivalent
A = A - Y.A * (Y.A&#39; * A)
qr!(A).Q</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/stiefel_manifold.jl#LL80-L120">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}" href="#GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}"><code>GeometricMachineLearning.init_optimizer_cache</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">init_optimizer_cache(method, x)</code></pre><p>Initialize the cache corresponding to the weights <code>x</code> for a specific method.</p><p><strong>Implementation</strong></p><p>Wrapper for the functions <code>setup_adam_cache</code>, <code>setup_momentum_cache</code>, <code>setup_gradient_cache</code>, <code>setup_bfgs_cache</code>. These appear outside of <code>optimizer_caches.jl</code> because the <code>OptimizerMethods</code> first have to be defined.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/init_optimizer_cache.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.init_optimizer_cache-Tuple{OptimizerMethod, Any}" href="#GeometricMachineLearning.init_optimizer_cache-Tuple{OptimizerMethod, Any}"><code>GeometricMachineLearning.init_optimizer_cache</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">init_optimizer_cache(method, x)</code></pre><p>Initialize the optimizer cache based on input <code>x</code> for the given <code>method</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer_method.jl#LL6-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.initialize_hessian_inverse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">initialize_hessian_inverse(B)</code></pre><p>Initialize the inverse of the Hessian for various arrays. </p><p><strong>Implementation</strong></p><p>This requires an implementation of a <em>vectorization operation</em> <code>vec</code>. This is important for custom arrays.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/bfgs_cache.jl#LL36-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}" href="#GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}"><code>GeometricMachineLearning.map_index_for_symplectic_potential</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the right index for the symplectic potential. To be used with <code>assign_ones_for_symplectic_potential_kernel!</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/arrays/symplectic.jl#LL65-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul!-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.mat_tensor_mul!-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.mat_tensor_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C, A, B)</code></pre><p>Multiply the matrix <code>A</code> onto the tensor <code>B</code> from the left and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays.</p><p>The function <a href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}"><code>mat_tensor_mul</code></a> calls <code>mat_tensor_mul!</code> internally.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL16-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, LowerTriangular{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, LowerTriangular{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C::AbstractArray{T, 3}, A::LowerTriangular{T}, B::AbstractArray{T, 3}) where T</code></pre><p>Multiply the lower-triangular matrix <code>A</code> onto the tensor <code>B</code> from the left and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays. </p><p>This performs an efficient multiplication based on the special structure of the lower-triangular matrix <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL147-L155">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, SkewSymMatrix{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C::AbstractArray{T, 3}, A::SkewSymMatrix{T}, B::AbstractArray{T, 3}) where T</code></pre><p>Multiply skew-symmetric the matrix <code>A</code> onto the tensor <code>B</code> from the left and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays. </p><p>This performs an efficient multiplication based on the special structure of the skew-symmetric matrix <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL237-L245">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, SymmetricMatrix{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, SymmetricMatrix{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C::AbstractArray{T, 3}, A::SymmetricMatrix{T}, B::AbstractArray{T, 3}) where T</code></pre><p>Multiply the symmetric matrix <code>A</code> onto the tensor <code>B</code> from the left and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays. </p><p>This performs an efficient multiplication based on the special structure of the symmetric matrix <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL103-L111">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, UpperTriangular{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, UpperTriangular{T, AT} where AT&lt;:AbstractVector{T}, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C::AbstractArray{T, 3}, A::UpperTriangular{T}, B::AbstractArray{T, 3}) where T</code></pre><p>Multiply the upper-triangular matrix <code>A</code> onto the tensor <code>B</code> from the left and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays. </p><p>This performs an efficient multiplication based on the special structure of the upper-triangular matrix <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL191-L199">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by the adjoint of an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/multi_head_attention.jl#LL140-L142">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul(A::AbstractMatrix{T}, B::AbstractArray{T, 3}) where T</code></pre><p>Multipliy the matrix <code>A</code> onto the tensor <code>B</code> from the left. </p><p>Internally this calls the inplace version <a href="#GeometricMachineLearning.mat_tensor_mul!-Tuple{Any, Any, Any}"><code>mat_tensor_mul!</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning: mat_tensor_mul

B = [1 1 1; 1 1 1; 1 1 1;;; 2 2 2; 2 2 2; 2 2 2]
A = [3 0 0; 0 2 0; 0 0 1]

mat_tensor_mul(A, B)

# output

3×3×2 Array{Int64, 3}:
[:, :, 1] =
 3  3  3
 2  2  2
 1  1  1

[:, :, 2] =
 6  6  6
 4  4  4
 2  2  2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/mat_tensor_mul.jl#LL33-L63">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/layers/multi_head_attention.jl#LL147-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}" href="#GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">metric(Y::GrassmannManifold, Δ₁::AbstractMatrix, Δ₂::AbstractMatrix)</code></pre><p>Compute the metric for vectors <code>Δ₁</code> and <code>Δ₂</code> at <code>Y</code>. </p><p>The representation of the Grassmann manifold is realized as a quotient space of the Stiefel manifold. </p><p>The metric for the Grassmann manifold is:</p><p class="math-container">\[g^{Gr}_Y(\Delta_1, \Delta_2) = g^{St}_Y(\Delta_1, \Delta_2) = \mathrm{Tr}(\Delta_1^T (\mathbb{I} - Y Y^T) \Delta_2) = \mathrm{Tr}(\Delta_1^T \Delta_2).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/grassmann_manifold.jl#LL46-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}" href="#GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Implements the canonical Riemannian metric for the Stiefel manifold:</p><p class="math-container">\[g_Y: (\Delta_1, \Delta_2) \mapsto \mathrm{tr}(\Delta_1^T(\mathbb{I} - \frac{1}{2}YY^T)\Delta_2).\]</p><p>It is called with: </p><ul><li><code>Y::StiefelManifold</code></li><li><code>Δ₁::AbstractMatrix</code></li><li><code>Δ₂::AbstractMatrix</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/stiefel_manifold.jl#LL62-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.number_of_batches-Union{Tuple{OT}, Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT, OT, :TimeSeries}, Batch}} where {T, BT&lt;:AbstractArray{T, 3}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}, OT}" href="#GeometricMachineLearning.number_of_batches-Union{Tuple{OT}, Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT, OT, :TimeSeries}, Batch}} where {T, BT&lt;:AbstractArray{T, 3}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}, OT}"><code>GeometricMachineLearning.number_of_batches</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Gives the number of batches. Inputs are of type <code>DataLoader</code> and <code>Batch</code>.</p><p>Here the big distinction is between data that are <em>time-series like</em> and data that are <em>autoencoder like</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/batch.jl#LL46-L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer" href="#GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer"><code>GeometricMachineLearning.onehotbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><p>One-hot-batch encoding of a vector of integers: <span>$input\in\{0,1,\ldots,9\}^\ell$</span>.  The output is a tensor of shape <span>$10\times1\times\ell$</span>. </p><p class="math-container">\[0 \mapsto \begin{bmatrix} 1 &amp; 0 &amp; \ldots &amp; 0 \end{bmatrix}.\]</p><p>In more abstract terms: <span>$i \mapsto e_i$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/mnist_utils.jl#LL6-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, NamedTuple, NamedTuple, NamedTuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, NamedTuple, NamedTuple, NamedTuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">optimization_step!(o::Optimizer, λY::NamedTuple, ps::NamedTuple, dx::NamedTuple)</code></pre><p>Optimize a neural network consisting of a single <code>AbstractExplicitLayer</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL89-L93">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Tuple, Tuple, Tuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Tuple, Tuple, Tuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">optimization_step!(o::Optimizer, λY::Chain, ps::Tuple, dx::Tuple)</code></pre><p>Optimize a neural network built with <code>Chain</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL77-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Vararg{NamedTuple, 4}}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Vararg{NamedTuple, 4}}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">optimization_step!(o, λY, ps, cache, dx)</code></pre><p>Update the weights <code>ps</code> of a <code>layer</code> based on an <a href="#GeometricMachineLearning.Optimizer"><code>Optimizer</code></a>, a <code>cache</code> and first-order derivatives <code>dx</code>.</p><p>The derivatives <code>dx</code> here are usually obtained via an AD routine by differentiating a loss function, i.e. <code>dx</code> is <span>$\nabla_xL$</span>.</p><p>It is calling the function <a href="#AbstractNeuralNetworks.update!-Tuple{Any, Any, AbstractArray}"><code>update!</code></a> internally which has to be implemented for every <a href="#GeometricMachineLearning.OptimizerMethod"><code>OptimizerMethod</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/optimizer.jl#LL59-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT} where AT&lt;:Union{AbstractArray{T}, NamedTuple}, Batch, Union{typeof(GeometricMachineLearning.loss), GeometricMachineLearning.NetworkLoss}, Any}} where T" href="#GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT} where AT&lt;:Union{AbstractArray{T}, NamedTuple}, Batch, Union{typeof(GeometricMachineLearning.loss), GeometricMachineLearning.NetworkLoss}, Any}} where T"><code>GeometricMachineLearning.optimize_for_one_epoch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimize for an entire epoch. For this you have to supply: </p><ul><li>an instance of the optimizer.</li><li>the neural network model </li><li>the parameters of the model </li><li>the data (in form of <code>DataLoader</code>)</li><li>in instance of <code>Batch</code> that contains <code>batch_size</code> (and optionally <code>seq_length</code>)</li></ul><p>With the optional argument:</p><ul><li>the loss, which takes the <code>model</code>, the parameters <code>ps</code> and an instance of <code>DataLoader</code> as input.</li></ul><p>The output of <code>optimize_for_one_epoch!</code> is the average loss over all batches of the epoch:</p><p class="math-container">\[output = \frac{1}{\mathtt{steps\_per\_epoch}}\sum_{t=1}^\mathtt{steps\_per\_epoch}loss(\theta^{(t-1)}).\]</p><p>This is done because any <strong>reverse differentiation</strong> routine always has two outputs: a pullback and the value of the function it is differentiating. In the case of zygote: <code>loss_value, pullback = Zygote.pullback(ps -&gt; loss(ps), ps)</code> (if the loss only depends on the parameters).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/optimize.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer" href="#GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer"><code>GeometricMachineLearning.patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the batch index (for MNIST data set for now).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/mnist_utils.jl#LL22-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}" href="#GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rgrad(Y::GrassmannManifold, e_grad::AbstractMatrix)</code></pre><p>Compute the Riemannian gradient at <span>$Y\in{}Gr(n, N)$</span>. </p><p>These gradient have the property that they are orthogonal to the space spanned by <span>$Y$</span>.</p><p>The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - YY^T\nabla{}L\]</p><p>Note the property <span>$Y^T\mathrm{rgrad}(Y, \nabla{}L) = \mathbb{O}.$</span></p><p>Also see <a href="#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}"><code>rgrad(::StiefelManifold, ::AbstractMatrix)</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = GrassmannManifold([1 0 ; 0 1 ; 0 0; 0 0])
Δ = [1 2; 3 4; 5 6; 7 8]
rgrad(Y, Δ)

# output

4×2 Matrix{Int64}:
 0  0
 0  0
 5  6
 7  8</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/grassmann_manifold.jl#LL8-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}" href="#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rgrad(Y::StiefelManifold, e_grad::AbstractMatrix)</code></pre><p>Compute the Riemannian gradient for the Stiefel manifold at <span>$Y\in{}St(N,n)$</span> based on <span>$\nabla{}L\in\mathbb{R}^{N\times{}n}$</span> (the Euclidean gradient). </p><p>The function computes the Riemannian gradient with respect to the canonical <a href="#GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}"><code>metric</code></a>.</p><p>The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - Y(\nabla{}L)^TY\]</p><p>Note the property <span>$Y^T\mathrm{rgrad}(Y, \nabla{}L)\in\mathcal{S}_\mathrm{skew}(n).$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = StiefelManifold([1 0 ; 0 1 ; 0 0; 0 0])
Δ = [1 2; 3 4; 5 6; 7 8]
rgrad(Y, Δ)

# output

4×2 Matrix{Int64}:
 0  -1
 1   0
 5   6
 7   8</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/stiefel_manifold.jl#LL26-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}" href="#GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}"><code>GeometricMachineLearning.solve!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><a href="#GeometricMachineLearning.PSDArch">PSDArch</a> does not require neural network training since it is a strictly linear operation that can be solved with singular value decomposition (SVD).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/architectures/psd.jl#LL45-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T" href="#GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T"><code>GeometricMachineLearning.split_and_flatten</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>split_and_flatten</code> takes a tensor as input and produces another one as output (essentially rearranges the input data in an intricate way) so that it can easily be processed with a transformer.</p><p>The optional arguments are: </p><ul><li><code>patch_length</code>: by default this is 7. </li><li><code>number_of_patches</code>: by default this is 16.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/mnist_utils.jl#LL51-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_mul!-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.tensor_mat_mul!-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.tensor_mat_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tensor_mat_mul!(C, A, B)</code></pre><p>Multiply the matrix <code>B</code> onto the tensor <code>A</code> from the right and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays.</p><p>The function <a href="#GeometricMachineLearning.tensor_mat_mul-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractMatrix{T}}} where T"><code>tensor_mat_mul</code></a> calls <code>tensor_mat_mul!</code> internally.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/tensor_mat_mul.jl#LL14-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractArray{T, 3}, SymmetricMatrix{T, AT} where AT&lt;:AbstractVector{T}}} where T" href="#GeometricMachineLearning.tensor_mat_mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractArray{T, 3}, SymmetricMatrix{T, AT} where AT&lt;:AbstractVector{T}}} where T"><code>GeometricMachineLearning.tensor_mat_mul!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mat_tensor_mul!(C::AbstractArray{T, 3}, B::AbstractArray{T, 3}, A::SymmetricMatrix{T}) where T</code></pre><p>Multiply the symmetric matrix <code>A</code> onto the tensor <code>B</code> from the right and store the result in <code>C</code>.</p><p>Also checks the bounds of the input arrays.</p><p>This performs an efficient multiplication based on the special structure of the symmetric matrix <code>A</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/tensor_mat_mul.jl#LL106-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_mul-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.tensor_mat_mul-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.tensor_mat_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tensor_mat_mul(A::AbstractArray{T, 3}, B::AbstractArray{T}) where T</code></pre><p>Multipliy the matrix <code>B</code> onto the tensor <code>A</code> from the right. </p><p>Internally this calls the inplace version <a href="#GeometricMachineLearning.tensor_mat_mul!-Tuple{Any, Any, Any}"><code>tensor_mat_mul!</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning: tensor_mat_mul

A = [1 1 1; 1 1 1; 1 1 1;;; 2 2 2; 2 2 2; 2 2 2]
B = [3 0 0; 0 2 0; 0 0 1]

tensor_mat_mul(A, B)

# output

3×3×2 Array{Int64, 3}:
[:, :, 1] =
 3  2  1
 3  2  1
 3  2  1

[:, :, 2] =
 6  4  2
 6  4  2
 6  4  2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/tensor_mat_mul.jl#LL31-L61">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_skew_sym_assign-Union{Tuple{AT}, Tuple{T}, Tuple{AT, AbstractMatrix{T}}} where {T, AT&lt;:AbstractArray{T, 3}}" href="#GeometricMachineLearning.tensor_mat_skew_sym_assign-Union{Tuple{AT}, Tuple{T}, Tuple{AT, AbstractMatrix{T}}} where {T, AT&lt;:AbstractArray{T, 3}}"><code>GeometricMachineLearning.tensor_mat_skew_sym_assign</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input: </p><ul><li><code>Z::AbstractArray{T, 3}</code>: A tensor that stores a bunch of time series. </li><li><code>A::AbstractMatrix</code>: A matrix that is used to perform various scalar products. </li></ul><p>For one of these time series the function performs the following computation: </p><p class="math-container">\[    (z^{(i)}, z^{(j)}) \mapsto (z^{(i)})^TAz^{(j)} \text{ for } i &gt; j.\]</p><p>The result of this are <span>$n(n-2)\div2$</span> scalar products. These scalar products are written into a lower-triangular matrix and the final output of the function is a tensor of these lower-triangular matrices. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/inverses/tensor_mat_skew_sym_assign.jl#LL30-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!-Tuple{Any}" href="#GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!-Tuple{Any}"><code>GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>A kernel that computes the weighted scalar products of all combinations of vectors in the matrix <code>Z</code> except where the two vectors are the same and writes the result into a <em>tensor of skew symmetric matrices</em> <code>C</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/kernels/inverses/tensor_mat_skew_sym_assign.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!" href="#GeometricMachineLearning.train!"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train!(...)</code></pre><p>Perform a training of a neural networks on data using given method a training Method</p><p>Different ways of use:</p><pre><code class="nohighlight hljs">train!(neuralnetwork, data, optimizer = GradientOptimizer(1e-2), training_method; nruns = 1000, batch_size = default(data, type), showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data</code> : the data (see <a href="#GeometricMachineLearning.TrainingData"><code>TrainingData</code></a>)</li><li><code>optimizer = GradientOptimizer</code>: the optimization method (see <a href="#GeometricMachineLearning.Optimizer"><code>Optimizer</code></a>)</li><li><code>training_method</code> : specify the loss function used </li><li><code>nruns</code> : number of iteration through the process with default value </li><li><code>batch_size</code> : size of batch of data used for each step</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/training/train.jl#LL16-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}" href="#GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(neuralnetwork, data, optimizer, training_method; nruns = 1000, batch_size, showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data::AbstractTrainingData</code> : the data</li><li>``</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/training/train.jl#LL84-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer" href="#GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer"><code>GeometricMachineLearning.within_patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the index within the batch</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/data_loader/mnist_utils.jl#LL31-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.write_ones_kernel!-Tuple{Any}" href="#GeometricMachineLearning.write_ones_kernel!-Tuple{Any}"><code>GeometricMachineLearning.write_ones_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Kernel that is needed for functions relating to <code>SymmetricMatrix</code> and <code>SkewSymMatrix</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/utils.jl#LL74-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Ω(Y::GrassmannManifold{T}, Δ::AbstractMatrix{T}) where T</code></pre><p>Perform the <em>canonical horizontal lift</em> for the Grassmann manifold:</p><p class="math-container">\[    \Delta \mapsto \Omega^{St}(Y, Δ),\]</p><p>where <span>$\Omega^{St}$</span> is the canonical horizontal lift for the Stiefel manifold.</p><pre><code class="language-julia hljs">using GeometricMachineLearning
E = GrassmannManifold(StiefelProjection(5, 2))
Δ = [0. 0.; 0. 0.; 2. 3.; 4. 5.; 6. 7.]
GeometricMachineLearning.Ω(E, Δ)

# output

5×5 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0  -0.0  -2.0  -4.0  -6.0
 0.0   0.0  -3.0  -5.0  -7.0
 2.0   3.0   0.0  -0.0  -0.0
 4.0   5.0   0.0   0.0  -0.0
 6.0   7.0   0.0   0.0   0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/grassmann_manifold.jl#LL81-L107">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Ω(Y::StiefelManifold{T}, Δ::AbstractMatrix{T}) where T</code></pre><p>Perform <em>canonical horizontal lift</em> for the Stiefel manifold:</p><p class="math-container">\[    \Delta \mapsto (\mathbb{I} - \frac{1}{2}YY^T)\Delta{}Y^T - Y\Delta^T(\mathbb{I} - \frac{1}{2}YY^T).\]</p><p>Internally this performs </p><pre><code class="language-julia hljs">SkewSymMatrix(2 * (I(n) - .5 * Y * Y&#39;) * Δ * Y&#39;)</code></pre><p>to save memory. </p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
E = StiefelManifold(StiefelProjection(5, 2))
Δ = [0. -1.; 1. 0.; 2. 3.; 4. 5.; 6. 7.]
GeometricMachineLearning.Ω(E, Δ)

# output

5×5 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0  -1.0  -2.0  -4.0  -6.0
 1.0   0.0  -3.0  -5.0  -7.0
 2.0   3.0   0.0  -0.0  -0.0
 4.0   5.0   0.0   0.0  -0.0
 6.0   7.0   0.0   0.0   0.0</code></pre><p>Note that the output of <code>Ω</code> is a skew-symmetric matrix, i.e. an element of <span>$\mathfrak{g}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/manifolds/stiefel_manifold.jl#LL130-L166">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.𝔄-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.𝔄-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.𝔄</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">𝔄(A)</code></pre><p>Compute <span>$\mathfrak{A}(A) := \sum_{n=1}^\infty \frac{1}{n!} (A)^{n-1}.$</span></p><p><strong>Implementation</strong></p><p>This uses a Taylor expansion that iteratively adds terms with</p><pre><code class="language-julia hljs">while norm(Aⁿ) &gt; ε
    mul!(A_temp, Aⁿ, A)
    Aⁿ .= A_temp
    rmul!(Aⁿ, inv(n))

    𝔄 += B
    n += 1 
end</code></pre><p>until the norm of <code>Aⁿ</code> becomes smaller than machine precision.  The counter <code>n</code> in the above algorithm is initialized as <code>2</code> The matrices <code>Aⁿ</code> and <code>𝔄</code> are initialized as the identity matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/modified_exponential.jl#LL1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.𝔄-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.𝔄-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.𝔄</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">𝔄(B̂, B̄)</code></pre><p>Compute <span>$\mathfrak{A}(B&#39;, B&#39;&#39;) := \sum_{n=1}^\infty \frac{1}{n!} ((B&#39;&#39;)^TB&#39;)^{n-1}.$</span></p><p>This expression has the property <span>$\mathbb{I} +  B&#39;\mathfrak{A}(B&#39;, B&#39;&#39;)(B&#39;&#39;)^T = \exp(B&#39;(B&#39;&#39;)^T).$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: 𝔄
import Random
Random.seed!(123)

B = rand(StiefelLieAlgHorMatrix, 10, 2)
B̂ = hcat(vcat(.5 * B.A, B.B), vcat(one(B.A), zero(B.B)))
B̄ = hcat(vcat(one(B.A), zero(B.B)), vcat(-.5 * B.A, -B.B))

one(B̂ * B̄&#39;) + B̂ * 𝔄(B̂, B̄) * B̄&#39; ≈ exp(Matrix(B))

# output

true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/85b97ac236ad4b28e71692bdb59842240238dfe8/src/optimizers/manifold_related/modified_exponential.jl#LL42-L67">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../references/">« References</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Tuesday 18 June 2024 17:36">Tuesday 18 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
