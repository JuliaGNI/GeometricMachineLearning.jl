<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Library · GeometricMachineLearning.jl</title><meta name="title" content="Library · GeometricMachineLearning.jl"/><meta property="og:title" content="Library · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Library · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/library/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li></ul></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../manifolds/inverse_function_theorem/">The Inverse Function Theorem</a></li><li><a class="tocitem" href="../manifolds/submersion_theorem/">The Submersion Theorem</a></li><li><a class="tocitem" href="../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li><li><a class="tocitem" href="../manifolds/stiefel_manifold/">Stiefel</a></li><li><a class="tocitem" href="../manifolds/grassmann_manifold/">Grassmann</a></li><li><a class="tocitem" href="../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li></ul></li><li><span class="tocitem">Arrays</span><ul><li><a class="tocitem" href="../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../arrays/stiefel_lie_alg_horizontal/">Stiefel Global Tangent Space</a></li><li><a class="tocitem" href="../arrays/grassmann_lie_alg_hor_matrix/">Grassmann Global Tangent Space</a></li></ul></li><li><span class="tocitem">Optimizer Framework</span><ul><li><a class="tocitem" href="../Optimizer/">Optimizers</a></li><li><a class="tocitem" href="../optimizers/general_optimization/">General Optimization</a></li><li><a class="tocitem" href="../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Optimizer Functions</span><ul><li><a class="tocitem" href="../optimizers/manifold_related/horizontal_lift/">Horizontal Lift</a></li><li><a class="tocitem" href="../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../optimizers/manifold_related/geodesic/">Geodesic Retraction</a></li><li><a class="tocitem" href="../optimizers/manifold_related/cayley/">Cayley Retraction</a></li><li><a class="tocitem" href="../optimizers/adam_optimizer/">Adam Optimizer</a></li><li><a class="tocitem" href="../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../layers/multihead_attention_layer/">Multihead Attention</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../reduced_order_modeling/autoencoder/">POD and Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../tutorials/grassmann_layer/">Grassmann manifold</a></li><li><a class="tocitem" href="../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li class="is-active"><a class="tocitem" href>Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Library</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Library</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/library.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="GeometricMachineLearning-Library-Functions"><a class="docs-heading-anchor" href="#GeometricMachineLearning-Library-Functions">GeometricMachineLearning Library Functions</a><a id="GeometricMachineLearning-Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#GeometricMachineLearning-Library-Functions" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{GSympNet{AT, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{GSympNet{AT, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>Chain</code> can also be called with a neural network as input.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL57-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL113-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, false, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>false</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL95-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, false}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL76-L78">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT" href="#AbstractNeuralNetworks.Chain-Union{Tuple{LASympNet{AT, true, true}}, Tuple{AT}} where AT"><code>AbstractNeuralNetworks.Chain</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Build a chain for an LASympnet for which <code>init_upper_linear</code> is <code>true</code> and <code>init_upper_act</code> is <code>true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL131-L133">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractCache" href="#GeometricMachineLearning.AbstractCache"><code>GeometricMachineLearning.AbstractCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractCache has subtypes: </p><ul><li>AdamCache</li><li>MomentumCache</li><li>GradientCache</li><li>BFGSCache</li></ul><p>All of them can be initialized with providing an array (also supporting manifold types).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/optimizer_caches.jl#LL1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractLieAlgHorMatrix" href="#GeometricMachineLearning.AbstractLieAlgHorMatrix"><code>GeometricMachineLearning.AbstractLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>AbstractLieAlgHorMatrix</code> is a supertype for various horizontal components of Lie algebras. We usually call this <span>$\mathfrak{g}^\mathrm{hor}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/abstract_lie_algebra_horizontal.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractRetraction" href="#GeometricMachineLearning.AbstractRetraction"><code>GeometricMachineLearning.AbstractRetraction</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractRetraction is a type that comprises all retraction methods for manifolds. For every manifold layer one has to specify a retraction method that takes the layer and elements of the (global) tangent space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/manifold_related/retraction_types.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayer" href="#GeometricMachineLearning.ActivationLayer"><code>GeometricMachineLearning.ActivationLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>ActivationLayer</code> is the <code>struct</code> corresponding to the constructors <code>ActivationLayerQ</code> and <code>ActivationLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL28-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerP-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q \\ p + \mathrm{diag}(a)\sigma(q)
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL85-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}" href="#GeometricMachineLearning.ActivationLayerQ-Tuple{Any, Any}"><code>GeometricMachineLearning.ActivationLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Performs:</p><p class="math-container">\[\begin{pmatrix}
        q \\ p
\end{pmatrix} \mapsto 
\begin{pmatrix}
        q + \mathrm{diag}(a)\sigma(p) \\ p
\end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL68-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamOptimizer" href="#GeometricMachineLearning.AdamOptimizer"><code>GeometricMachineLearning.AdamOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines the Adam Optimizer. Algorithm and suggested defaults are taken from [<a href="../references/#goodfellow2016deep">27</a>] (page 301).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/adam_optimizer.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AdamOptimizerWithDecay" href="#GeometricMachineLearning.AdamOptimizerWithDecay"><code>GeometricMachineLearning.AdamOptimizerWithDecay</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines the Adam Optimizer with weight decay.</p><p><strong>Constructors</strong></p><p>The default constructor takes as input: </p><ul><li><code>n_epochs::Int</code></li><li><code>η₁</code>: the learning rate at the start </li><li><code>η₂</code>: the learning rate at the end </li><li><code>ρ₁</code>: the decay parameter for the first moment </li><li><code>ρ₂</code>: the decay parameter for the second moment</li><li><code>δ</code>: the safety parameter </li><li><code>T</code> (keyword argument): the type. </li></ul><p>The second constructor is called with: </p><ul><li><code>n_epochs::Int</code></li><li><code>T</code></li></ul><p>... the rest are keyword arguments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/adam_optimizer_with_learning_rate_decay.jl#LL1-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AutoEncoder" href="#GeometricMachineLearning.AutoEncoder"><code>GeometricMachineLearning.AutoEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The autoencoder architecture</strong></p><p>An autoencoder [<a href="../references/#goodfellow2016deep">27</a>] is a neural network consisting of an encoder <span>$\Psi^e$</span> and a decoder <span>$\Psi^d$</span>. In the simplest case they are trained on some data set <span>$\mathcal{D}$</span> to reduce the following error: </p><p class="math-container">\[||\Psi^d\circ\Psi^e(\mathcal{D}) - \mathcal{D}||,\]</p><p>which we call the <em>reconstruction error</em> or <em>autoencoder error</em> (see the docs for <a href="#GeometricMachineLearning.AutoEncoderLoss">AutoEncoderLoss</a>) and <span>$||\cdot||$</span> is some norm.</p><p><strong>Implementation details.</strong></p><p>Abstract <code>AutoEncoder</code> type. If a custom <code>&lt;:AutoEncoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code>, <code>n_encoder_blocks</code> and <code>n_decoder_blocks</code>. Further the routines <code>encoder</code>, <code>decoder</code>, <code>encoder_parameters</code> and <code>decoder_parameters</code> should be extended.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AutoEncoderLoss" href="#GeometricMachineLearning.AutoEncoderLoss"><code>GeometricMachineLearning.AutoEncoderLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This loss should always be used together with a neural network of type <a href="#GeometricMachineLearning.AutoEncoder">AutoEncoder</a> (and it is also the default for training such a network). </p><p>It simply computes: </p><p class="math-container">\[\mathtt{AutoEncoderLoss}(nn\mathtt{::Loss}, input) = ||nn(input) - input||.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/loss/losses.jl#LL61-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSCache" href="#GeometricMachineLearning.BFGSCache"><code>GeometricMachineLearning.BFGSCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The cache for the BFGS optimizer.</p><p>It stores an array for the previous time step <code>B</code> and the inverse of the Hessian matrix <code>H</code>.</p><p>It is important to note that setting up this cache already requires a derivative! This is not the case for the other optimizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/bfgs_cache.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSDummyCache" href="#GeometricMachineLearning.BFGSDummyCache"><code>GeometricMachineLearning.BFGSDummyCache</code></a> — <span class="docstring-category">Type</span></header><section><div><p>In order to initialize <code>BGGSCache</code> we first need gradient information. This is why we initially have this <code>BFGSDummyCache</code> until gradient information is available.</p><p>NOTE: we may not need this. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/bfgs_cache.jl#LL17-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BFGSOptimizer" href="#GeometricMachineLearning.BFGSOptimizer"><code>GeometricMachineLearning.BFGSOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is an implementation of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) optimizer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/bfgs_optimizer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Batch" href="#GeometricMachineLearning.Batch"><code>GeometricMachineLearning.Batch</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>Batch</code> is a struct whose functor acts on an instance of <code>DataLoader</code> to produce a sequence of training samples for training for one epoch. </p><p><strong>The Constructor</strong></p><p>The constructor for <code>Batch</code> is called with: </p><ul><li><code>batch_size::Int</code></li><li><code>seq_length::Int</code> (optional)</li><li><code>prediction_window::Int</code> (optional)</li></ul><p>The first one of these arguments is required; it indicates the number of training samples in a batch. If we deal with time series data then we can additionaly supply a <em>sequence length</em> and a <em>prediction window</em> as input arguments to <code>Batch</code>. These indicate the number of input vectors and the number of output vectors.</p><p><strong>The functor</strong></p><p>An instance of <code>Batch</code> can be called on an instance of <code>DataLoader</code> to produce a sequence of samples that contain all the input data, i.e. for training for one epoch. The output of applying <code>batch:Batch</code> to <code>dl::DataLoader</code> is a tuple of vectors of integers. Each of these vectors contains two integers: the first is the <em>time index</em> and the second one is the <em>parameter index</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/batch.jl#LL18-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.BiasLayer" href="#GeometricMachineLearning.BiasLayer"><code>GeometricMachineLearning.BiasLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <em>bias layer</em> that does nothing more than add a vector to the input. This is needed for <em>LA-SympNets</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/bias_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Classification" href="#GeometricMachineLearning.Classification"><code>GeometricMachineLearning.Classification</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Classification Layer that takes a matrix as an input and returns a vector that is used for MNIST classification. </p><p>It has the following arguments: </p><ul><li><code>M</code>: input dimension </li><li><code>N</code>: output dimension </li><li><code>activation</code>: the activation function </li></ul><p>And the following optional argument: </p><ul><li><code>average</code>: If this is set to <code>true</code>, then the output is computed as <span>$\frac{1}{N}\sum_{i=1}^N[input]_{\bullet{}i}$</span>. If set to <code>false</code> (the default) it picks the last column of the input. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/classification.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ClassificationTransformer" href="#GeometricMachineLearning.ClassificationTransformer"><code>GeometricMachineLearning.ClassificationTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a transformer neural network for classification purposes. At the moment this is only used for training on MNIST, but can in theory be used for any classification problem.</p><p>It has to be called with a <code>DataLoader</code> that stores an input and an output tensor. The optional arguments are: </p><ul><li><code>n_heads</code>: The number of heads in the <code>MultiHeadAttention</code> (mha) layers. Default: <code>7</code>.</li><li><code>n_layers</code>: The number of transformer layers. Default: <code>16</code>.</li><li><code>activation</code>: The activation function. Default: <code>softmax</code>.</li><li><code>Stiefel</code>: Wheter the matrices in the mha layers are on the <strong>Stiefel manifold</strong>. </li><li><code>add_connection</code>: Whether the input is appended to the output of the mha layer. (skip connection)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/transformer_neural_network.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader" href="#GeometricMachineLearning.DataLoader"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p><strong>Constructor</strong></p><p>The data loader can be called with various inputs:</p><ul><li><strong>A single vector</strong>: If the data loader is called with a single vector (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the second axis indicates parameter values and/or time steps and the system has a single degree of freedom (i.e. the system dimension is one).</li><li><strong>A single matrix</strong>: If the data loader is called with a single matrix (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the first axis is assumed to indicate the degrees of freedom of the system and the second axis indicates parameter values and/or time steps. </li><li><strong>A single tensor</strong>: If the data loader is called with a single tensor, then this is interpreted as an <em>integration problem</em> with the second axis indicating the time step and the third one indicating the parameters.</li><li><strong>A tensor and a vector</strong>: This is a special case (MNIST classification problem). For the MNIST problem for example the input are <span>$n_p$</span> matrices (first input argument) and <span>$n_p$</span> integers (second input argument).</li><li><strong>A <code>NamedTuple</code> with fields <code>q</code> and <code>p</code></strong>: The <code>NamedTuple</code> contains (i) two matrices or (ii) two tensors. </li><li><strong>An <code>EnsembleSolution</code></strong>: The <code>EnsembleSolution</code> typically comes from <code>GeometricProblems</code>.</li></ul><p>When we supply a single vector or a single matrix as input to <code>DataLoader</code> and further set <code>autoencoder = false</code> (keyword argument), then the data are stored as an <em>integration problem</em> and the second axis is assumed to indicate time steps.</p><p><strong>Fields of <code>DataLoader</code></strong></p><p>The fields of the <code>DataLoader</code> struct are the following: </p><ul><li><code>input</code>: The input data with axes (i) system dimension, (ii) number of time steps and (iii) number of parameters.</li><li><code>output</code>: The tensor that contains the output (supervised learning) - this may be of type <code>Nothing</code> if the constructor is only called with one tensor (unsupervised learning).</li><li><code>input_dim</code>: The <em>dimension</em> of the system, i.e. what is taken as input by a regular neural network.</li><li><code>input_time_steps</code>: The length of the entire time series (length of the second axis).</li><li><code>n_params</code>: The number of parameters that are present in the data set (length of third axis)</li><li><code>output_dim</code>: The dimension of the output tensor (first axis). If <code>output</code> is of type <code>Nothing</code>, then this is also of type <code>Nothing</code>.</li><li><code>output_time_steps</code>: The size of the second axis of the output tensor. If <code>output</code> is of type <code>Nothing</code>, then this is also of type <code>Nothing</code>.</li></ul><p><strong>The <code>input</code> and <code>output</code> fields of <code>DataLoader</code></strong></p><p>Even though the arguments to the Constructor may be vectors or matrices, internally <code>DataLoader</code> always stores tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/data_loader.jl#LL17-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{@NamedTuple{q::AT, p::AT}}, Tuple{AT}, Tuple{T}} where {T, AT&lt;:AbstractMatrix{T}}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Data Loader is a struct that creates an instance based on a tensor (or different input format) and is designed to make training convenient. </p><p><strong>Constructor</strong></p><p>The data loader can be called with various inputs:</p><ul><li><strong>A single vector</strong>: If the data loader is called with a single vector (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the second axis indicates parameter values and/or time steps and the system has a single degree of freedom (i.e. the system dimension is one).</li><li><strong>A single matrix</strong>: If the data loader is called with a single matrix (and no other arguments are given), then this is interpreted as an autoencoder problem, i.e. the first axis is assumed to indicate the degrees of freedom of the system and the second axis indicates parameter values and/or time steps. </li><li><strong>A single tensor</strong>: If the data loader is called with a single tensor, then this is interpreted as an <em>integration problem</em> with the second axis indicating the time step and the third one indicating the parameters.</li><li><strong>A tensor and a vector</strong>: This is a special case (MNIST classification problem). For the MNIST problem for example the input are <span>$n_p$</span> matrices (first input argument) and <span>$n_p$</span> integers (second input argument).</li><li><strong>A <code>NamedTuple</code> with fields <code>q</code> and <code>p</code></strong>: The <code>NamedTuple</code> contains (i) two matrices or (ii) two tensors. </li><li><strong>An <code>EnsembleSolution</code></strong>: The <code>EnsembleSolution</code> typically comes from <code>GeometricProblems</code>.</li></ul><p>When we supply a single vector or a single matrix as input to <code>DataLoader</code> and further set <code>autoencoder = false</code> (keyword argument), then the data are stored as an <em>integration problem</em> and the second axis is assumed to indicate time steps.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/data_loader.jl#LL86-L100">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT, ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT}})}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT, ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT}})}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Constructor for <code>EnsembleSolution</code> from package <code>GeometricSolutions</code> with field <code>q</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/data_loader.jl#LL149-L151">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT&lt;:(GeometricSolutions.DataSeries{T, AT} where AT&lt;:Union{AbstractArray{T}, T}), ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT, p::DT}})}" href="#GeometricMachineLearning.DataLoader-Union{Tuple{GeometricSolutions.EnsembleSolution{T, T1, Vector{ST}}}, Tuple{ST}, Tuple{DT}, Tuple{T1}, Tuple{T}} where {T, T1, DT&lt;:(GeometricSolutions.DataSeries{T, AT} where AT&lt;:Union{AbstractArray{T}, T}), ST&lt;:(GeometricSolutions.GeometricSolution{T, T1, @NamedTuple{q::DT, p::DT}})}"><code>GeometricMachineLearning.DataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Constructor for <code>EnsembleSolution</code> form package <code>GeometricSolutions</code> with fields <code>q</code> and <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/data_loader.jl#LL112-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Decoder" href="#GeometricMachineLearning.Decoder"><code>GeometricMachineLearning.Decoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract <code>Decoder</code> type. If a custom <code>&lt;:Decoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_decoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL23-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Encoder" href="#GeometricMachineLearning.Encoder"><code>GeometricMachineLearning.Encoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract <code>Encoder</code> type. If a custom <code>&lt;:Encoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_encoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL18-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GSympNet" href="#GeometricMachineLearning.GSympNet"><code>GeometricMachineLearning.GSympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GSympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>upscaling_dimension::Int</code>: The <em>upscaling dimension</em> of the gradient layer. See the documentation for <code>GradientLayerQ</code> and <code>GradientLayerP</code> for further explanation. The default is <code>2*dim</code>.</li><li><code>nhidden::Int</code>: The number of hidden layers (i.e. layers that are <strong>not</strong> input or output layers). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper::Bool</code>: Initialize the gradient layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL34-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GlobalSection" href="#GeometricMachineLearning.GlobalSection"><code>GeometricMachineLearning.GlobalSection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This implements global sections for the Stiefel manifold and the Symplectic Stiefel manifold. </p><p>In practice this is implemented using Householder reflections, with the auxiliary column vectors given by:  |0| |0| |.| |1| ith spot for i in (n+1) to N (or with random columns) |0| |.| |0|</p><p>Maybe consider dividing the output in the check functions by n!</p><p>Implement a general global section here!!!! Tₓ𝔐 → G×𝔤 !!!!!! (think about random initialization!)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/manifold_related/global_sections.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayer" href="#GeometricMachineLearning.GradientLayer"><code>GeometricMachineLearning.GradientLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GradientLayer</code> is the <code>struct</code> corresponding to the constructors <code>GradientLayerQ</code> and <code>GradientLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL8-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerP-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.GradientLayerP-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.GradientLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \mathbb{O} \\ \nabla{}V &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL53-L63">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientLayerQ-Tuple{Any, Any, Any}" href="#GeometricMachineLearning.GradientLayerQ-Tuple{Any, Any, Any}"><code>GeometricMachineLearning.GradientLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The gradient layer that changes the <span>$q$</span> component. It is of the form: </p><p class="math-container">\[\begin{bmatrix}
        \mathbb{I} &amp; \nabla{}V \\ \mathbb{O} &amp; \mathbb{I} 
\end{bmatrix},\]</p><p>with <span>$V(p) = \sum_{i=1}^Ma_i\Sigma(\sum_jk_{ij}p_j+b_i)$</span>, where <span>$\Sigma$</span> is the antiderivative of the activation function <span>$\sigma$</span> (one-layer neural network). We refer to <span>$M$</span> as the <em>upscaling dimension</em>. Such layers are by construction symplectic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL38-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GradientOptimizer" href="#GeometricMachineLearning.GradientOptimizer"><code>GeometricMachineLearning.GradientOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Define the Gradient optimizer, i.e. W ← W - η*∇f(W) Or the riemannian manifold equivalent, if applicable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/gradient_optimizer.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLayer" href="#GeometricMachineLearning.GrassmannLayer"><code>GeometricMachineLearning.GrassmannLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Grassmann manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/grassmann_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This implements the horizontal component of a Lie algebra that is isomorphic to the Grassmann manifold. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/grassmann_lie_algebra_horizontal.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannManifold" href="#GeometricMachineLearning.GrassmannManifold"><code>GeometricMachineLearning.GrassmannManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>GrassmannManifold</code> is based on the <code>StiefelManifold</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/manifolds/grassmann_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.HRedSys" href="#GeometricMachineLearning.HRedSys"><code>GeometricMachineLearning.HRedSys</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>HRedSys</code> computes the reconstructed dynamics in the full system based on the reduced one. Optionally it can be compared to the FOM solution.</p><p>It can be called using the following constructor: <code>HRedSys(N, n; encoder, decoder, v_full, f_full, v_reduced, f_reduced, parameters, tspan, tstep, ics, projection_error)</code> where </p><ul><li><code>encoder</code>: a function <span>$\mathbb{R}^{2N}\mapsto{}\mathbb{R}^{2n}$</span></li><li><code>decoder</code>: a (differentiable) function <span>$\mathbb{R}^{2n}\mapsto\mathbb{R}^{2N}$</span></li><li><code>v_full</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>f_full</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>v_reduced</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>f_reduced</code>: a (differentiable) mapping defined the same way as in GeometricIntegrators.</li><li><code>parameters</code>: a NamedTuple that parametrizes the vector fields (the same for full<em>vector</em>field and reduced<em>vector</em>field)</li><li><code>tspan</code>: a tuple <code>(t₀, tₗ)</code> that specifies start and end point of the time interval over which integration is performed. </li><li><code>tstep</code>: the time step </li><li><code>ics</code>: the initial condition for the big system.</li><li><code>projection_error</code>: the error <span>$||M - \mathcal{R}\circ\mathcal{P}(M)||$</span> where <span>$M$</span> is the snapshot matrix; <span>$\mathcal{P}$ and $\mathcal{R}$</span> are the reduction and reconstruction respectively.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/reduced_system/reduced_system.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LASympNet" href="#GeometricMachineLearning.LASympNet"><code>GeometricMachineLearning.LASympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LASympNet</code> is called with <strong>a single input argument</strong>, the <strong>system dimension</strong>, or with an instance of <code>DataLoader</code>. Optional input arguments are: </p><ul><li><code>depth::Int</code>: The number of linear layers that are applied. The default is 5.</li><li><code>nhidden::Int</code>: The number of hidden layers (i.e. layers that are <strong>not</strong> input or output layers). The default is 2.</li><li><code>activation</code>: The activation function that is applied. By default this is <code>tanh</code>.</li><li><code>init_upper_linear::Bool</code>: Initialize the linear layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li><li><code>init_upper_act::Bool</code>: Initialize the activation layer so that it first modifies the <span>$q$</span>-component. The default is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL9-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LayerWithManifold" href="#GeometricMachineLearning.LayerWithManifold"><code>GeometricMachineLearning.LayerWithManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Additional types to make handling manifolds more readable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/manifold_related/retractions.jl#LL9-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayer" href="#GeometricMachineLearning.LinearLayer"><code>GeometricMachineLearning.LinearLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>LinearLayer</code> is the <code>struct</code> corresponding to the constructors <code>LinearLayerQ</code> and <code>LinearLayerP</code>. See those for more information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerP-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerP-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerP</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; \mathbb{O} \\ 
B &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL117-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LinearLayerQ-Tuple{Any}" href="#GeometricMachineLearning.LinearLayerQ-Tuple{Any}"><code>GeometricMachineLearning.LinearLayerQ</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Equivalent to a left multiplication by the matrix:</p><p class="math-container">\[\begin{pmatrix}
\mathbb{I} &amp; B \\ 
\mathbb{O} &amp; \mathbb{I}
\end{pmatrix}, \]</p><p>where <span>$B$</span> is a symmetric matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL103-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.LowerTriangular" href="#GeometricMachineLearning.LowerTriangular"><code>GeometricMachineLearning.LowerTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A lower-triangular matrix is an <span>$n\times{}n$</span> matrix that has ones on the diagonal and zeros on the upper triangular.</p><p>The data are stored in a vector <span>$S$</span> similarly to <code>SkewSymMatrix</code>.</p><p>The struct two fields: <code>S</code> and <code>n</code>. The first stores all the entries of the matrix in a sparse fashion (in a vector) and the second is the dimension <span>$n$</span> for <span>$A\in\mathbb{R}^{n\times{}n}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/lower_triangular.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Manifold" href="#GeometricMachineLearning.Manifold"><code>GeometricMachineLearning.Manifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>rand</code> is implemented for manifolds that use the initialization of the <code>StiefelManifold</code> and the <code>GrassmannManifold</code> by default. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/manifolds/abstract_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.ManifoldLayer" href="#GeometricMachineLearning.ManifoldLayer"><code>GeometricMachineLearning.ManifoldLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This defines a manifold layer that only has one matrix-valued manifold <span>$A$</span> associated with it does <span>$x\mapsto{}Ax$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/manifold_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MomentumOptimizer" href="#GeometricMachineLearning.MomentumOptimizer"><code>GeometricMachineLearning.MomentumOptimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Define the Momentum optimizer, i.e.  V ← α<em>V - ∇f(W) W ← W + η</em>V Or the riemannian manifold equivalent, if applicable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/momentum_optimizer.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.MultiHeadAttention" href="#GeometricMachineLearning.MultiHeadAttention"><code>GeometricMachineLearning.MultiHeadAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p>MultiHeadAttention (MHA) serves as a preprocessing step in the transformer. It reweights the input vectors bases on correlations within those data. </p><p><strong>Constructor</strong></p><p>Takes input arguments: </p><ul><li><code>dim::Int</code>: The system dimension </li><li><code>n_heads::Int</code>: The number of heads. </li><li><code>Stiefel::Bool=true</code> (keyword argument): whether the weights should be put on the Stiefel manifold. </li><li><code>retraction::AbstractRetraction</code> (keyword argument): what kind of retraction should be used. By default this is the geodesic retraction. </li><li><code>add_connection::Bool=true</code> (keyword argument): determines if the input should be added to the output for the final result. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/multi_head_attention.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer" href="#GeometricMachineLearning.Optimizer"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Optimizer struct that stores the &#39;method&#39; (i.e. Adam with corresponding hyperparameters), the cache and the optimization step.</p><p>It takes as input an optimization method and the parameters of a network. </p><p>For <em>technical reasons</em> we first specify an OptimizerMethod that stores all the hyperparameters of the optimizer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/optimizer.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, GeometricMachineLearning.NetworkLoss}" href="#GeometricMachineLearning.Optimizer-Tuple{NeuralNetwork, DataLoader, Batch, Int64, GeometricMachineLearning.NetworkLoss}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>A functor for <code>Optimizer</code>. It is called with:     - <code>nn::NeuralNetwork</code>     - <code>dl::DataLoader</code>     - <code>batch::Batch</code>     - <code>n_epochs::Int</code>     - <code>loss</code></p><p>The last argument is a function through which <code>Zygote</code> differentiates. This argument is optional; if it is not supplied <code>GeometricMachineLearning</code> defaults to an appropriate loss for the <code>DataLoader</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/optimize.jl#LL50-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}" href="#GeometricMachineLearning.Optimizer-Tuple{OptimizerMethod, NeuralNetwork}"><code>GeometricMachineLearning.Optimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Typically the Optimizer is not initialized with the network parameters, but instead with a NeuralNetwork struct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/optimizer.jl#LL18-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.PSDArch" href="#GeometricMachineLearning.PSDArch"><code>GeometricMachineLearning.PSDArch</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The architecture</strong></p><p>Proper symplectic decomposition (PSD) can be seen as a <a href="#GeometricMachineLearning.SymplecticAutoencoder">SymplecticAutoencoder</a> for which the decoder and the encoder are both PSD-like matrices (see the docs for <a href="#GeometricMachineLearning.PSDLayer">PSDLayer</a>. </p><p><strong>Training</strong></p><p>For optimizing the parameters in this architecture no neural network training is necessary (see the docs for <a href="#GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}">solve!</a>).</p><p><strong>The constructor</strong></p><p>The constructor only takes two arguments as input:</p><ul><li><code>full_dim::Integer</code></li><li><code>reduced_dim::Integer</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/psd.jl#LL1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.PSDLayer" href="#GeometricMachineLearning.PSDLayer"><code>GeometricMachineLearning.PSDLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This is a PSD-like layer used for symplectic autoencoders.  One layer has the following shape:</p><p class="math-container">\[A = \begin{bmatrix} \Phi &amp; \mathbb{O} \\ \mathbb{O} &amp; \Phi \end{bmatrix},\]</p><p>where <span>$\Phi$</span> is an element of the Stiefel manifold <span>$St(n, N)$</span>.</p><p>The constructor of PSDLayer is called by <code>PSDLayer(M, N; retraction=retraction)</code>: </p><ul><li><code>M</code> is the input dimension.</li><li><code>N</code> is the output dimension. </li><li><code>retraction</code> is an instance of a struct with supertype <code>AbstractRetraction</code>. The only options at the moment are <code>Geodesic()</code> and <code>Cayley()</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/psd_like_layer.jl#LL1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.RegularTransformerIntegrator" href="#GeometricMachineLearning.RegularTransformerIntegrator"><code>GeometricMachineLearning.RegularTransformerIntegrator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The regular transformer used as an integrator (multi-step method). </p><p>The constructor is called with the following arguments: </p><ul><li><code>sys_dim::Int</code></li><li><code>transformer_dim::Int</code>: the default is <code>transformer_dim = sys_dim</code>.</li><li><code>n_blocks::Int</code>: The default is <code>1</code>.</li><li><code>n_heads::Int</code>: the number of heads in the multihead attentio layer (default is <code>n_heads = sys_dim</code>)</li><li><code>L::Int</code> the number of transformer blocks (default is <code>L = 2</code>).</li><li><code>upscaling_activation</code>: by default identity</li><li><code>resnet_activation</code>: by default tanh</li><li><code>add_connection:Bool=true</code> (keyword argument): if the input should be added to the output.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/regular_transformer_integrator.jl#LL1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SkewSymMatrix" href="#GeometricMachineLearning.SkewSymMatrix"><code>GeometricMachineLearning.SkewSymMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <code>SkewSymMatrix</code> is a matrix <span>$A$</span> s.t. <span>$A^T = -A$</span>.</p><p>If the constructor is called with a matrix as input it returns a symmetric matrix via the projection <span>$A \mapsto \frac{1}{2}(A - A^T)$</span>.  This is a projection defined via the canonical metric <span>$\mathbb{R}^{n\times{}n}\times\mathbb{R}^{n\times{}n}\to\mathbb{R}, (A,B) \mapsto \mathrm{Tr}(A^TB)$</span>.</p><p>The first index is the row index, the second one the column index.</p><p>The struct two fields: <code>S</code> and <code>n</code>. The first stores all the entries of the matrix in a sparse fashion (in a vector) and the second is the dimension <span>$n$</span> for <span>$A\in\mathbb{R}^{n\times{}n}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/skew_symmetric.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLayer" href="#GeometricMachineLearning.StiefelLayer"><code>GeometricMachineLearning.StiefelLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines a layer that performs simple multiplication with an element of the Stiefel manifold.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/stiefel_layer.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>StiefelLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric). The projection here is: (\pi:S \to SE ) where </p><p class="math-container">\[E = \begin{pmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{pmatrix}.\]</p><p>The matrix (E) is implemented under <code>StiefelProjection</code> in <code>GeometricMachineLearning</code>.</p><p>An element of StiefelLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where (A) is skew-symmetric (this is <code>SkewSymMatrix</code> in <code>GeometricMachineLearning</code>).</p><p>If the constructor is called with a big (N\times{}N) matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\mathrm{skew}(A) &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>The operation <span>$\mathrm{skew}:\mathbb{R}^{n\times{}n}\to\mathcal{S}_\mathrm{skew}(n)$</span> is the skew-symmetrization operation. This is equivalent to calling the constructor of <code>SkewSymMatrix</code> with an (n\times{}n) matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/stiefel_lie_algebra_horizontal.jl#LL1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelManifold" href="#GeometricMachineLearning.StiefelManifold"><code>GeometricMachineLearning.StiefelManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An implementation of the Stiefel manifold. It has various convenience functions associated with it:</p><ul><li>check </li><li>rand </li><li>rgrad</li><li>metric</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/manifolds/stiefel_manifold.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Outer constructor for <code>StiefelProjection</code>. This works with two integers as input and optionally the type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/stiefel_projection.jl#LL39-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelProjection" href="#GeometricMachineLearning.StiefelProjection"><code>GeometricMachineLearning.StiefelProjection</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An array that essentially does <code>vcat(I(n), zeros(N-n, n))</code> with GPU support. It has <strong>three inner constructors</strong>. The <strong>first one</strong> is called with the following arguments: </p><ol><li><code>backend</code>: backends as supported by <code>KernelAbstractions</code>.</li><li><code>T::Type</code></li><li><code>N::Integer</code></li><li><code>n::Integer</code></li></ol><p>The <strong>second constructor</strong> is called by supplying a matrix as input. The constructor will then extract the backend, the type and the dimensions of that matrix. </p><p>The <strong>third constructor</strong> is called by supplying an instance of <code>StiefelLieAlgHorMatrix</code>.  </p><p>Technically this should be a subtype of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/stiefel_projection.jl#LL1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymmetricMatrix" href="#GeometricMachineLearning.SymmetricMatrix"><code>GeometricMachineLearning.SymmetricMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A <code>SymmetricMatrix</code> <span>$A$</span> is a matrix <span>$A^T = A$</span>.</p><p>If the constructor is called with a matrix as input it returns a symmetric matrix via the projection:</p><p class="math-container">\[A \mapsto \frac{1}{2}(A + A^T).\]</p><p>This is a projection defined via the canonical metric <span>$(A,B) \mapsto \mathrm{tr}(A^TB)$</span>.</p><p>Internally the <code>struct</code> saves a vector <span>$S$</span> of size <span>$n(n+1)\div2$</span>. The conversion is done the following way: </p><p class="math-container">\[[A]_{ij} = \begin{cases} S[( (i-1) i ) \div 2 + j] &amp; \text{if $i\geq{}j$}\\ 
                         S[( (j-1) j ) \div 2 + i] &amp; \text{else}. \end{cases}\]</p><p>So <span>$S$</span> stores a string of vectors taken from <span>$A$</span>: <span>$S = [\tilde{a}_1, \tilde{a}_2, \ldots, \tilde{a}_n]$</span> with <span>$\tilde{a}_i = [[A]_{i1},[A]_{i2},\ldots,[A]_{ii}]$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/symmetric.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNet" href="#GeometricMachineLearning.SympNet"><code>GeometricMachineLearning.SympNet</code></a> — <span class="docstring-category">Type</span></header><section><div><p>SympNet type encompasses GSympNets and LASympnets.</p><p>TODO:  -[ ] add bias to <code>LASympNet</code>!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/sympnet.jl#LL1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer" href="#GeometricMachineLearning.SympNetLayer"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Implements the various layers from the SympNet paper: (https://www.sciencedirect.com/science/article/abs/pii/S0893608020303063). This is a super type of <code>Gradient</code>, <code>Activation</code> and <code>Linear</code>.</p><p>For the linear layer, the activation and the bias are left out, and for the activation layer <span>$K$</span> and <span>$b$</span> are left out!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, Any}" href="#GeometricMachineLearning.SympNetLayer-Tuple{AbstractArray, Any}"><code>GeometricMachineLearning.SympNetLayer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This is called when a SympnetLayer is applied to a <code>NamedTuple</code>. It calls <code>apply_layer_to_nt_and_return_array</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL247-L249">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymplecticAutoencoder" href="#GeometricMachineLearning.SymplecticAutoencoder"><code>GeometricMachineLearning.SymplecticAutoencoder</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>The architecture</strong></p><p>The symplectic autoencoder architecture was introduced in [<a href="../references/#brantner2023symplectic">28</a>]. Like any other autoencoder it consists of an <em>encoder</em> <span>$\Psi^e:\mathbb{R}^{2N}\to\mathbb{R}^{2n}$</span> and a <em>decoder</em> <span>$\Psi^d:\mathbb{R}^{2n}\to\mathbb{R}^{2N}$</span> with <span>$n\ll{}N$</span>. These satisfy the following properties: </p><p class="math-container">\[\nabla_z\Psi^e\mathbb{J}_{2N}(\nabla_z\Psi^e\mathbb{J}_{2N})^T = \mathbb{J}_{2n} \text{ and } (\nabla_\xi\Psi^d)^T\mathbb{J}_{2N}\nabla_\xi\Psi^d = \mathbb{J}_{2n}.\]</p><p>Because the decoder has this particular property, the reduced system can be described by the Hamiltonian <span>$H\circ\Psi^d$</span>: </p><p class="math-container">\[\mathbb{J}_{2n}\nabla_\xi(H\circ\Psi^d) = \mathbb{J}_{2n}(\nabla_\xi\Psi^d)^T\nabla_{\Psi^d(\xi)}H = \mathbb{J}_{2n}(\nabla_\xi\Psi^d)^T\mathbb{J}_{2N}^T\mathbb{J}_{2N}\nabla_{\Psi^d(\xi)}H = (\nabla_\xi\Psi^d)^+X_H(\Psi^d(\xi)),\]</p><p>where <span>$(\nabla_\xi\Psi^d)^+$</span> is the pseudoinverse of <span>$\nabla_\xi\Psi^d$</span> (for more details see the docs on the <a href="#GeometricMachineLearning.AutoEncoder">AutoEncoder</a> type).</p><p><strong>The constructor</strong></p><p>The constructor is called with</p><ul><li><code>full_dim::Integer</code> </li><li><code>reduced_dim::Integer</code> </li><li><code>n_encoder_layers::Integer = 4</code> (keyword argument)</li><li><code>n_encoder_blocks::Integer = 2</code> (keyword argument)</li><li><code>n_decoder_layers::Integer = 1</code> (keyword argument)</li><li><code>n_decoder_blocks::Integer = 3</code> (keyword argument)</li><li><code>sympnet_upscale::Integer = 5</code> (keyword argument)</li><li><code>activation = tanh</code> (keyword argument)</li><li><code>encoder_init_q::Bool = true</code> (keyword argument)</li><li><code>decoder_init_q::Bool = true</code> (keyword argument)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/symplectic_autoencoder.jl#LL1-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.SymplecticPotential" href="#GeometricMachineLearning.SymplecticPotential"><code>GeometricMachineLearning.SymplecticPotential</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>SymplecticPotential(n)</code></p><p>Returns a symplectic matrix of size 2n x 2n</p><p class="math-container">\[\begin{pmatrix}
\mathbb{O} &amp; \mathbb{I} \\
\mathbb{O} &amp; -\mathbb{I} \\
\end{pmatrix}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/symplectic.jl#LL2-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TrainingData" href="#GeometricMachineLearning.TrainingData"><code>GeometricMachineLearning.TrainingData</code></a> — <span class="docstring-category">Type</span></header><section><div><p>TrainingData stores: </p><pre><code class="nohighlight hljs"> - problem 

 - shape 

 - get 

 - symbols 

 - dim 

 - noisemaker</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data/data_training.jl#LL4-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TransformerIntegrator" href="#GeometricMachineLearning.TransformerIntegrator"><code>GeometricMachineLearning.TransformerIntegrator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Encompasses various transformer architectures, such as the structure-preserving transformer and the linear symplectic transformer. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/transformer_integrator.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.TransformerLoss" href="#GeometricMachineLearning.TransformerLoss"><code>GeometricMachineLearning.TransformerLoss</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The loss for a transformer network (especially a transformer integrator). The constructor is called with:</p><ul><li><code>seq_length::Int</code></li><li><code>prediction_window::Int</code> (default is 1).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/loss/losses.jl#LL20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.UpperTriangular" href="#GeometricMachineLearning.UpperTriangular"><code>GeometricMachineLearning.UpperTriangular</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An upper-triangular matrix is an <span>$n\times{}n$</span> matrix that has ones on the diagonal and zeros on the upper triangular.</p><p>The data are stored in a vector <span>$S$</span> similarly to <code>SkewSymMatrix</code>.</p><p>The struct two fields: <code>S</code> and <code>n</code>. The first stores all the entries of the matrix in a sparse fashion (in a vector) and the second is the dimension <span>$n$</span> for <span>$A\in\mathbb{R}^{n\times{}n}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/upper_triangular.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingAttention" href="#GeometricMachineLearning.VolumePreservingAttention"><code>GeometricMachineLearning.VolumePreservingAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>Volume-preserving attention (single head attention)</strong></p><p>Drawbacks: </p><ul><li>the super fast activation is only implemented for sequence lengths of 2, 3, 4 and 5.</li><li>other sequence lengths only work on CPU for now (lu decomposition has to be implemented to work for tensors in parallel).</li></ul><p><strong>Constructor</strong></p><p>The constructor is called with: </p><ul><li><code>dim::Int</code>: The system dimension </li><li><code>seq_length::Int</code>: The sequence length to be considered. The default is zero, i.e. arbitrary sequence lengths; this works for all sequence lengths but doesn&#39;t apply the super-fast activation. </li><li><code>skew_sym::Bool</code> (keyword argument): specifies if we the weight matrix is skew symmetric or arbitrary (default is false).</li></ul><p><strong>Functor</strong></p><p>Applying a layer of type <code>VolumePreservingAttention</code> does the following: </p><ul><li>First we perform the operation <span>$X \mapsto X^T A X =: C$</span>, where <span>$X\in\mathbb{R}^{N\times\mathtt{seq\_length}}$</span> is a vector containing time series data and <span>$A$</span> is the skew symmetric matrix associated with the layer. </li><li>In a second step we compute the Cayley transform of <span>$C$</span>; <span>$\Lambda = \mathrm{Cayley}(C)$</span>.</li><li>The output of the layer is then <span>$X\Lambda$</span>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/volume_preserving_attention.jl#LL1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingFeedForward" href="#GeometricMachineLearning.VolumePreservingFeedForward"><code>GeometricMachineLearning.VolumePreservingFeedForward</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Realizes a volume-preserving neural network as a combination of <code>VolumePreservingLowerLayer</code> and <code>VolumePreservingUpperLayer</code>. </p><p><strong>Constructor</strong></p><p>The constructor is called with the following arguments: </p><ul><li><code>sys_dim::Int</code>: The system dimension. </li><li><code>n_blocks::Int</code>: The number of blocks in the neural network (containing linear layers and nonlinear layers). Default is <code>1</code>.</li><li><code>n_linear::Int</code>: The number of linear <code>VolumePreservingLowerLayer</code>s and <code>VolumePreservingUpperLayer</code>s in one block. Default is <code>1</code>.</li><li><code>activation</code>: The activation function for the nonlinear layers in a block. </li><li><code>init_upper::Bool=false</code> (keyword argument): Specifies if the first layer is lower or upper. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/volume_preserving_feedforward.jl#LL10-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingFeedForwardLayer" href="#GeometricMachineLearning.VolumePreservingFeedForwardLayer"><code>GeometricMachineLearning.VolumePreservingFeedForwardLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Super-type of <code>VolumePreservingLowerLayer</code> and <code>VolumePreservingUpperLayer</code>. The layers do the following: </p><p class="math-container">\[x \mapsto \begin{cases} \sigma(Lx + b) &amp; \text{where $L$ is }\mathtt{LowerTriangular} \\ \sigma(Ux + b) &amp; \text{where $U$ is }\mathtt{UpperTriangular}. \end{cases}\]</p><p>The functor can be applied to a vecotr, a matrix or a tensor. </p><p><strong>Constructor</strong></p><p>The constructors are called with:</p><ul><li><code>sys_dim::Int</code>: the system dimension. </li><li><code>activation=tanh</code>: the activation function. </li><li><code>include_bias::Bool=true</code> (keyword argument): specifies whether a bias should be used. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/volume_preserving_feedforward.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingLowerLayer" href="#GeometricMachineLearning.VolumePreservingLowerLayer"><code>GeometricMachineLearning.VolumePreservingLowerLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>See the documentation for <code>VolumePreservingFeedForwardLayer</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/volume_preserving_feedforward.jl#LL19-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingTransformer" href="#GeometricMachineLearning.VolumePreservingTransformer"><code>GeometricMachineLearning.VolumePreservingTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The volume-preserving transformer with the Cayley activation function and built-in upscaling. The arguments for the constructor are: </p><ul><li><code>sys_dim::Int</code></li><li><code>seq_length::Int</code>: The sequence length of the data fed into the transformer.</li><li><code>n_blocks::Int=1</code> (keyword argument): The number of blocks in one transformer unit (containing linear layers and nonlinear layers). Default is <code>1</code>.</li><li><code>n_linear::Int=1</code> (keyword argument): The number of linear <code>VolumePreservingLowerLayer</code>s and <code>VolumePreservingUpperLayer</code>s in one block. Default is <code>1</code>.</li><li><code>L::Int=1</code> (keyword argument): The number of transformer units (default is 2). </li><li><code>activation=tanh</code> (keyward argument): The activation function (<code>tanh</code> by default).</li><li><code>init_upper::Bool=false</code> (keyword argument): Specifies if the network first acts on the <span>$q$</span> component. </li><li><code>skew_sym::Bool=false</code> (keyword argument): specifies if we the weight matrix is skew symmetric or arbitrary.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/volume_preserving_transformer.jl#LL1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.VolumePreservingUpperLayer" href="#GeometricMachineLearning.VolumePreservingUpperLayer"><code>GeometricMachineLearning.VolumePreservingUpperLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>See the documentation for <code>VolumePreservingFeedForwardLayer</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/volume_preserving_feedforward.jl#LL34-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, AT} where AT&lt;:(AbstractArray{T}))}" href="#AbstractNeuralNetworks.update!-Union{Tuple{CT}, Tuple{T}, Tuple{Optimizer{&lt;:BFGSOptimizer}, CT, AbstractArray{T}}} where {T, CT&lt;:(BFGSCache{T, AT} where AT&lt;:(AbstractArray{T}))}"><code>AbstractNeuralNetworks.update!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for an entire neural networks with BFGS. What is different in this case is that we still have to initialize the cache.</p><p>If <code>o.step == 1</code>, then we initialize the cache</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/bfgs_optimizer.jl#LL13-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.iterate-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:GeometricMachineLearning.TransformerIntegrator}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractMatrix{T}}" href="#Base.iterate-Union{Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:GeometricMachineLearning.TransformerIntegrator}, @NamedTuple{q::AT, p::AT}}} where {T, AT&lt;:AbstractMatrix{T}}"><code>Base.iterate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function computes a trajectory for a Transformer that has already been trained for valuation purposes.</p><p>It takes as input: </p><ul><li><code>nn</code>: a <code>NeuralNetwork</code> (that has been trained).</li><li><code>ics</code>: initial conditions (a matrix in <span>$\mathbb{R}^{2n\times\mathtt{seq\_length}}$</span> or <code>NamedTuple</code> of two matrices in <span>$\mathbb{R}^{n\times\mathtt{seq\_length}}$</span>)</li><li><code>n_points::Int=100</code> (keyword argument): The number of steps for which we run the prediction. </li><li><code>prediction_window::Int=size(ics.q, 2)</code>: The prediction window (i.e. the number of steps we predict into the future) is equal to the sequence length (i.e. the number of input time steps) by default.  </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/transformer_integrator.jl#LL10-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.iterate-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:GeometricMachineLearning.NeuralNetworkIntegrator}, BT}} where {T, AT&lt;:AbstractVector{T}, BT&lt;:@NamedTuple{q::AT, p::AT}}" href="#Base.iterate-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:GeometricMachineLearning.NeuralNetworkIntegrator}, BT}} where {T, AT&lt;:AbstractVector{T}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>Base.iterate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function computes a trajectory for a SympNet that has already been trained for valuation purposes.</p><p>It takes as input: </p><ul><li><code>nn</code>: a <code>NeuralNetwork</code> (that has been trained).</li><li><code>ics</code>: initial conditions (a <code>NamedTuple</code> of two vectors)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/neural_network_integrator.jl#LL28-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.vec-Tuple{GeometricMachineLearning.AbstractTriangular}" href="#Base.vec-Tuple{GeometricMachineLearning.AbstractTriangular}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>If <code>vec</code> is applied onto <code>Triangular</code>, then the output is the associated vector.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/triangular.jl#LL98-L100">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.vec-Tuple{SkewSymMatrix}" href="#Base.vec-Tuple{SkewSymMatrix}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>If <code>vec</code> is applied onto <code>SkewSymMatrix</code>, then the output is the associated vector.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/skew_symmetric.jl#LL174-L176">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Gradient" href="#GeometricMachineLearning.Gradient"><code>GeometricMachineLearning.Gradient</code></a> — <span class="docstring-category">Function</span></header><section><div><p>This is an old constructor and will be depricated. For <code>change_q=true</code> it is equivalent to <code>GradientLayerQ</code>; for <code>change_q=false</code> it is equivalent to <code>GradientLayerP</code>.</p><p>If <code>full_grad=false</code> then <code>ActivationLayer</code> is called</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL131-L135">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.Transformer-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.Transformer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The architecture for a &quot;transformer encoder&quot; is essentially taken from arXiv:2010.11929, but with the difference that <strong>no</strong> layer normalization is employed. This is because we still need to find a generalization of layer normalization to manifolds. </p><p>The transformer is called with the following inputs: </p><ul><li><code>dim</code>: the dimension of the transformer </li><li><code>n_heads</code>: the number of heads </li><li><code>L</code>: the number of <strong>transformer blocks</strong></li></ul><p>In addition we have the following optional arguments: </p><ul><li><code>activation</code>: the activation function used for the <code>ResNet</code> (<code>tanh</code> by default)</li><li><code>Stiefel::Bool</code>: if the matrices <span>$P^V$</span>, <span>$P^Q$</span> and <span>$P^K$</span> should live on a manifold (<code>false</code> by default)</li><li><code>retraction</code>: which retraction should be used (<code>Geodesic()</code> by default)</li><li><code>add_connection::Bool</code>: if the input should by added to the ouput after the <code>MultiHeadAttention</code> layer is used (<code>true</code> by default)</li><li><code>use_bias::Bool</code>: If the <code>ResNet</code> should use a bias (<code>true</code> by default)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/transformer.jl#LL1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}" href="#GeometricMachineLearning.accuracy-Union{Tuple{BT}, Tuple{AT}, Tuple{T1}, Tuple{T}, Tuple{Chain, Tuple, DataLoader{T, AT, BT}}} where {T, T1&lt;:Integer, AT&lt;:(AbstractArray{T}), BT&lt;:(AbstractArray{T1})}"><code>GeometricMachineLearning.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the accuracy (as opposed to the loss) of a neural network classifier. </p><p>It takes as input:</p><ul><li><code>model::Chain</code></li><li><code>ps</code>: parameters of the network</li><li><code>dl::DataLoader</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/data_loader.jl#LL167-L174">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_layer_to_nt_and_return_array-Union{Tuple{M}, Tuple{AbstractArray, GeometricMachineLearning.SympNetLayer{M, M}, Any}} where M" href="#GeometricMachineLearning.apply_layer_to_nt_and_return_array-Union{Tuple{M}, Tuple{AbstractArray, GeometricMachineLearning.SympNetLayer{M, M}, Any}} where M"><code>GeometricMachineLearning.apply_layer_to_nt_and_return_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function is used in the wrappers where the input to the SympNet layers is not a <code>NamedTuple</code> (as it should be) but an <code>AbstractArray</code>.</p><p>It converts the Array to a <code>NamedTuple</code> (via <code>assign_q_and_p</code>), then calls the SympNet routine(s) and converts back to an <code>AbstractArray</code> (with <code>vcat</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL235-L239">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_batch_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_batch_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input a <em>batch tensor</em> (to which the data are assigned), the whole data tensor and two vectors <em>params</em> and <em>time_steps</em> that include the specific parameters and time steps we want to assign. </p><p>Note that this assigns sequential data! For e.g. being processed by a transformer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/tensor_assign.jl#LL9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T" href="#GeometricMachineLearning.assign_output_estimate-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, Int64}} where T"><code>GeometricMachineLearning.assign_output_estimate</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The function <code>assign_output_estimate</code> is closely related to the transformer. It takes the last <code>prediction_window</code> columns of the output and uses them for the final prediction. i.e.</p><p class="math-container">\[\mathbb{R}^{N\times\mathtt{pw}}\to\mathbb{R}^{N\times\mathtt{pw}}, 
\begin{bmatrix} 
    z^{(1)}_1               &amp; \cdots &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots &amp; \cdots    \\ 
    z^{(1)}_n               &amp; \cdots &amp; z^{(T})_n
    \end{bmatrix} \mapsto 
    \begin{bmatrix} 
    z^{(T - \mathtt{pw})}_1 &amp; \cdots      &amp; z^{(T)}_1 \\ 
    \cdots                  &amp; \cdots      &amp; \cdots \\ 
    z^{(T - \mathtt{pw})}_n &amp; \cdots      &amp; z^{(T})_n\end{bmatrix}     \]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/tensor_assign.jl#LL37-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_output_kernel!-Tuple{Any}" href="#GeometricMachineLearning.assign_output_kernel!-Tuple{Any}"><code>GeometricMachineLearning.assign_output_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This should be used together with <code>assign_batch_kernel!</code>. It assigns the corresponding output (i.e. target).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/tensor_assign.jl#LL21-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}" href="#GeometricMachineLearning.assign_q_and_p-Tuple{AbstractVector, Int64}"><code>GeometricMachineLearning.assign_q_and_p</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Allocates two new arrays <code>q</code> and <code>p</code> whose first dimension is half of that of the input <code>x</code>. This should also be supplied through the second argument <code>N</code>.</p><p>The output is a <code>Tuple</code> containing <code>q</code> and <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/kernels/assign_q_and_p.jl#LL35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}" href="#GeometricMachineLearning.augment_zeros_kernel!-Tuple{Any}"><code>GeometricMachineLearning.augment_zeros_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Used for differentiating assign<em>output</em>estimate (this appears in the loss). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/tensor_assign.jl#LL62-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.build_v_reduced-Tuple{Any, Any, NeuralNetwork{&lt;:GeometricMachineLearning.SymplecticDecoder}}" href="#GeometricMachineLearning.build_v_reduced-Tuple{Any, Any, NeuralNetwork{&lt;:GeometricMachineLearning.SymplecticDecoder}}"><code>GeometricMachineLearning.build_v_reduced</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Builds the reduced vector field based on the full vector field for a Hamiltonian system. We derive the reduced vector field via the reduced Hamiltonian: <span>$\tilde{H} := H\circ\Psi^\mathrm{dec}$</span>.  We then get </p><p class="math-container">\[\mathbb{J}_{2n}\nabla_\xi\tilde{H} = \mathbb{J}_{2n}(\nabla\Psi^\mathrm{dec})^T\mathbb{J}_{2N}^T\mathbb{J}_{2N}\nabla_z{}H = \mathbb{J}_{2n}(\nabla\Psi^\mathrm{dec})^T\mathbb{J}_{2N}^T \begin{pmatrix} v(z) \\ f(z) \end{pmatrix} = \begin{pmatrix} - (\nabla_p\Psi_q)^Tf(z) + (\nabla_p\Psi_p)^Tv(z) \\ (\nabla_q\Psi_q)^Tf(z) - (\nabla_q\Psi_p)^Tv(z) \end{pmatrix}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/reduced_system/reduced_system.jl#LL74-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_iterations-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.compute_iterations-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.compute_iterations</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function gives iterations from the full dimension to the reduced dimension (i.e. the intermediate steps). The iterations are given in ascending order. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL60-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_iterations_for_symplectic_system-Tuple{Integer, Integer, Integer}" href="#GeometricMachineLearning.compute_iterations_for_symplectic_system-Tuple{Integer, Integer, Integer}"><code>GeometricMachineLearning.compute_iterations_for_symplectic_system</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This function gives iterations from the full dimension to the reduced dimension (i.e. the intermediate steps). The iterations are given in ascending order. Only even steps are allowed here.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/symplectic_autoencoder.jl#LL78-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}" href="#GeometricMachineLearning.compute_output_of_mha-Union{Tuple{T}, Tuple{M}, Tuple{MultiHeadAttention{M, M}, AbstractMatrix{T}, NamedTuple}} where {M, T}"><code>GeometricMachineLearning.compute_output_of_mha</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Applies MHA to an abstract matrix. This is the same independent of whether the input is added to the output or not. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/multi_head_attention.jl#LL86-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, AT&lt;:AbstractArray{T, 3}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array (NamedTuples). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/batch.jl#LL121-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}" href="#GeometricMachineLearning.convert_input_and_batch_indices_to_array-Union{Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, BT}, Batch, Vector{Tuple{Int64, Int64}}}} where {T, BT&lt;:AbstractArray{T, 3}}"><code>GeometricMachineLearning.convert_input_and_batch_indices_to_array</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes the output of the batch functor and uses it to create the corresponding array. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/batch.jl#LL147-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.crop_array_for_transformer_loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T2}, Tuple{T}, Tuple{AT, BT}} where {T, T2, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T2, 3}}" href="#GeometricMachineLearning.crop_array_for_transformer_loss-Union{Tuple{BT}, Tuple{AT}, Tuple{T2}, Tuple{T}, Tuple{AT, BT}} where {T, T2, AT&lt;:AbstractArray{T, 3}, BT&lt;:AbstractArray{T2, 3}}"><code>GeometricMachineLearning.crop_array_for_transformer_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This crops the output array of the neural network so that it conforms with the output it should be compared to. This is needed for the transformer loss. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/loss/losses.jl#LL32-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}" href="#GeometricMachineLearning.custom_mat_mul-Tuple{AbstractMatrix, AbstractVecOrMat}"><code>GeometricMachineLearning.custom_mat_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Multiplies a matrix with a vector, a matrix or a tensor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/sympnets.jl#LL185-L187">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.decoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}" href="#GeometricMachineLearning.decoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}"><code>GeometricMachineLearning.decoder_layers_from_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input the autoencoder architecture and a vector of integers specifying the layer dimensions in the decoder. Has to return a tuple of <code>AbstractExplicitLayer</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL82-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.draw_batch!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.draw_batch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the batch if the data are in form of a matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/matrix_assign.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.encoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}" href="#GeometricMachineLearning.encoder_layers_from_iteration-Tuple{GeometricMachineLearning.AutoEncoder, AbstractVector{&lt;:Integer}}"><code>GeometricMachineLearning.encoder_layers_from_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input the autoencoder architecture and a vector of integers specifying the layer dimensions in the encoder. Has to return a tuple of <code>AbstractExplicitLayer</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/autoencoder.jl#LL77-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}" href="#GeometricMachineLearning.init_optimizer_cache-Tuple{GradientOptimizer, Any}"><code>GeometricMachineLearning.init_optimizer_cache</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Wrapper for the functions <code>setup_adam_cache</code>, <code>setup_momentum_cache</code>, <code>setup_gradient_cache</code>, <code>setup_bfgs_cache</code>. These appear outside of <code>optimizer_caches.jl</code> because the <code>OptimizerMethods</code> first have to be defined.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/init_optimizer_cache.jl#LL1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.initialize_hessian_inverse-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.initialize_hessian_inverse</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This initializes the inverse of the Hessian for various arrays. This requires an implementation of a <em>vectorization operation</em> <code>vec</code>. This is important for custom arrays.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/bfgs_cache.jl#LL33-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}" href="#GeometricMachineLearning.map_index_for_symplectic_potential-Tuple{Int64, Int64}"><code>GeometricMachineLearning.map_index_for_symplectic_potential</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This assigns the right index for the symplectic potential. To be used with <code>assign_ones_for_symplectic_potential_kernel!</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/arrays/symplectic.jl#LL65-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{AT}, Tuple{ST}, Tuple{BT}, Tuple{T}, Tuple{AT, AbstractArray{T, 3}}} where {T, BT&lt;:(AbstractArray{T}), ST&lt;:StiefelManifold{T, BT}, AT&lt;:LinearAlgebra.Adjoint{T, ST}}"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by the adjoint of an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/multi_head_attention.jl#LL140-L142">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T" href="#GeometricMachineLearning.mat_tensor_mul-Union{Tuple{T}, Tuple{StiefelManifold, AbstractArray{T, 3}}} where T"><code>GeometricMachineLearning.mat_tensor_mul</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Extend <code>mat_tensor_mul</code> to a multiplication by an element of <code>StiefelManifold</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/layers/multi_head_attention.jl#LL147-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}" href="#GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Implements the canonical Riemannian metric for the Stiefel manifold:</p><p class="math-container">\[g_Y: (\Delta_1, \Delta_2) \mapsto \mathrm{tr}(\Delta_1^T(\mathbb{I} - \frac{1}{2}YY^T)\Delta_2).\]</p><p>It is called with: </p><ul><li><code>Y::StiefelManifold</code></li><li><code>Δ₁::AbstractMatrix</code></li><li><code>Δ₂::AbstractMatrix</code>`</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/manifolds/stiefel_manifold.jl#LL37-L46">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.number_of_batches-Union{Tuple{OT}, Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT, OT, :TimeSeries}, Batch}} where {T, BT&lt;:AbstractArray{T, 3}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}, OT}" href="#GeometricMachineLearning.number_of_batches-Union{Tuple{OT}, Tuple{AT}, Tuple{BT}, Tuple{T}, Tuple{DataLoader{T, AT, OT, :TimeSeries}, Batch}} where {T, BT&lt;:AbstractArray{T, 3}, AT&lt;:Union{@NamedTuple{q::BT, p::BT}, BT}, OT}"><code>GeometricMachineLearning.number_of_batches</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Gives the number of batches. Inputs are of type <code>DataLoader</code> and <code>Batch</code>.</p><p>Here the big distinction is between data that are <em>time-series like</em> and data that are <em>autoencoder like</em>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/batch.jl#LL46-L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer" href="#GeometricMachineLearning.onehotbatch-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Integer"><code>GeometricMachineLearning.onehotbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><p>One-hot-batch encoding of a vector of integers: <span>$input\in\{0,1,\ldots,9\}^\ell$</span>.  The output is a tensor of shape <span>$10\times1\times\ell$</span>. </p><p class="math-container">\[0 \mapsto \begin{bmatrix} 1 &amp; 0 &amp; \ldots &amp; 0 \end{bmatrix}.\]</p><p>In more abstract terms: <span>$i \mapsto e_i$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/mnist_utils.jl#LL6-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Chain, Tuple, Tuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Chain, Tuple, Tuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for an entire neural network, the way this function should be called. </p><p>inputs: </p><ul><li><code>o::Optimizer</code></li><li><code>model::Chain</code></li><li><code>ps::Tuple</code></li><li><code>dx::Tuple</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/optimizer.jl#LL51-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Union{AbstractNeuralNetworks.AbstractExplicitCell, AbstractNeuralNetworks.AbstractExplicitLayer}, NamedTuple, NamedTuple, NamedTuple}" href="#GeometricMachineLearning.optimization_step!-Tuple{Optimizer, Union{AbstractNeuralNetworks.AbstractExplicitCell, AbstractNeuralNetworks.AbstractExplicitLayer}, NamedTuple, NamedTuple, NamedTuple}"><code>GeometricMachineLearning.optimization_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimization for a single layer. </p><p>inputs: </p><ul><li><code>o::Optimizer</code></li><li><code>d::Union{AbstractExplicitLayer, AbstractExplicitCell}</code></li><li><code>ps::NamedTuple</code>: the parameters </li><li><code>C::NamedTuple</code>: NamedTuple of the caches </li><li><code>dx::NamedTuple</code>: NamedTuple of the derivatives (output of AD routine)</li></ul><p><code>ps</code>, <code>C</code> and <code>dx</code> must have the same keys. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/optimizers/optimizer.jl#LL30-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT} where AT&lt;:Union{AbstractArray{T}, NamedTuple}, Batch, Union{typeof(GeometricMachineLearning.loss), GeometricMachineLearning.NetworkLoss}}} where T" href="#GeometricMachineLearning.optimize_for_one_epoch!-Union{Tuple{T}, Tuple{Optimizer, Any, Union{Tuple, NamedTuple}, DataLoader{T, AT} where AT&lt;:Union{AbstractArray{T}, NamedTuple}, Batch, Union{typeof(GeometricMachineLearning.loss), GeometricMachineLearning.NetworkLoss}}} where T"><code>GeometricMachineLearning.optimize_for_one_epoch!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Optimize for an entire epoch. For this you have to supply: </p><ul><li>an instance of the optimizer.</li><li>the neural network model </li><li>the parameters of the model </li><li>the data (in form of <code>DataLoader</code>)</li><li>in instance of <code>Batch</code> that contains <code>batch_size</code> (and optionally <code>seq_length</code>)</li></ul><p>With the optional argument:</p><ul><li>the loss, which takes the <code>model</code>, the parameters <code>ps</code> and an instance of <code>DataLoader</code> as input.</li></ul><p>The output of <code>optimize_for_one_epoch!</code> is the average loss over all batches of the epoch:</p><p class="math-container">\[output = \frac{1}{\mathtt{steps\_per\_epoch}}\sum_{t=1}^\mathtt{steps\_per\_epoch}loss(\theta^{(t-1)}).\]</p><p>This is done because any <strong>reverse differentiation</strong> routine always has two outputs: a pullback and the value of the function it is differentiating. In the case of zygote: <code>loss_value, pullback = Zygote.pullback(ps -&gt; loss(ps), ps)</code> (if the loss only depends on the parameters).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/optimize.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer" href="#GeometricMachineLearning.patch_index-Union{Tuple{T}, Tuple{T, T, T}, NTuple{4, T}} where T&lt;:Integer"><code>GeometricMachineLearning.patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the batch index (for MNIST data set for now).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/mnist_utils.jl#LL22-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}" href="#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Computes the Riemannian gradient for the Stiefel manifold given an element <span>$Y\in{}St(N,n)$</span> and a matrix <span>$\nabla{}L\in\mathbb{R}^{N\times{}n}$</span> (the Euclidean gradient). It computes the Riemannian gradient with respect to the canonical metric (see the documentation for the function <code>metric</code> for an explanation of this). The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - Y(\nabla{}L)^TY\]</p><p>It is called with inputs:</p><ul><li><code>Y::StiefelManifold</code></li><li><code>e_grad::AbstractMatrix</code>: i.e. the Euclidean gradient (what was called <span>$\nabla{}L$</span>) above.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/manifolds/stiefel_manifold.jl#LL23-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}" href="#GeometricMachineLearning.solve!-Tuple{NeuralNetwork{&lt;:PSDArch}, AbstractMatrix}"><code>GeometricMachineLearning.solve!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><a href="#GeometricMachineLearning.PSDArch">PSDArch</a> does not require neural network training since it is a strictly linear operation that can be solved with singular value decomposition (SVD).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/architectures/psd.jl#LL45-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T" href="#GeometricMachineLearning.split_and_flatten-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T"><code>GeometricMachineLearning.split_and_flatten</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>split_and_flatten</code> takes a tensor as input and produces another one as output (essentially rearranges the input data in an intricate way) so that it can easily be processed with a transformer.</p><p>The optional arguments are: </p><ul><li><code>patch_length</code>: by default this is 7. </li><li><code>number_of_patches</code>: by default this is 16.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/mnist_utils.jl#LL51-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_skew_sym_assign-Union{Tuple{AT}, Tuple{T}, Tuple{AT, AbstractMatrix{T}}} where {T, AT&lt;:AbstractArray{T, 3}}" href="#GeometricMachineLearning.tensor_mat_skew_sym_assign-Union{Tuple{AT}, Tuple{T}, Tuple{AT, AbstractMatrix{T}}} where {T, AT&lt;:AbstractArray{T, 3}}"><code>GeometricMachineLearning.tensor_mat_skew_sym_assign</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Takes as input: </p><ul><li><code>Z::AbstractArray{T, 3}</code>: A tensor that stores a bunch of time series. </li><li><code>A::AbstractMatrix</code>: A matrix that is used to perform various scalar products. </li></ul><p>For one of these time series the function performs the following computation: </p><p class="math-container">\[    (z^{(i)}, z^{(j)}) \mapsto (z^{(i)})^TAz^{(j)} \text{ for } i &gt; j.\]</p><p>The result of this are <span>$n(n-2)\div2$</span> scalar products. These scalar products are written into a lower-triangular matrix and the final output of the function is a tensor of these lower-triangular matrices. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/kernels/inverses/tensor_mat_skew_sym_assign.jl#LL30-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!-Tuple{Any}" href="#GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!-Tuple{Any}"><code>GeometricMachineLearning.tensor_mat_skew_sym_assign_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>A kernel that computes the weighted scalar products of all combinations of vectors in the matrix <code>Z</code> except where the two vectors are the same and writes the result into a <em>tensor of skew symmetric matrices</em> <code>C</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/kernels/inverses/tensor_mat_skew_sym_assign.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!" href="#GeometricMachineLearning.train!"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train!(...)</code></pre><p>Perform a training of a neural networks on data using given method a training Method</p><p>Different ways of use:</p><pre><code class="nohighlight hljs">train!(neuralnetwork, data, optimizer = GradientOptimizer(1e-2), training_method; nruns = 1000, batch_size = default(data, type), showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data</code> : the data (see <a href="#GeometricMachineLearning.TrainingData"><code>TrainingData</code></a>)</li><li><code>optimizer = GradientOptimizer</code>: the optimization method (see <a href="../Optimizer/#Optimizer"><code>Optimizer</code></a>)</li><li><code>training_method</code> : specify the loss function used </li><li><code>nruns</code> : number of iteration through the process with default value </li><li><code>batch_size</code> : size of batch of data used for each step</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/training/train.jl#LL16-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}" href="#GeometricMachineLearning.train!-Tuple{AbstractNeuralNetworks.AbstractNeuralNetwork{&lt;:AbstractNeuralNetworks.Architecture}, AbstractTrainingData, TrainingParameters}"><code>GeometricMachineLearning.train!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">train!(neuralnetwork, data, optimizer, training_method; nruns = 1000, batch_size, showprogress = false )</code></pre><p><strong>Arguments</strong></p><ul><li><code>neuralnetwork::LuxNeuralNetwork</code> : the neural net work using LuxBackend</li><li><code>data::AbstractTrainingData</code> : the data</li><li>``</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/training/train.jl#LL84-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer" href="#GeometricMachineLearning.within_patch_index-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Integer"><code>GeometricMachineLearning.within_patch_index</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Based on coordinates i,j this returns the index within the batch</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/data_loader/mnist_utils.jl#LL31-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.write_ones_kernel!-Tuple{Any}" href="#GeometricMachineLearning.write_ones_kernel!-Tuple{Any}"><code>GeometricMachineLearning.write_ones_kernel!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Kernel that is needed for functions relating to <code>SymmetricMatrix</code> and <code>SkewSymMatrix</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/132565cc48ac510479a204807451b86a2e0fee5b/src/utils.jl#LL74-L76">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../references/">« References</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Wednesday 8 May 2024 10:56">Wednesday 8 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
