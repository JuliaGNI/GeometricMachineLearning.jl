<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Homogeneous Spaces · GeometricMachineLearning.jl</title><meta name="title" content="Homogeneous Spaces · GeometricMachineLearning.jl"/><meta property="og:title" content="Homogeneous Spaces · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Homogeneous Spaces · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/homogeneous_spaces/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/homogeneous_spaces/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/homogeneous_spaces/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../riemannian_manifolds/">Riemannian Manifolds</a></li><li class="is-active"><a class="tocitem" href>Homogeneous Spaces</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#The-Stiefel-Manifold"><span>The Stiefel Manifold</span></a></li><li><a class="tocitem" href="#The-Riemannian-Gradient-for-the-Stiefel-Manifold"><span>The Riemannian Gradient for the Stiefel Manifold</span></a></li><li class="toplevel"><a class="tocitem" href="#The-Grassmann-Manifold"><span>The Grassmann Manifold</span></a></li><li><a class="tocitem" href="#The-Riemannian-Gradient-of-the-Grassmann-Manifold"><span>The Riemannian Gradient of the Grassmann Manifold</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Optimizers</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Network Losses</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../library/">Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manifolds</a></li><li class="is-active"><a href>Homogeneous Spaces</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Homogeneous Spaces</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/manifolds/homogeneous_spaces.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Homogeneous-Spaces"><a class="docs-heading-anchor" href="#Homogeneous-Spaces">Homogeneous Spaces</a><a id="Homogeneous-Spaces-1"></a><a class="docs-heading-anchor-permalink" href="#Homogeneous-Spaces" title="Permalink"></a></h1><p><em>Homogeneous spaces</em> are very important in <code>GeometricMachineLearning</code> as we can generalize existing neural network optimizers from vector spaces to such homogenous spaces. They are intricately linked to the notion of a <em>Lie Group</em> and its <em>Lie Algebra</em><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>.</p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>A <strong>homogeneous space</strong> is a manifold <span>$\mathcal{M}$</span> on which a Lie group <span>$G$</span> acts transitively, i.e.</p><p class="math-container">\[\forall X,Y\in\mathcal{M} \exists{}A\in{}G\text{ s.t. }AX = Y.\]</p></div></div><p>Now fix a distinct element <span>$E\in\mathcal{M}$</span>; we will refer to this as the <em>canonical element</em>. We can also establish an isomorphism between <span>$\mathcal{M}$</span> and the quotient space <span>$G/\sim$</span> with the equivalence relation: </p><p class="math-container">\[A_1 \sim A_2 \iff A_1E = A_2E.\]</p><p>Note that this is independent of the chosen <span>$E$</span>.</p><p>The tangent spaces of <span>$\mathcal{M}$</span> are of the form <span>$T_Y\mathcal{M} = \mathfrak{g}\cdot{}Y$</span>, i.e. can be fully described through its Lie algebra.  Based on this we can perform a splitting of <span>$\mathfrak{g}$</span> into two parts:</p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>A <strong>splitting of the Lie algebra</strong> <span>$\mathfrak{g}$</span> at an element of a homogeneous space <span>$Y$</span> is a decomposition into a <strong>vertical</strong> and a <strong>horizontal</strong> component, denoted by <span>$\mathfrak{g} = \mathfrak{g}^{\mathrm{ver},Y} \oplus \mathfrak{g}^{\mathrm{hor},Y}$</span> such that</p><ol><li>The <em>vertical component</em> <span>$\mathfrak{g}^{\mathrm{ver},Y}$</span> is the kernel of the map <span>$\mathfrak{g}\to{}T_Y\mathcal{M}, V \mapsto VY$</span>, i.e. <span>$\mathfrak{g}^{\mathrm{ver},Y} = \{V\in\mathfrak{g}:VY = 0\}.$</span></li><li>The <em>horizontal component</em> <span>$\mathfrak{g}^{\mathrm{hor},Y}$</span> is the orthogonal complement of <span>$\mathfrak{g}^{\mathrm{ver},Y}$</span> in <span>$\mathfrak{g}$</span>. It is isomorphic to <span>$T_Y\mathcal{M}$</span>.</li></ol></div></div><p>We will refer to the mapping from <span>$T_Y\mathcal{M}$</span> to <span>$\mathfrak{g}^{\mathrm{hor}, Y}$</span> by <span>$\Omega$</span>. We will give explicit examples of <span>$\Omega$</span> below. If we have now defined a metric <span>$\langle\cdot,\cdot\rangle$</span> on <span>$\mathfrak{g}$</span>, then this induces a Riemannian metric on <span>$\mathcal{M}$</span>:</p><p class="math-container">\[g_Y(\Delta_1, \Delta_2) = \langle\Omega(Y,\Delta_1),\Omega(Y,\Delta_2)\rangle\text{ for $\Delta_1,\Delta_2\in{}T_Y\mathcal{M}$.}\]</p><p>Two examples of homogeneous spaces implemented in <code>GeometricMachineLearning</code> are the <a href="#The-Stiefel-Manifold">Stiefel</a> and the <a href="#The-Grassmann-Manifold">Grassmann</a> manifold. The Lie group <span>$SO(N)$</span> acts transitively on both of these manifolds, i.e. turns them into homogeneous spaces. The Lie algebra of <span>$SO(N)$</span> are the skew-symmetric matrices <span>$\mathfrak{so}(N):=\{V\in\mathbb{R}^{N\times{}N}:V^T + V = 0\}$</span> and the canonical metric associated with it is simply <span>$(V_1,V_2)\mapsto\frac{1}{2}\mathrm{Tr}(V_1^TV_2)$</span>.</p><h1 id="The-Stiefel-Manifold"><a class="docs-heading-anchor" href="#The-Stiefel-Manifold">The Stiefel Manifold</a><a id="The-Stiefel-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#The-Stiefel-Manifold" title="Permalink"></a></h1><p>The Stiefel manifold <span>$St(n, N)$</span> is the space of all orthonormal frames in <span>$\mathbb{R}^{N\times{}n}$</span>, i.e. matrices <span>$Y\in\mathbb{R}^{N\times{}n}$</span> s.t. <span>$Y^TY = \mathbb{I}_n$</span>. It can also be seen as <span>$SO(N)$</span> modulo an equivalence relation: <span>$A\sim{}B\iff{}AE = BE$</span> for </p><p class="math-container">\[E = \begin{bmatrix}
\mathbb{I}_n \\ 
\mathbb{O}
\end{bmatrix}\in{}St(n, N),\]</p><p>which is the canonical element of the Stiefel manifold. In words: the first <span>$n$</span> columns of <span>$A$</span> and <span>$B$</span> are the same. We also use this principle to draw random elements from the Stiefel manifold.</p><div class="admonition is-info"><header class="admonition-header">Example</header><div class="admonition-body"><p>Drawing random elements from the Stiefel (and the Grassmann) manifold is done by first calling <code>rand(N, n)</code> (i.e. drawing from a normal distribution) and then performing a <span>$QR$</span> decomposition. We then take the first <span>$n$</span> columns of the <span>$Q$</span> matrix to be an element of the Stiefel manifold.</p></div></div><p>The tangent space to the element <span>$Y\in{}St(n,N)$</span> can be determined by considering <span>$C^\infty$</span> curves on <span>$SO(N)$</span> through <span>$\mathbb{I}$</span> which we write <span>$t\mapsto{}A(t)$</span>. Because <span>$SO(N)$</span> acts transitively on <span>$St(n, N)$</span> each <span>$C^\infty$</span> curve on <span>$St(n, N)$</span> through <span>$Y$</span> can be written as <span>$A(t)Y$</span> and we get: </p><p class="math-container">\[T_YSt(n,N)=\{BY : B\in\mathfrak{g}\} = \{\Delta\in\mathbb{R}^{N\times{}n}: \Delta^TY + Y^T\Delta = \mathbb{O}\},\]</p><p>where the last equality can be established through the isomorphism </p><p class="math-container">\[\Omega: T_YSt(n, N) \to \mathfrak{g}^{\mathrm{vec}, Y}, \Delta \mapsto (\mathbb{I} - \frac{1}{2}YY^T)\Delta{}Y^T - Y\Delta^T(\mathbb{I} - \frac{1}{2}YY^T).\]</p><p>That this is an isomorphism can be easily checked: </p><p class="math-container">\[    \Omega(\Delta)Y = (\mathbb{I} - \frac{1}{2}YY^T)\Delta - \frac{1}{2}Y\Delta^TY = \Delta.\]</p><p>The isomorphism is also implemented in <code>GeometricMachineLearning</code>:</p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = rand(StiefelManifold{Float32}, 5, 3)
Δ = rgrad(Y, rand(Float32, 5, 3))
GeometricMachineLearning.Ω(Y, Δ) * Y.A ≈ Δ</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>The function <code>rgrad</code> is introduced below. </p><h2 id="The-Riemannian-Gradient-for-the-Stiefel-Manifold"><a class="docs-heading-anchor" href="#The-Riemannian-Gradient-for-the-Stiefel-Manifold">The Riemannian Gradient for the Stiefel Manifold</a><a id="The-Riemannian-Gradient-for-the-Stiefel-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#The-Riemannian-Gradient-for-the-Stiefel-Manifold" title="Permalink"></a></h2><p>We defined the <a href="../riemannian_manifolds/#The-Riemannian-Gradient">Riemannian gradient</a> to be a vector field <span>$\mathrm{grad}^gL$</span> such that it is <em>compatible with the Riemannian metric</em> in some sense; the definition we gave relied on an explicit coordinate chart. We can also express the Riemannian gradient for matrix manifolds by not relying on an explicit coordinate representation (which would be computationally expensive) [<a href="../../references/#absil2004riemannian">6</a>].</p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>Given a Riemannian matrix manifold <span>$\mathcal{M}$</span> we define the <strong>Riemannian gradient</strong> of <span>$L:\mathcal{M}\to\mathbb{R}$</span> at <span>$Y$</span>, called <span>$\mathrm{grad}_YL\in{}T_Y\mathcal{M}$</span>, as the unique element of <span>$T_Y\mathcal{M}$</span> such that for any other <span>$\Delta\in{}T_Y\mathcal{M}$</span> we have</p><p class="math-container">\[\mathrm{Tr}((\nabla{}L)^T\Delta) = g_Y(\mathrm{grad}_YL, \Delta),\]</p><p>where Tr indicates the usual matrix trace.</p></div></div><p>For the Stiefel manifold the Riemannian gradient is given by: </p><p class="math-container">\[    \mathrm{grad}_YL = \nabla_YL - Y(\nabla_YL)^TY =: \mathtt{rgrad}(Y, \nabla_YL),\]</p><p>where <span>$\nabla_YL$</span> refers to the Euclidean gradient, i.e. </p><p class="math-container">\[    [\nabla_YL]_{ij} = \frac{\partial{}L}{\partial{}y_{ij}}.\]</p><p>The Euclidean gradient <span>$\nabla{}L$</span> can in practice be obtained with an <a href="../../pullbacks/computation_of_pullbacks/#Pullbacks-and-Automatic-Differentiation">AD routine</a>. We then use the function <code>rgrad</code> to map <span>$\nabla_YL$</span> from <span>$\mathbb{R}^{N\times{}n}$</span> to <span>$T_YSt(n,N)$</span>. We can check that this mapping indeed maps to the Riemannian gradient</p><pre><code class="language-julia hljs">using GeometricMachineLearning
using LinearAlgebra: tr

Y = rand(StiefelManifold{Float32}, 5, 3)
∇L = rand(Float32, 5, 3)
gradL = rgrad(Y, ∇L)
Δ = rgrad(Y, rand(Float32, 5, 3))

metric(Y, gradL, Δ) ≈ tr(∇L&#39; * Δ)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h1 id="The-Grassmann-Manifold"><a class="docs-heading-anchor" href="#The-Grassmann-Manifold">The Grassmann Manifold</a><a id="The-Grassmann-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#The-Grassmann-Manifold" title="Permalink"></a></h1><p>The Grassmann manifold is closely related to the Stiefel manifold, and an element of the Grassmann manifold can be represented through an element of the Stiefel manifold (but not vice-versa). An element of the Grassmann manifold <span>$G(n,N)$</span> is a vector subspace <span>$\subset\mathbb{R}^N$</span> of dimension <span>$n$</span>. Each such subspace (i.e. element of the Grassmann manifold) can be represented by a full-rank matrix <span>$A\in\mathbb{R}^{N\times{}n}$</span> and we identify two elements with the following equivalence relation: </p><p class="math-container">\[    A_1 \sim A_2 \iff \exists{}C\in\mathbb{R}^{n\times{}n}\text{ s.t. }A_1C = A_2.\]</p><p>The resulting manifold is of dimension <span>$n(N-n)$</span>. One can find a parametrization of the manifold the following way: Because the matrix <span>$Y$</span> has full rank, there have to be <span>$n$</span> independent columns in it: <span>$i_1, \ldots, i_n$</span>. For simplicity assume that <span>$i_1 = 1, i_2=2, \ldots, i_n=n$</span> and call the matrix made up of these columns <span>$C$</span>. Then the mapping to the coordinate chart is: <span>$YC^{-1}$</span> and the last <span>$N-n$</span> columns are the coordinates.</p><p>We can also define the Grassmann manifold based on the Stiefel manifold since elements of the Stiefel manifold are already full-rank matrices. In this case we have the following equivalence relation (for <span>$Y_1, Y_2\in{}St(n,N)$</span>): </p><p class="math-container">\[    Y_1 \sim Y_2 \iff \exists{}C\in{}SO(n)\text{ s.t. }Y_1C = Y_2.\]</p><p>In <code>GeometricMachineLearning</code> elements of the Grassmann manifold are drawn the same way as elements of the Stiefel manifold:</p><pre><code class="language-julia hljs">using GeometricMachineLearning

rand(GrassmannManifold{Float32}, 5, 3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×3 GrassmannManifold{Float32, Matrix{Float32}}:
 -0.157512    0.185112  -0.216194
  0.0595288  -0.523402  -0.567974
 -0.379467    0.669637  -0.545434
  0.908048    0.323416  -0.259806
 -0.0556817  -0.372523  -0.51543</code></pre><h2 id="The-Riemannian-Gradient-of-the-Grassmann-Manifold"><a class="docs-heading-anchor" href="#The-Riemannian-Gradient-of-the-Grassmann-Manifold">The Riemannian Gradient of the Grassmann Manifold</a><a id="The-Riemannian-Gradient-of-the-Grassmann-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#The-Riemannian-Gradient-of-the-Grassmann-Manifold" title="Permalink"></a></h2><p>Obtaining the Riemannian Gradient for the Grassmann manifold is slightly more difficult than it is in the case of the Stiefel manifold [<a href="../../references/#absil2004riemannian">6</a>]. Since the Grassmann manifold can be obtained from the Stiefel manifold through an equivalence relation, we can however use this as a starting point. </p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>The Riemannian gradient of a function <span>$L$</span> defined on the Grassmann manifold can be written as</p><p class="math-container">\[\mathrm{grad}_\mathcal{Y}^{Gr}L \simeq \nabla_Y{}L - YY^T\nabla_YL,\]</p><p>where <span>$\nabla_Y{}L$</span> again is again the Euclidean gradient.</p></div></div><details class="admonition is-details"><summary class="admonition-header">Proof</summary><div class="admonition-body"><p>In a first step we identify charts on the Grassmann manifold to make dealing with it easier. For this consider the following open cover of the Grassmann manifold. </p><p class="math-container">\[\{\mathcal{U}_W\}_{W\in{}St(n, N)} \quad\text{where}\quad \mathcal{U}_W = \{\mathrm{span}(Y):\mathrm{det}(W^TY)\neq0\}.\]</p><p>We can find a canonical bijective mapping from the set <span>$\mathcal{U}_W$</span> to the set <span>$\mathcal{S}_W := \{Y\in\mathbb{R}^{N\times{}n}:W^TY=\mathbb{I}_n\}$</span>:</p><p class="math-container">\[\sigma_W: \mathcal{U}_W \to \mathcal{S}_W,\, \mathcal{Y}=\mathrm{span}(Y)\mapsto{}Y(W^TY)^{-1} =: \hat{Y}.\]</p><p>That <span>$\sigma_W$</span> is well-defined is easy to see: Consider <span>$YC$</span> with <span>$C\in\mathbb{R}^{n\times{}n}$</span> non-singular. Then <span>$YC(W^TYC)^{-1}=Y(W^TY)^{-1} = \hat{Y}$</span>. With this isomorphism we can also find a representation of elements of the tangent space:</p><p class="math-container">\[T_\mathcal{Y}\sigma_W: T_\mathcal{Y}Gr(n,N)\to{}T_{\hat{Y}}\mathcal{S}_W.\]</p><p>We give an explicit representation of this isomorphism; because the map <span>$\sigma_W$</span> does not care about the representation of <span>$\mathrm{span}(Y)$</span> we can perform the variations in <span>$St(n,N)$</span>. We write the variations as <span>$Y(t)\in{}St(n,N)$</span> for <span>$t\in(-\varepsilon,\varepsilon)$</span>. We also set <span>$Y(0) = Y$</span> and hence</p><p class="math-container">\[\frac{d}{dt}Y(t)(W^TY(t))^{-1} = (\dot{Y}(0) - Y(W^TY)^{-1}W^T\dot{Y}(0))(W^TY)^{-1},\]</p><p>where <span>$\dot{Y}(0)\in{}T_YSt(n,N)$</span>. Also note  note that we have <span>$T_\mathcal{Y}\mathcal{U}_W = T_\mathcal{Y}Gr(n,N)$</span> because <span>$\mathcal{U}_W$</span> is an open subset of <span>$Gr(n,N)$</span>. We thus can identify the tangent space <span>$T_\mathcal{Y}Gr(n,N)$</span> with the following set:</p><p class="math-container">\[T_{\hat{Y}}\mathcal{S}_W = \{(\Delta - YW^T\Delta)(W^T\Delta)^{-1}: Y\in{}St(n,N)\text{ s.t. }\mathrm{span}(Y)=\mathcal{Y}\text{ and }\Delta\in{}T_YSt(n,N)\}.\]</p><p>Further note that we can pick any element <span>$W$</span> to construct the charts for a neighborhood around the point <span>$\mathcal{Y}\in{}Gr(n,N)$</span> as long as we have <span>$\mathrm{det}(W^TY)\neq0$</span> for <span>$\mathrm{span}(Y)=\mathcal{Y}$</span>. We  hence take <span>$W=Y$</span> and get the identification: </p><p class="math-container">\[T_\mathcal{Y}Gr(n,N) \equiv \{\Delta - YY^T\Delta: Y\in{}St(n,N)\text{ s.t. }\mathrm{span}(Y)=\mathcal{Y}\text{ and }\Delta\in{}T_YSt(n,N)\},\]</p><p>which is very easy to handle computationally (we simply store and change the matrix <span>$Y$</span> that represents an element of the Grassmann manifold). The Riemannian gradient is then </p><p class="math-container">\[\mathrm{grad}_\mathcal{Y}^{Gr}L = \mathrm{grad}_Y^{St}L - YY^T\mathrm{grad}_Y^{St}L = \nabla_Y{}L - YY^T\nabla_YL,\]</p><p>where <span>$\mathrm{grad}^{St}_YL$</span> is the Riemannian gradient of the Stiefel manifold at <span>$Y$</span>. We proved our assertion.</p></div></details><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelManifold-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.StiefelManifold-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.StiefelManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>An implementation of the Stiefel manifold [<a href="../../references/#hairer2006geometric">7</a>]. The Stiefel manifold is the collection of all matrices <span>$Y\in\mathbb{R}^{N\times{}n}$</span> whose columns are orthonormal, i.e. </p><p class="math-container">\[    St(n, N) = \{Y: Y^TY = \mathbb{I}_n \}.\]</p><p>The Stiefel manifold can be shown to have manifold structure (as the name suggests) and this is heavily used in <code>GeometricMachineLearning</code>. It is further a compact space.  More information can be found in the docstrings for <code>rgrad(::StiefelManifold, ::AbstractMatrix)</code><code>and</code>metric(::StiefelManifold, ::AbstractMatrix, ::AbstractMatrix)`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/stiefel_manifold.jl#LL1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannManifold-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.GrassmannManifold-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.GrassmannManifold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The <code>GrassmannManifold</code> is based on the <a href="../../library/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/grassmann_manifold.jl#LL1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.rand-Union{Tuple{MT}, Tuple{Type{MT}, Integer, Integer}} where MT&lt;:Manifold-manifolds-homogeneous_spaces" href="#Base.rand-Union{Tuple{MT}, Tuple{Type{MT}, Integer, Integer}} where MT&lt;:Manifold-manifolds-homogeneous_spaces"><code>Base.rand</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rand(manifold_type::Type{MT}, N::Integer, n::Integer) where MT &lt;: Manifold</code></pre><p>Draw random elements from the Stiefel and the Grassmann manifold. </p><p>Because both of these manifolds are compact spaces we can sample them uniformly [<a href="../../references/#mezzadri2006generate">8</a>].</p><p><strong>Examples</strong></p><p>When we call ...</p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round # hide
import Random
Random.seed!(123)

N, n = 5, 3
Y = rand(StiefelManifold{Float32}, N, n)
_round(Y; digits = 5) # hide

# output

5×3 StiefelManifold{Float32, Matrix{Float32}}:
 -0.27575   0.32991   0.77275
 -0.62485  -0.33224  -0.0686
 -0.69333   0.36724  -0.18988
 -0.09295  -0.73145   0.46064
  0.2102    0.33301   0.38717</code></pre><p>... the sampling is done by first allocating a random matrix of size <span>$N\times{}n$</span> via <code>Y = randn(Float32, N, n)</code>. We then perform a QR decomposition <code>Q, R = qr(Y)</code> with the <code>qr</code> function from the <code>LinearAlgebra</code> package (this is using Householder reflections internally).  The final output are then the first <code>n</code> columns of the <code>Q</code> matrix. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/abstract_manifold.jl#LL91-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rgrad(Y::StiefelManifold, e_grad::AbstractMatrix)</code></pre><p>Compute the Riemannian gradient for the Stiefel manifold at <span>$Y\in{}St(N,n)$</span> based on <span>$\nabla{}L\in\mathbb{R}^{N\times{}n}$</span> (the Euclidean gradient). </p><p>The function computes the Riemannian gradient with respect to the canonical <a href="../../library/#GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}"><code>metric</code></a>.</p><p>The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - Y(\nabla{}L)^TY\]</p><p>Note the property <span>$Y^T\mathrm{rgrad}(Y, \nabla{}L)\in\mathcal{S}_\mathrm{skew}(n).$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = StiefelManifold([1 0 ; 0 1 ; 0 0; 0 0])
Δ = [1 2; 3 4; 5 6; 7 8]
rgrad(Y, Δ)

# output

4×2 Matrix{Int64}:
 0  -1
 1   0
 5   6
 7   8</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/stiefel_manifold.jl#LL26-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.rgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rgrad(Y::GrassmannManifold, e_grad::AbstractMatrix)</code></pre><p>Compute the Riemannian gradient at <span>$Y\in{}Gr(n, N)$</span>. </p><p>These gradient have the property that they are orthogonal to the space spanned by <span>$Y$</span>.</p><p>The precise form of the mapping is: </p><p class="math-container">\[\mathtt{rgrad}(Y, \nabla{}L) \mapsto \nabla{}L - YY^T\nabla{}L\]</p><p>Note the property <span>$Y^T\mathrm{rgrad}(Y, \nabla{}L) = \mathbb{O}.$</span></p><p>Also see <a href="../../library/#GeometricMachineLearning.rgrad-Tuple{StiefelManifold, AbstractMatrix}"><code>rgrad(::StiefelManifold, ::AbstractMatrix)</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = GrassmannManifold([1 0 ; 0 1 ; 0 0; 0 0])
Δ = [1 2; 3 4; 5 6; 7 8]
rgrad(Y, Δ)

# output

4×2 Matrix{Int64}:
 0  0
 0  0
 5  6
 7  8</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/grassmann_manifold.jl#LL8-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.metric-Tuple{StiefelManifold, AbstractMatrix, AbstractMatrix}-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Implements the canonical Riemannian metric for the Stiefel manifold:</p><p class="math-container">\[g_Y: (\Delta_1, \Delta_2) \mapsto \mathrm{tr}(\Delta_1^T(\mathbb{I} - \frac{1}{2}YY^T)\Delta_2).\]</p><p>It is called with: </p><ul><li><code>Y::StiefelManifold</code></li><li><code>Δ₁::AbstractMatrix</code></li><li><code>Δ₂::AbstractMatrix</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/stiefel_manifold.jl#LL62-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.metric-Tuple{GrassmannManifold, AbstractMatrix, AbstractMatrix}-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.metric</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">metric(Y::GrassmannManifold, Δ₁::AbstractMatrix, Δ₂::AbstractMatrix)</code></pre><p>Compute the metric for vectors <code>Δ₁</code> and <code>Δ₂</code> at <code>Y</code>. </p><p>The representation of the Grassmann manifold is realized as a quotient space of the Stiefel manifold. </p><p>The metric for the Grassmann manifold is:</p><p class="math-container">\[g^{Gr}_Y(\Delta_1, \Delta_2) = g^{St}_Y(\Delta_1, \Delta_2) = \mathrm{Tr}(\Delta_1^T (\mathbb{I} - Y Y^T) \Delta_2) = \mathrm{Tr}(\Delta_1^T \Delta_2).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/grassmann_manifold.jl#LL46-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.Ω</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Ω(Y::StiefelManifold{T}, Δ::AbstractMatrix{T}) where T</code></pre><p>Perform <em>canonical horizontal lift</em> for the Stiefel manifold:</p><p class="math-container">\[    \Delta \mapsto (\mathbb{I} - \frac{1}{2}YY^T)\Delta{}Y^T - Y\Delta^T(\mathbb{I} - \frac{1}{2}YY^T).\]</p><p>Internally this performs </p><pre><code class="language-julia hljs">SkewSymMatrix(2 * (I(n) - .5 * Y * Y&#39;) * Δ * Y&#39;)</code></pre><p>to save memory. </p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
E = StiefelManifold(StiefelProjection(5, 2))
Δ = [0. -1.; 1. 0.; 2. 3.; 4. 5.; 6. 7.]
GeometricMachineLearning.Ω(E, Δ)

# output

5×5 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0  -1.0  -2.0  -4.0  -6.0
 1.0   0.0  -3.0  -5.0  -7.0
 2.0   3.0   0.0  -0.0  -0.0
 4.0   5.0   0.0   0.0  -0.0
 6.0   7.0   0.0   0.0   0.0</code></pre><p>Note that the output of <code>Ω</code> is a skew-symmetric matrix, i.e. an element of <span>$\mathfrak{g}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/stiefel_manifold.jl#LL130-L166">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T-manifolds-homogeneous_spaces" href="#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T-manifolds-homogeneous_spaces"><code>GeometricMachineLearning.Ω</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Ω(Y::GrassmannManifold{T}, Δ::AbstractMatrix{T}) where T</code></pre><p>Perform the <em>canonical horizontal lift</em> for the Grassmann manifold:</p><p class="math-container">\[    \Delta \mapsto \Omega^{St}(Y, Δ),\]</p><p>where <span>$\Omega^{St}$</span> is the canonical horizontal lift for the Stiefel manifold.</p><pre><code class="language-julia hljs">using GeometricMachineLearning
E = GrassmannManifold(StiefelProjection(5, 2))
Δ = [0. 0.; 0. 0.; 2. 3.; 4. 5.; 6. 7.]
GeometricMachineLearning.Ω(E, Δ)

# output

5×5 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0  -0.0  -2.0  -4.0  -6.0
 0.0   0.0  -3.0  -5.0  -7.0
 2.0   3.0   0.0  -0.0  -0.0
 4.0   5.0   0.0   0.0  -0.0
 6.0   7.0   0.0   0.0   0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/manifolds/grassmann_manifold.jl#LL81-L107">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[6]</dt><dd><div>P.-A. Absil, R. Mahony and R. Sepulchre. <em>Riemannian geometry of Grassmann manifolds with a view on algorithmic computation</em>. Acta Applicandae Mathematica <strong>80</strong>, 199–220 (2004).</div></dd><dt>[51]</dt><dd><div>T. Frankel. <em>The geometry of physics: an introduction</em> (Cambridge university press, Cambridge, UK, 2011).</div></dd><dt>[15]</dt><dd><div>T. Bendokat and R. Zimmermann. <em>The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications</em>, arXiv preprint arXiv:2108.12447 (2021).</div></dd></dl></div><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Recall that a Lie group is a manifold that also has group structure. We say that a Lie group <span>$G$</span> <em>acts</em> on a manifold <span>$\mathcal{M}$</span> if there is a map <span>$G\times\mathcal{M} \to \mathcal{M}$</span> such that <span>$(ab)x = a(bx)$</span> for <span>$a,b\in{}G$</span> and <span>$x\in\mathcal{M}$</span>. For us the Lie algebra belonging to a Lie group, denoted by <span>$\mathfrak{g}$</span>, is the tangent space to the identity element <span>$T_\mathbb{I}G$</span>. </li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../riemannian_manifolds/">« Riemannian Manifolds</a><a class="docs-footer-nextpage" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Tuesday 2 July 2024 08:48">Tuesday 2 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
