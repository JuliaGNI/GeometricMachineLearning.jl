<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Riemannian Manifolds · GeometricMachineLearning.jl</title><meta name="title" content="Riemannian Manifolds · GeometricMachineLearning.jl"/><meta property="og:title" content="Riemannian Manifolds · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Riemannian Manifolds · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/riemannian_manifolds/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/riemannian_manifolds/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/manifolds/riemannian_manifolds/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li class="is-active"><a class="tocitem" href>Riemannian Manifolds</a><ul class="internal"><li><a class="tocitem" href="#Geodesic-Sprays-and-the-Exponential-Map"><span>Geodesic Sprays and the Exponential Map</span></a></li><li><a class="tocitem" href="#The-Riemannian-Gradient"><span>The Riemannian Gradient</span></a></li><li><a class="tocitem" href="#Gradient-Flows-and-Riemannian-Optimization"><span>Gradient Flows and Riemannian Optimization</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Optimizers</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Network Losses</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../library/">Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manifolds</a></li><li class="is-active"><a href>Riemannian Manifolds</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Riemannian Manifolds</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/manifolds/riemannian_manifolds.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Riemannian-Manifolds"><a class="docs-heading-anchor" href="#Riemannian-Manifolds">Riemannian Manifolds</a><a id="Riemannian-Manifolds-1"></a><a class="docs-heading-anchor-permalink" href="#Riemannian-Manifolds" title="Permalink"></a></h1><p>A Riemannian manifold is a manifold <span>$\mathcal{M}$</span> that we endow with a mapping <span>$g$</span> that smoothly<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> assigns a <a href="../metric_and_vector_spaces/#(Topological)-Metric-Spaces">metric</a> <span>$g_x$</span> to each tangent space <span>$T_x\mathcal{M}$</span>. By a slight abuse of notation we will also refer to this <span>$g$</span> as a <em>metric</em>.</p><p>After having defined a metric <span>$g$</span> we can <em>associate a length</em> to each curve <span>$\gamma:[0, t] \to \mathcal{M}$</span> through: </p><p class="math-container">\[L(\gamma) = \int_0^t \sqrt{g_{\gamma(s)}(\gamma&#39;(s), \gamma&#39;(s))}ds.\]</p><p>This <span>$L$</span> turns <span>$\mathcal{M}$</span> into a metric space:</p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>The <strong>metric on a Riemannian manifold</strong> <span>$\mathcal{M}$</span> is </p><p class="math-container">\[d(x, y) = \mathrm{inf}_{\text{$\gamma(0) = x$ and $\gamma(t) = y$}}L(\gamma),\]</p><p>where <span>$t$</span> can be chosen arbitrarily.</p></div></div><p>If a curve is minimal with respect to the function <span>$L$</span> we call it the <em>shortest curve</em> or a geodesic. So we say that a curve <span>$\gamma:[0, t]\to\mathcal{M}$</span> is a geodesic if there is no shorter curve that can connect two points in <span>$\gamma([0, t])$</span>, i.e. </p><p class="math-container">\[d(\gamma(t_i), \gamma(t_f)) = \int_{t_i}^{t_f}\sqrt{g_{\gamma(s)}(\gamma&#39;(s), \gamma&#39;(s))}ds,\]</p><p>for any <span>$t_i, t_f\in[0, t]$</span>.</p><p>An important result of Riemannian geometry states that there exists a vector field <span>$X$</span> on <span>$T\mathcal{M}$</span>, called the <em>geodesic spray</em>, whose integral curves are derivatives of geodesics.</p><h2 id="Geodesic-Sprays-and-the-Exponential-Map"><a class="docs-heading-anchor" href="#Geodesic-Sprays-and-the-Exponential-Map">Geodesic Sprays and the Exponential Map</a><a id="Geodesic-Sprays-and-the-Exponential-Map-1"></a><a class="docs-heading-anchor-permalink" href="#Geodesic-Sprays-and-the-Exponential-Map" title="Permalink"></a></h2><p>To every Riemannian manifold we can naturally associate a vector field called the <em>geodesic spray</em> or <em>geodesic equation</em>. For our purposes it is enough to state that this vector field is unique and well-defined [<a href="../../references/#do1992riemannian">5</a>].</p><p>The important property of the geodesic spray is</p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>Given an initial point <span>$x$</span> and an initial velocity <span>$v_x$</span>, an integral curve for the geodesic spray is of the form <span>$t \mapsto (\gamma_{v_x}(t), \gamma_{v_x}&#39;(t))$</span> where <span>$\gamma_{v_x}$</span> is a geodesic. We further have the property that the integral curve for the geodesic spray for an initial point <span>$x$</span> and an initial velocity <span>$\eta\cdot{}v_x$</span> (where <span>$\eta$</span> is a scalar) is of the form <span>$t \mapsto (\gamma_{\eta\cdot{}v_x}(t), \gamma_{\eta\cdot{}v_x}&#39;(t)) = (\gamma_{v_x}(\eta\cdot{}t), \eta\cdot\gamma_{v_x}&#39;(\eta\cdot{}t)).$</span></p></div></div><p>It is therefore customary to introduce the <em>exponential map</em> <span>$\exp:T_x\mathcal{M}\to\mathcal{M}$</span> as</p><p class="math-container">\[\exp(v_x) := \gamma_{v_x}(1),\]</p><p>and we see that <span>$\gamma_{v_x}(t) = \exp(t\cdot{}v_x)$</span>. In <code>GeometricMachineLearning</code> we denote the exponential map by <a href="../../library/#GeometricMachineLearning.geodesic-Union{Tuple{GrassmannLieAlgHorMatrix{T, ST} where ST&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>geodesic</code></a> to avoid confusion with the matrix exponential map<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>:</p><p class="math-container">\[    \mathtt{geodesic}(x, v_x) \equiv \exp(v_x).\]</p><p>We give an example here:</p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = rand(StiefelManifold, 3, 1)

v = 5 * rand(3, 1)
Δ = v - Y * (v&#39; * Y)


    # height = 75.,

# plot a sphere with radius one and origin 0
surface!(ax, Main.sphere(1., [0., 0., 0.])...; alpha = .5, transparency = true)

point_vec = ([Y[1]], [Y[2]], [Y[3]])
scatter!(ax, point_vec...; color = morange, marker = :star5)

arrow_vec = ([Δ[1]], [Δ[2]], [Δ[3]])
arrows!(ax, point_vec..., arrow_vec...; color = mred, linewidth = .02)</code></pre><object type="image/svg+xml" class="display-light-only" data=../sphere_with_tangent_vec.png></object><object type="image/svg+xml" class="display-dark-only" data=../sphere_with_tangent_vec_dark.png></object><p>We now solve the geodesic spray for <span>$\eta\cdot\Delta$</span> for <span>$\eta = 0.1, 0.2, 0.3, \ldots, 2.5$</span> and plot the corresponding points:</p><pre><code class="language-julia hljs">Δ_increments = [Δ * η for η in 0.1 : 0.1 : 5.5]

Y_increments = [geodesic(Y, Δ_increment) for Δ_increment in Δ_increments]

fig, ax = set_up_plot(; theme = theme)
for Y_increment in Y_increments
    scatter!(ax, [Y_increment[1]], [Y_increment[2]], [Y_increment[3]];
        color = mred, markersize = 5)
end

fig</code></pre><object type="image/svg+xml" class="display-light-only" data=../sphere_with_tangent_vec_and_geodesic.png></object><object type="image/svg+xml" class="display-dark-only" data=../sphere_with_tangent_vec_and_geodesic_dark.png></object><p>So a geodesic can be seen as the <em>equivalent of a straight line</em> on a manifold. Also note that we drew a random element form <a href="../../library/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> here and not from <span>$S^2$</span>. This is because <a href="../homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifolds</a> are more general spaces than <span>$S^n$</span> and also comprise them. </p><h2 id="The-Riemannian-Gradient"><a class="docs-heading-anchor" href="#The-Riemannian-Gradient">The Riemannian Gradient</a><a id="The-Riemannian-Gradient-1"></a><a class="docs-heading-anchor-permalink" href="#The-Riemannian-Gradient" title="Permalink"></a></h2><p>The Riemannian gradient of a function <span>$L\mathcal{M}\to\mathbb{R}$</span> is a vector field<sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup> <span>$\mathrm{grad}^gL$</span> (or simply <span>$\mathrm{grad}L$</span>) for which we have</p><p class="math-container">\[    g_x(\mathrm{grad}_x^gL, v_x) = (\nabla_{\varphi_U(x)}(L\circ\varphi_U^{-1}))^T \varphi_U&#39;(v_x), \]</p><p>where </p><p class="math-container">\[ \nabla_xf = \begin{pmatrix} \frac{\partial{}f}{\partial{}x_1} \\ \cdots \\ \frac{\partial{}f}{\partial{}x_n} \end{pmatrix},\]</p><p>is the Euclidean gradient. By the <em>non-degeneracy</em> of <span>$g$</span> the Riemannian gradient always exists [<a href="../../references/#bishop1980tensor">3</a>]. We will give specific examples of this when discussing the <a href="../homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifold</a> and the <a href="../homogeneous_spaces/#The-Grassmann-Manifold">Grassmann manifold</a>. </p><h2 id="Gradient-Flows-and-Riemannian-Optimization"><a class="docs-heading-anchor" href="#Gradient-Flows-and-Riemannian-Optimization">Gradient Flows and Riemannian Optimization</a><a id="Gradient-Flows-and-Riemannian-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-Flows-and-Riemannian-Optimization" title="Permalink"></a></h2><p>In <code>GeometricMachineLearning</code> we can include weights in neural networks that are part of a manifold. Training such neural networks amounts to <em>Riemannian optimization</em> and hence solving the <em>gradient flow</em> equation. The gradient flow equation is given by</p><p class="math-container">\[X(x) = - \mathrm{grad}_xL.\]</p><p>Solving this gradient flow equation will then lead us to a local minimum on <span>$\mathcal{M}$</span>. This will be elaborated on when talking about <a href="../../optimizers/optimizer_framework/#Neural-Network-Optimizers">optimizers</a>. In practice we cannot solve the gradient flow equation directly and have to rely on approximations. The most straightforward approximation (and one that serves as a basis for all the optimization algorithms in <code>GeometricMachineLearning</code>) is to take the point <span>$(x, X(x))$</span> as an initial condition for the geodesic spray and then solve the ODE for a small time step. Such an update rule, i.e. </p><p class="math-container">\[x^{(t)} \leftarrow \gamma_{X(x^{(t-1)})}(\Delta{}t)\text{ with $\Delta{}t$ the time step},\]</p><p>we call the <em>gradient optimization scheme</em>.</p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T-manifolds-riemannian_manifolds" href="#GeometricMachineLearning.geodesic-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T-manifolds-riemannian_manifolds"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">geodesic(Y::Manifold, Δ)</code></pre><p>Take as input an element of a manifold <code>Y</code> and a tangent vector in <code>Δ</code> in the corresponding tangent space and compute the geodesic (exponential map).</p><p>In different notation: take as input an element <span>$x$</span> of <span>$\mathcal{M}$</span> and an element of <span>$T_x\mathcal{M}$</span> and return <span>$\mathtt{geodesic}(x, v_x) = \exp(v_x).$</span> For example: </p><pre><code class="language-julia hljs">Y = rand(StiefelManifold{Float64}, N, n)
Δ = rgrad(Y, rand(N, n))
geodesic(Y, Δ)</code></pre><p>See the docstring for <a href="../../library/#GeometricMachineLearning.rgrad-Tuple{GrassmannManifold, AbstractMatrix}"><code>rgrad</code></a> for details on this function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/dfc295a8332f5a63feccb4b30d5ee4807824747b/src/optimizers/manifold_related/retractions.jl#LL16-L30">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[2]</dt><dd><div>S. Lang. <em>Fundamentals of differential geometry</em>. Vol. 191 (Springer Science &amp; Business Media, 2012).</div></dd><dt>[5]</dt><dd><div>M. P. Do Carmo and J. Flaherty Francis. <em>Riemannian geometry</em>. Vol. 2 (Springer, 1992).</div></dd></dl></div><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Smooth here refers to the fact that <span>$g:\mathcal{M}\to\text{(Space of Metrics)}$</span> has to be a smooth map. But in order to discuss this in detail we would have to define a topology on the space of metrics. A more detailed discussion can be found in [<a href="../../references/#lang2012fundamentals">2</a>, <a href="../../references/#bishop1980tensor">3</a>, <a href="../../references/#do1992riemannian">5</a>].</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>The Riemannian exponential map and the matrix exponential map coincide for many matrix Lie groups.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>We also write <span>$\mathrm{grad}^gL(x) = \mathrm{grad}^g_xL.$</span></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../existence_and_uniqueness_theorem/">« Differential Equations and the EAU theorem</a><a class="docs-footer-nextpage" href="../homogeneous_spaces/">Homogeneous Spaces »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Tuesday 2 July 2024 08:48">Tuesday 2 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
