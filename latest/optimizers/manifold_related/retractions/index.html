<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Retractions · GeometricMachineLearning.jl</title><meta name="title" content="Retractions · GeometricMachineLearning.jl"/><meta property="og:title" content="Retractions · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Retractions · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/optimizers/manifold_related/retractions/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/optimizers/manifold_related/retractions/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/optimizers/manifold_related/retractions/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizer_framework/">Optimizers</a></li><li class="is-active"><a class="tocitem" href>Retractions</a><ul class="internal"><li><a class="tocitem" href="#Classical-Retractions"><span>Classical Retractions</span></a></li><li><a class="tocitem" href="#In-GeometricMachineLearning"><span>In <code>GeometricMachineLearning</code></span></a></li><li><a class="tocitem" href="#Retractions-for-Homogeneous-Spaces"><span>Retractions for Homogeneous Spaces</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../../../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../../architectures/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../../architectures/symplectic_transformer/">Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../../tutorials/sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../../../tutorials/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../../tutorials/mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../../tutorials/grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../../tutorials/matrix_softmax/">Matrix Attention</a></li><li><a class="tocitem" href="../../../tutorials/volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../../tutorials/symplectic_transformer/">Symplectic Transformer</a></li><li><a class="tocitem" href="../../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../../references/">References</a></li><li><a class="tocitem" href="../../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Optimizer</a></li><li class="is-active"><a href>Retractions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Retractions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/optimizers/manifold_related/retractions.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Retractions"><a class="docs-heading-anchor" href="#Retractions">Retractions</a><a id="Retractions-1"></a><a class="docs-heading-anchor-permalink" href="#Retractions" title="Permalink"></a></h1><p>In practice we usually do not solve the geodesic equation exactly in each optimization step (even though this is possible and computationally feasible), but prefer approximations that are called &quot;retractions&quot; [<a href="../../../references/#absil2008optimization">22</a>] for numerical stability. The definition of a retraction in <code>GeometricMachineLearning</code> is slightly different from how it is usually defined in textbooks [<a href="../../../references/#hairer2006geometric">1</a>, <a href="../../../references/#absil2008optimization">22</a>]. We discuss these differences here.</p><h2 id="Classical-Retractions"><a class="docs-heading-anchor" href="#Classical-Retractions">Classical Retractions</a><a id="Classical-Retractions-1"></a><a class="docs-heading-anchor-permalink" href="#Classical-Retractions" title="Permalink"></a></h2><p>By &quot;classical retraction&quot; we here mean the textbook definition. </p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>A <strong>classical retraction</strong> is a smooth map</p><p class="math-container">\[R: T\mathcal{M}\to\mathcal{M}:(x,v)\mapsto{}R_x(v),\]</p><p>such that each curve <span>$c(t) := R_x(tv)$</span> is a local approximation of a geodesic, i.e. the following two conditions hold:</p><ol><li><span>$c(0) = x$</span> and </li><li><span>$c&#39;(0) = v.$</span></li></ol></div></div><p>Perhaps the most common example for matrix manifolds is the <em>Cayley retraction</em>. It is a retraction for many matrix Lie groups [<a href="../../../references/#hairer2006geometric">1</a>, <a href="../../../references/#bendokat2021real">37</a>, <a href="../../../references/#gao2021riemannian">38</a>].</p><div class="admonition is-info"><header class="admonition-header">Example</header><div class="admonition-body"><p>The <strong>Cayley retraction</strong> for <span>$V\in{}T_\mathbb{I}G\equiv\mathfrak{g}$</span> is defined as</p><p class="math-container">\[\mathrm{Cayley}(V) = \left(\mathbb{I} - \frac{1}{2}V\right)^{-1}\left(\mathbb{I} +\frac{1}{2}V\right).\]</p></div></div><p>We show that the Cayley transform is a retraction for <span>$G = SO(N)$</span> at <span>$\mathbb{I}\in{}SO(N)$</span>:</p><details class="admonition is-details"><summary class="admonition-header">Proof</summary><div class="admonition-body"><p>The Cayley transform trivially satisfies <span>$\mathrm{Cayley}(\mathbb{O}) = \mathbb{I}$</span>. So what we have to show is the second condition for a retraction and that <span>$\mathrm{Cayley}(V)\in{}SO(N)$</span>. For this take <span>$V\in\mathfrak{so}(N).$</span> We then have</p><p class="math-container">\[\frac{d}{dt}\bigg|_{t = 0}\mathrm{Cayley}(tV) = \frac{d}{dt}\bigg|_{t = 0}\left(\mathbb{I} - \frac{1}{2}tV\right)^{-1}\left(\mathbb{I} +\frac{1}{2}tV\right) = \frac{1}{2}V - \frac{1}{2}V^T = V,\]</p><p>which satisfies the second condition. We further have</p><p class="math-container">\[\frac{d}{dt}\bigg|_{t = 0}(\mathrm{Cayley}(tV))^T\mathrm{Cayley}(tV) = (\frac{1}{2}V - \frac{1}{2}V^T)^T + \frac{1}{2}V - \frac{1}{2}V^T = 0.\]</p><p>This proofs that the Cayley transform maps to <span>$SO(N)$</span>.</p></div></details><p>We should mention that the factor <span>$\frac{1}{2}$</span> is sometimes left out in the definition of the Cayley transform when used in different contexts. But it is necessary for defining a retraction as without it the second condition is not satisfied.</p><div class="admonition is-success"><header class="admonition-header">Remark</header><div class="admonition-body"><p>We can also use the Cayley retraction at a different point than the identity <span>$\mathbb{I}.$</span> For this consider <span>$\bar{A}\in{}SO(N)$</span> and <span>$\bar{B}\in{}T_{\bar{A}}SO(N) = \{\bar{B}\in\mathbb{R}^{N\times{}N}: \bar{A}^T\bar{B} + \bar{B}^T\bar{A} = \mathbb{O}\}$</span>. We then have <span>$\bar{A}^T\bar{B}\in\mathfrak{so}(N)$</span> and </p><p class="math-container">\[    \overline{\mathrm{Cayley}}: T_{\bar{A}}SO(N) \to SO(N), \bar{B} \mapsto \bar{A}\mathrm{Cayley}(\bar{A}^T\bar{B}),\]</p><p>is a retraction <span>$\forall{}\bar{A}\in{}SO(N)$</span>.</p></div></div><p>As a retraction is always an approximation of the geodesic map, we now compare the <a href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>cayley</code></a> retraction for the example we introduced along <a href="../../../manifolds/riemannian_manifolds/#Geodesic-Sprays-and-the-Exponential-Map">Riemannian manifolds</a>:</p><pre><code class="language-julia hljs">η_increments = 0.2 : 0.2 : 5.4
Δ_increments = [Δ * η for η in η_increments]

Y_increments_geodesic = [geodesic(Y, Δ_increment) for Δ_increment in Δ_increments]
Y_increments_cayley = [cayley(Y, Δ_increment) for Δ_increment in Δ_increments]</code></pre><p><img src="../retraction_comparison_light.png" alt="Comparison between the geodesic and the Cayley retraction."/> <img src="../retraction_comparison_dark.png" alt="Comparison between the geodesic and the Cayley retraction."/></p><p>We see that for small <span>$\Delta$</span> increments the Cayley retraction seems to match the geodesic retraction very well, but for larger values there is a notable discrepancy. We can plot this discrepancy directly: </p><pre><code class="language-julia hljs">zip_ob = zip(Y_increments_geodesic, Y_increments_cayley, axes(Y_increments_geodesic, 1))
discrepancies = [norm(Y_geo_inc - Y_cay_inc) for (Y_geo_inc, Y_cay_inc, _) in zip_ob]
nothing</code></pre><p><img src="../retraction_discrepancy_light.png" alt="Discrepancy between the geodesic and the Cayley retraction."/> <img src="../retraction_discrepancy_dark.png" alt="Discrepancy between the geodesic and the Cayley retraction."/></p><h2 id="In-GeometricMachineLearning"><a class="docs-heading-anchor" href="#In-GeometricMachineLearning">In <code>GeometricMachineLearning</code></a><a id="In-GeometricMachineLearning-1"></a><a class="docs-heading-anchor-permalink" href="#In-GeometricMachineLearning" title="Permalink"></a></h2><p>The way we use <em>retractions</em><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> in <code>GeometricMachineLearning</code> is slightly different from their classical definition:</p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>Given a section <span>$\lambda:\mathcal{M}\to{}G,$</span> where <span>$\mathcal{M}$</span> is a homogeneous space, a <strong>retraction</strong> is a map <span>$\mathrm{Retraction}:\mathfrak{g}^\mathrm{hor}\to{}G$</span> such that </p><p class="math-container">\[\Delta \mapsto \lambda(Y)\mathrm{Retraction}(\lambda(Y)^{-1}\Omega(\Delta)\lambda(Y))E,\]</p><p>is a classical retraction.</p></div></div><p>This map <span>$\mathrm{Retraction}$</span> is also what was visualized in the figure on <a href="../../optimizer_framework/#Generalization-to-Homogeneous-Spaces">the general optimization framework</a>. We now discuss how the geodesic retraction (exponential map) and the Cayley retraction are implemented in <code>GeometricMachineLearning</code>.</p><h2 id="Retractions-for-Homogeneous-Spaces"><a class="docs-heading-anchor" href="#Retractions-for-Homogeneous-Spaces">Retractions for Homogeneous Spaces</a><a id="Retractions-for-Homogeneous-Spaces-1"></a><a class="docs-heading-anchor-permalink" href="#Retractions-for-Homogeneous-Spaces" title="Permalink"></a></h2><p>Here we harness special properties of homogeneous spaces to obtain computationally efficient retractions for the <a href="../../../manifolds/homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifold</a> and the <a href="../../../manifolds/homogeneous_spaces/#The-Grassmann-Manifold">Grassmann manifold</a>. This is also discussed in e.g. [<a href="../../../references/#bendokat2020grassmann">23</a>, <a href="../../../references/#bendokat2021real">37</a>].</p><p>The <em>geodesic retraction</em> is a retraction whose associated curve is also the unique geodesic. For many matrix Lie groups (including <span>$SO(N)$</span>) geodesics are obtained by simply evaluating the exponential map [<a href="../../../references/#absil2008optimization">22</a>, <a href="../../../references/#o1983semi">39</a>]:</p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>The geodesic on a compact matrix Lie group <span>$G$</span> with bi-invariant metric for <span>$\bar{B}\in{}T_{\bar{A}}G$</span> is simply</p><p class="math-container">\[\gamma(t) = \exp(t\cdot{}\bar{B}\bar{A}^{-1})\bar{A} = A\exp(t\cdot{}\bar{A}^{-1}\bar{B}^n),\]</p><p>where <span>$\exp:\mathfrak{g}\to{}G$</span> is the matrix exponential map.</p></div></div><p>The last equality in the equation above is a result of:</p><p class="math-container">\[\begin{aligned}
\exp(\bar{A}^{-1}\hat{B}\bar{A}) = \sum_{k=1}^\infty\frac{1}{k!}(\bar{A}^{-1}\hat{B}\bar{A})^k &amp; = \sum_{k=1}^\infty \frac{1}{k!}\underbrace{(\bar{A}^{-1}\hat{B}\bar{A})\cdots(A^{-1}\hat{B}\bar{A})}_{\text{$k$ times}} \\ &amp; = \sum_{k=1}^\infty \frac{1}{k!} \bar{A}^{-1} \hat{B}^k \bar{A} = \bar{A}^{-1}\exp(\hat{B})\bar{A}.
\end{aligned}\]</p><p>Because <span>$SO(N)$</span> is compact and we furnish it with the canonical metric, i.e. </p><p class="math-container">\[    g:T_{\bar{A}}G\times{}T_{\bar{A}}G \to \mathbb{R}, (B_1, B_2) \mapsto \mathrm{Tr}(B_1^TB_2) = \mathrm{Tr}((B_1\bar{A}^{-1})^T(B_2\bar{A}^{-1})),\]</p><p>its geodesics are thus equivalent to the exponential maps. We now use this observation to obtain an expression for the geodesics on the <a href="../../../manifolds/homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifold</a>. We use the following theorem from [<a href="../../../references/#o1983semi">39</a>, Proposition 25.7]:</p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>The geodesics for a naturally reductive homogeneous space <span>$\mathcal{M}$</span> starting at <span>$Y$</span> are given by:</p><p class="math-container">\[\gamma_{\Delta}(t) = \exp(t\cdot\Omega(\Delta))Y,\]</p><p>where the <span>$\exp$</span> is the exponential map for the Lie group <span>$G$</span> corresponding to <span>$\mathcal{M}$</span>.</p></div></div><p>The theorem requires the homogeneous space to be naturally reductive: </p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>A homogeneous space is called <strong>naturally reductive</strong> if the following two conditions hold:</p><ol><li><span>$\bar{A}^{-1}\bar{B}\bar{A}\in\mathfrak{g}^\mathrm{hor}$</span> for every <span>$\bar{B}\in\mathfrak{g}^\mathrm{hor}$</span> and <span>$\bar{A}\in\exp(\mathfrak{g}^\mathrm{ver}$</span>),</li><li><span>$g([X, Y]^\mathrm{hor}, Z) = g(X, [Y, Z]^\mathrm{hor})$</span> for all <span>$X, Y, Z \in \mathfrak{g}^\mathrm{hor}$</span>,</li></ol><p>where <span>$[X, Y]^\mathrm{hor} = \Omega(XYE - YXE)$</span>. If only the first condition holds the homogeneous space is called <strong>reductive</strong> (but not <strong>naturally reductive</strong>).</p></div></div><p>We state here without proof that the <a href="../../../manifolds/homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifold</a> and the <a href="../../../manifolds/homogeneous_spaces/#The-Grassmann-Manifold">Grassmann manifold</a> are naturally reductive. We can however provide empirical evidence here:</p><pre><code class="language-julia hljs">B̄ = rand(SkewSymMatrix, 6) # ∈ 𝔤
Ā = exp(B̄ - StiefelLieAlgHorMatrix(B̄, 3)) # ∈ exp(𝔤ᵛᵉʳ)

X = rand(StiefelLieAlgHorMatrix, 6, 3) # ∈ 𝔤ʰᵒʳ
Y = rand(StiefelLieAlgHorMatrix, 6, 3) # ∈ 𝔤ʰᵒʳ
Z = rand(StiefelLieAlgHorMatrix, 6, 3) # ∈ 𝔤ʰᵒʳ

Ā&#39; * X * Ā # this has to be in 𝔤ʰᵒʳ for St(3, 6) to be reductive</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">6×6 Matrix{Float64}:
 0.0       -0.914247  -0.387374  -0.650933  -0.741877  -0.7678
 0.914247   0.0       -0.771916  -0.454759  -0.869684  -0.80972
 0.387374   0.771916   0.0       -0.924238  -0.292897  -0.749455
 0.650933   0.454759   0.924238   0.0        0.0        0.0
 0.741877   0.869684   0.292897   0.0        0.0        0.0
 0.7678     0.80972    0.749455   0.0        0.0        0.0</code></pre><p>verifies the first property and</p><pre><code class="language-julia hljs">adʰᵒʳ(X, Y) = StiefelLieAlgHorMatrix(X * Y - Y * X, 3)

tr(adʰᵒʳ(X, Y)&#39; * Z) ≈ tr(X&#39; * adʰᵒʳ(Y, Z))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>verifies the second.</p><p>In <code>GeometricMachineLearning</code> we always work with elements in <span>$\mathfrak{g}^\mathrm{hor}$</span> and the Lie group <span>$G$</span> is always <span>$SO(N)$</span>. We hence use:</p><p class="math-container">\[    \gamma_\Delta(t) = \exp(\lambda(Y)\lambda(Y)^{-1}\Omega(\Delta)\lambda(Y)\lambda(Y)^{-1})Y = \lambda(Y)\exp(\lambda(Y)^{-1}\Omega(\Delta)\lambda(Y))E.\]</p><p>Based on this we define the maps: </p><p class="math-container">\[\mathtt{geodesic}: \mathfrak{g}^\mathrm{hor} \to G, \bar{B} \mapsto \exp(\bar{B}),\]</p><p>and</p><p class="math-container">\[\mathtt{cayley}: \mathfrak{g}^\mathrm{hor} \to G, \bar{B} \mapsto \mathrm{Cayley}(\bar{B}),\]</p><p>where <span>$\bar{B} = \lambda(Y)^{-1}\Omega(\Delta)\lambda(Y)$</span>. These expressions for <code>geodesic</code> and <code>cayley</code> are the ones that we typically use in <code>GeometricMachineLearning</code> for computational reasons. We show how we can utilize the sparse structure of <span>$\mathfrak{g}^\mathrm{hor}$</span> for computing the geodesic retraction and the Cayley retraction (i.e. the expressions <span>$\exp(\bar{B})$</span> and <span>$\mathrm{Cayley}(\bar{B})$</span> for <span>$\bar{B}\in\mathfrak{g}^\mathrm{hor}$</span>). Similar derivations can be found in [<a href="../../../references/#bendokat2021real">37</a>, <a href="../../../references/#celledoni2000approximating">40</a>, <a href="../../../references/#fraikin2007optimization">41</a>].</p><div class="admonition is-success"><header class="admonition-header">Remark</header><div class="admonition-body"><p>Further note that, even though the global section <span>$\lambda:\mathcal{M} \to G$</span> is not unique, the final geodesic <span>$\gamma_\Delta(t) = \lambda(Y)\exp(\lambda(Y)^{-1}\Omega(\Delta)\lambda(Y))E$</span> does not depend on the particular section we choose.</p></div></div><h3 id="The-Geodesic-Retraction"><a class="docs-heading-anchor" href="#The-Geodesic-Retraction">The Geodesic Retraction</a><a id="The-Geodesic-Retraction-1"></a><a class="docs-heading-anchor-permalink" href="#The-Geodesic-Retraction" title="Permalink"></a></h3><p>An element <span>$\bar{B}$</span> of <span>$\mathfrak{g}^\mathrm{hor}$</span> can be written as:</p><p class="math-container">\[\bar{B} = \begin{bmatrix}
    A &amp; -B^T \\ 
    B &amp; \mathbb{O}
\end{bmatrix} = \begin{bmatrix}  \frac{1}{2}A &amp; \mathbb{I} \\ B &amp; \mathbb{O} \end{bmatrix} \begin{bmatrix}  \mathbb{I} &amp; \mathbb{O} \\ \frac{1}{2}A &amp; -B^T  \end{bmatrix} =: B&#39;(B&#39;&#39;)^T,\]</p><p>where we exploit the sparse structure of the array, i.e. it is a multiplication of a <span>$N\times2n$</span> with a <span>$2n\times{}N$</span> matrix.</p><p>We further use the following: </p><p class="math-container">\[    \begin{aligned}
    \exp(B&#39;(B&#39;&#39;)^T) &amp; = \sum_{n=0}^\infty \frac{1}{n!} (B&#39;(B&#39;&#39;)^T)^n = \mathbb{I} + \sum_{n=1}^\infty \frac{1}{n!} B&#39;((B&#39;&#39;)^TB&#39;)^{n-1}(B&#39;&#39;)^T \\
    &amp; = \mathbb{I} + B&#39;\left( \sum_{n=1}^\infty \frac{1}{n!} ((B&#39;&#39;)^TB&#39;)^{n-1} \right)B&#39;&#39; =: \mathbb{I} + B&#39;\mathfrak{A}(B&#39;, B&#39;&#39;)B&#39;&#39;,
    \end{aligned}\]</p><p>where we defined <span>$\mathfrak{A}(B&#39;, B&#39;&#39;) := \sum_{n=1}^\infty \frac{1}{n!} ((B&#39;&#39;)^TB&#39;)^{n-1}.$</span> Note that evaluating <span>$\mathfrak{A}$</span> relies on computing products of <em>small</em> matrices of size <span>$2n\times2n.$</span> We do this by relying on a simple Taylor expansion (see the docstring for <a href="#GeometricMachineLearning.𝔄-Tuple{AbstractMatrix}"><code>GeometricMachineLearning.𝔄</code></a>). </p><p>The final expression we obtain is: </p><p class="math-container">\[\exp(\bar{B}) = \mathbb{I} + B&#39; \mathfrak{A}(B&#39;, B&#39;&#39;)  (B&#39;&#39;)^T\]</p><h3 id="The-Cayley-Retraction"><a class="docs-heading-anchor" href="#The-Cayley-Retraction">The Cayley Retraction</a><a id="The-Cayley-Retraction-1"></a><a class="docs-heading-anchor-permalink" href="#The-Cayley-Retraction" title="Permalink"></a></h3><p>For the Cayley retraction we leverage the decomposition of <span>$\bar{B} = B&#39;(B&#39;&#39;)^T\in\mathfrak{g}^\mathrm{hor}$</span> through the <em>Sherman-Morrison-Woodbury formula</em>:</p><p class="math-container">\[(\mathbb{I} - \frac{1}{2}B&#39;(B&#39;&#39;)^T)^{-1} = \mathbb{I} + \frac{1}{2}B&#39;(\mathbb{I} - \frac{1}{2}B&#39;(B&#39;&#39;)^T)^{-1}(B&#39;&#39;)^T\]</p><p>So what we have to compute the inverse of:</p><p class="math-container">\[\mathbb{I} - \frac{1}{2}\begin{bmatrix}  \mathbb{I} &amp; \mathbb{O} \\ \frac{1}{2}A &amp; -B^T  \end{bmatrix}\begin{bmatrix}  \frac{1}{2}A &amp; \mathbb{I} \\ B &amp; \mathbb{O} \end{bmatrix} = 
\begin{bmatrix}  \mathbb{I} - \frac{1}{4}A &amp; - \frac{1}{2}\mathbb{I} \\ \frac{1}{2}B^TB - \frac{1}{8}A^2 &amp; \mathbb{I} - \frac{1}{4}A  \end{bmatrix}.\]</p><p>By leveraging the sparse structure of the matrices in <span>$\mathfrak{g}^\mathrm{hor}$</span> we arrive at the following expression for the Cayley retraction (similar to the case of the geodesic retraction):</p><p class="math-container">\[\mathrm{Cayley}(\bar{B}) = \mathbb{I} + \frac{1}{2} B&#39; \left(\mathbb{I}_{2n} - \frac{1}{2} (B&#39;&#39;)^T B&#39;\right)^{-1} (B&#39;&#39;)^T \left(\mathbb{I} + \frac{1}{2} \bar{B}\right),\]</p><p>where we have abbreviated <span>$\mathbb{I} := \mathbb{I}_N.$</span> We conclude with a remark:</p><div class="admonition is-success"><header class="admonition-header">Remark</header><div class="admonition-body"><p>As mentioned previously the Lie group <span>$SO(N)$</span>, i.e. the one corresponding to the Stiefel manifold and the Grassmann manifold, has a bi-invariant Riemannian metric associated with it: <span>$(B_1,B_2)\mapsto \mathrm{Tr}(B_1^TB_2)$</span>. For other Lie groups (e.g. the symplectic group) the situation is slightly more difficult.</p></div></div><p>One of such Lie groups is the <em>group of symplectic matrices</em> [<a href="../../../references/#bendokat2021real">37</a>]; for this group the expressions presented here are more complicated.</p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Tuple{StiefelLieAlgHorMatrix}" href="#GeometricMachineLearning.geodesic-Tuple{StiefelLieAlgHorMatrix}"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">geodesic(B̄::StiefelLieAlgHorMatrix)</code></pre><p>Compute the geodesic of an element in <a href="../../../arrays/global_tangent_spaces/#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a>.</p><p><strong>Implementation</strong></p><p>Internally this is using:</p><p class="math-container">\[\mathbb{I} + B&#39;\mathfrak{A}(B&#39;, B&#39;&#39;)B&#39;&#39;,\]</p><p>with </p><p class="math-container">\[\bar{B} = \begin{bmatrix}
    A &amp; -B^T \\ 
    B &amp; \mathbb{O}
\end{bmatrix} = \begin{bmatrix}  \frac{1}{2}A &amp; \mathbb{I} \\ B &amp; \mathbb{O} \end{bmatrix} \begin{bmatrix}  \mathbb{I} &amp; \mathbb{O} \\ \frac{1}{2}A &amp; -B^T  \end{bmatrix} =: B&#39;(B&#39;&#39;)^T.\]</p><p>This is using a computationally efficient version of the matrix exponential <span>$\mathfrak{A}$</span>. </p><p>See <a href="#GeometricMachineLearning.𝔄-Tuple{AbstractMatrix}"><code>GeometricMachineLearning.𝔄</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/retractions.jl#LL42-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.geodesic-Tuple{GrassmannLieAlgHorMatrix}" href="#GeometricMachineLearning.geodesic-Tuple{GrassmannLieAlgHorMatrix}"><code>GeometricMachineLearning.geodesic</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">geodesic(B̄::GrassmannLieAlgHorMatrix)</code></pre><p>Compute the geodesic of an element in <a href="../../../arrays/global_tangent_spaces/#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p><p>This is equivalent to the method of <a href="../../../manifolds/riemannian_manifolds/#GeometricMachineLearning.geodesic-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T"><code>geodesic</code></a> for <a href="../../../arrays/global_tangent_spaces/#GeometricMachineLearning.StiefelLieAlgHorMatrix">StiefelLieAlgHorMatrix</a>.</p><p>See <a href="#GeometricMachineLearning.geodesic-Tuple{StiefelLieAlgHorMatrix}"><code>geodesic(::StiefelLieAlgHorMatrix)</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/retractions.jl#LL78-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}" href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">cayley(B̄::StiefelLieAlgHorMatrix)</code></pre><p>Compute the Cayley retraction of <code>B</code>.</p><p><strong>Implementation</strong></p><p>Internally this is using </p><p class="math-container">\[\mathrm{Cayley}(\bar{B}) = \mathbb{I} + \frac{1}{2} B&#39; (\mathbb{I}_{2n} - \frac{1}{2} (B&#39;&#39;)^T B&#39;)^{-1} (B&#39;&#39;)^T (\mathbb{I} + \frac{1}{2} B),\]</p><p>with</p><p class="math-container">\[\bar{B} = \begin{bmatrix}
    A &amp; -B^T \\ 
    B &amp; \mathbb{O}
\end{bmatrix} = \begin{bmatrix}  \frac{1}{2}A &amp; \mathbb{I} \\ B &amp; \mathbb{O} \end{bmatrix} \begin{bmatrix}  \mathbb{I} &amp; \mathbb{O} \\ \frac{1}{2}A &amp; -B^T  \end{bmatrix} =: B&#39;(B&#39;&#39;)^T,\]</p><p>i.e. <span>$\bar{B}$</span> is expressed as a product of two <span>$N\times{}2n$</span> matrices.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/retractions.jl#LL132-L152">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Tuple{GrassmannLieAlgHorMatrix}" href="#GeometricMachineLearning.cayley-Tuple{GrassmannLieAlgHorMatrix}"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">cayley(B̄::GrassmannLieAlgHorMatrix)</code></pre><p>Compute the Cayley retraction of <code>B</code>.</p><p>This is equivalent to the method of <a href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>cayley</code></a> for <a href="../../../arrays/global_tangent_spaces/#GeometricMachineLearning.StiefelLieAlgHorMatrix">StiefelLieAlgHorMatrix</a>.</p><p>See <a href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>cayley(::StiefelLieAlgHorMatrix)</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/retractions.jl#LL167-L175">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.cayley-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T" href="#GeometricMachineLearning.cayley-Union{Tuple{T}, Tuple{Manifold{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.cayley</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">cayley(Y::Manifold, Δ)</code></pre><p>Take as input an element of a manifold <code>Y</code> and a tangent vector in <code>Δ</code> in the corresponding tangent space and compute the Cayley retraction.</p><p>In different notation: take as input an element <span>$x$</span> of <span>$\mathcal{M}$</span> and an element of <span>$T_x\mathcal{M}$</span> and return <span>$\mathrm{Cayley}(v_x).$</span> </p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning

Y = StiefelManifold([1. 0. 0.;]&#39; |&gt; Matrix)
Δ = [0. .5 0.;]&#39; |&gt; Matrix
Y₂ = cayley(Y, Δ)

Y₂&#39; * Y₂ ≈ [1.;]

# output

true</code></pre><p>See the example in [<code>geodesic(::Manifold{T}, ::AbstractMatrix{T}) where T</code>].</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/retractions.jl#LL99-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.𝔄-Tuple{AbstractMatrix}" href="#GeometricMachineLearning.𝔄-Tuple{AbstractMatrix}"><code>GeometricMachineLearning.𝔄</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">𝔄(A)</code></pre><p>Compute <span>$\mathfrak{A}(A) := \sum_{n=1}^\infty \frac{1}{n!} (A)^{n-1}.$</span></p><p><strong>Implementation</strong></p><p>This uses a Taylor expansion that iteratively adds terms with</p><pre><code class="language-julia hljs">while norm(Aⁿ) &gt; ε
mul!(A_temp, Aⁿ, A)
Aⁿ .= A_temp
rmul!(Aⁿ, T(inv(n)))

𝔄A += Aⁿ
n += 1 
end</code></pre><p>until the norm of <code>Aⁿ</code> becomes smaller than machine precision.  The counter <code>n</code> in the above algorithm is initialized as <code>2</code> The matrices <code>Aⁿ</code> and <code>𝔄</code> are initialized as the identity matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/modified_exponential.jl#LL10-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.𝔄-Tuple{AbstractMatrix, AbstractMatrix}" href="#GeometricMachineLearning.𝔄-Tuple{AbstractMatrix, AbstractMatrix}"><code>GeometricMachineLearning.𝔄</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">𝔄(B̂, B̄)</code></pre><p>Compute <span>$\mathfrak{A}(B&#39;, B&#39;&#39;) := \sum_{n=1}^\infty \frac{1}{n!} ((B&#39;&#39;)^TB&#39;)^{n-1}.$</span></p><p>This expression has the property <span>$\mathbb{I} +  B&#39;\mathfrak{A}(B&#39;, B&#39;&#39;)(B&#39;&#39;)^T = \exp(B&#39;(B&#39;&#39;)^T).$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: 𝔄
import Random
Random.seed!(123)

B = rand(StiefelLieAlgHorMatrix, 10, 2)
B̂ = hcat(vcat(.5 * B.A, B.B), vcat(one(B.A), zero(B.B)))
B̄ = hcat(vcat(one(B.A), zero(B.B)), vcat(-.5 * B.A, -B.B))

one(B̂ * B̄&#39;) + B̂ * 𝔄(B̂, B̄) * B̄&#39; ≈ exp(Matrix(B))

# output

true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/e24f4dce45778be51be106f97b46fd6dcad4cb7c/src/optimizers/manifold_related/modified_exponential.jl#LL47-L72">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[22]</dt><dd><div>P.-A. Absil, R. Mahony and R. Sepulchre. <em>Optimization algorithms on matrix manifolds</em> (Princeton University Press, Princeton, New Jersey, 2008).</div></dd><dt>[37]</dt><dd><div>T. Bendokat and R. Zimmermann. <em>The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications</em>, arXiv preprint arXiv:2108.12447 (2021).</div></dd><dt>[39]</dt><dd><div>B. O&#39;neill. <em>Semi-Riemannian geometry with applications to relativity</em> (Academic press, New York City, New York, 1983).</div></dd></dl></div><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Classical retractions are also defined in <code>GeometricMachineLearning</code> under the same name, i.e. there is e.g. a method <a href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>cayley(::StiefelLieAlgHorMatrix)</code></a> and a method <a href="#GeometricMachineLearning.cayley-Tuple{StiefelLieAlgHorMatrix}"><code>cayley(::StiefelManifold, ::AbstractMatrix)</code></a> (the latter being the classical retraction); but the user is <em>strongly discouraged</em> from using classical retractions as these are computationally inefficient.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../optimizer_framework/">« Optimizers</a><a class="docs-footer-nextpage" href="../parallel_transport/">Parallel Transport »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Monday 10 March 2025 09:57">Monday 10 March 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
