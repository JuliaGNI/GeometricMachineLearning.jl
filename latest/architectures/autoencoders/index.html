<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Variational Autoencoders · GeometricMachineLearning.jl</title><meta name="title" content="Variational Autoencoders · GeometricMachineLearning.jl"/><meta property="og:title" content="Variational Autoencoders · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Variational Autoencoders · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/autoencoders/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/autoencoders/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/architectures/autoencoders/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../sympnet/">SympNet</a></li></ul></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">The Inverse Function Theorem</a></li><li><a class="tocitem" href="../../manifolds/submersion_theorem/">The Submersion Theorem</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li><li><a class="tocitem" href="../../manifolds/stiefel_manifold/">Stiefel</a></li><li><a class="tocitem" href="../../manifolds/grassmann_manifold/">Grassmann</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li></ul></li><li><span class="tocitem">Arrays</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/stiefel_lie_alg_horizontal/">Stiefel Global Tangent Space</a></li><li><a class="tocitem" href="../../arrays/grassmann_lie_alg_hor_matrix/">Grassmann Global Tangent Space</a></li></ul></li><li><span class="tocitem">Optimizer Framework</span><ul><li><a class="tocitem" href="../../Optimizer/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/general_optimization/">General Optimization</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Optimizer Functions</span><ul><li><a class="tocitem" href="../../optimizers/manifold_related/horizontal_lift/">Horizontal Lift</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/global_sections/">Global Sections</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/geodesic/">Geodesic Retraction</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/cayley/">Cayley Retraction</a></li><li><a class="tocitem" href="../../optimizers/adam_optimizer/">Adam Optimizer</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li></ul></li><li><span class="tocitem">Reduced Order Modelling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/autoencoder/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_autoencoder/">PSD and Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/kolmogorov_n_width/">Kolmogorov n-width</a></li><li><a class="tocitem" href="../../reduced_order_modeling/projection_reduction_errors/">Projection and Reduction Error</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">Sympnets</a></li><li><a class="tocitem" href="../../tutorials/linear_wave_equation/">Linear Wave Equation</a></li><li><a class="tocitem" href="../../tutorials/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../library/">Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Variational Autoencoders</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Variational Autoencoders</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/architectures/autoencoders.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Variational-Autoencoders"><a class="docs-heading-anchor" href="#Variational-Autoencoders">Variational Autoencoders</a><a id="Variational-Autoencoders-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-Autoencoders" title="Permalink"></a></h1><p>Variational autoencoders (Lee and Carlberg, 2020) train on the following set: </p><p class="math-container">\[\mathcal{X}(\mathbb{P}_\mathrm{train}) := \{\mathbf{x}^k(\mu) - \mathbf{x}^0(\mu):0\leq{}k\leq{}K,\mu\in\mathbb{P}_\mathrm{train}\},\]</p><p>where <span>$\mathbf{x}^k(\mu)\approx\mathbf{x}(t^k;\mu)$</span>. Note that <span>$\mathbf{0}\in\mathcal{X}(\mathbb{P}_\mathrm{train})$</span> as <span>$k$</span> can also be zero. </p><p>The encoder <span>$\Psi^\mathrm{enc}$</span> and decoder <span>$\Psi^\mathrm{dec}$</span> are then trained on this set <span>$\mathcal{X}(\mathbb{P}_\mathrm{train})$</span> by minimizing the reconstruction error: </p><p class="math-container">\[|| \mathbf{x} - \Psi^\mathrm{dec}\circ\Psi^\mathrm{enc}(\mathbf{x}) ||\text{ for $\mathbf{x}\in\mathcal{X}(\mathbb{P}_\mathrm{train})$}.\]</p><h2 id="Initial-condition"><a class="docs-heading-anchor" href="#Initial-condition">Initial condition</a><a id="Initial-condition-1"></a><a class="docs-heading-anchor-permalink" href="#Initial-condition" title="Permalink"></a></h2><p>No matter the parameter <span>$\mu$</span> the initial condition in the reduced system is always <span>$\mathbf{x}_{r,0}(\mu) = \mathbf{x}_{r,0} = \Psi^\mathrm{enc}(\mathbf{0})$</span>. </p><h2 id="Reconstructed-solution"><a class="docs-heading-anchor" href="#Reconstructed-solution">Reconstructed solution</a><a id="Reconstructed-solution-1"></a><a class="docs-heading-anchor-permalink" href="#Reconstructed-solution" title="Permalink"></a></h2><p>In order to arrive at the reconstructed solution one first has to <strong>decode</strong> the reduced state and then add the reference state:</p><p class="math-container">\[\mathbf{x}^\mathrm{reconstr}(t;\mu) = \mathbf{x}^\mathrm{ref}(\mu) + \Psi^\mathrm{dec}(\mathbf{x}_r(t;\mu)),\]</p><p>where <span>$\mathbf{x}^\mathrm{ref}(\mu) = \mathbf{x}(t_0;\mu) - \Psi^\mathrm{dec}\circ\Psi^\mathrm{dec}(\mathbf{0})$</span>.</p><h2 id="Symplectic-reduced-vector-field"><a class="docs-heading-anchor" href="#Symplectic-reduced-vector-field">Symplectic reduced vector field</a><a id="Symplectic-reduced-vector-field-1"></a><a class="docs-heading-anchor-permalink" href="#Symplectic-reduced-vector-field" title="Permalink"></a></h2><p>A <strong>symplectic vector field</strong> is one whose flow conserves the symplectic structure <span>$\mathbb{J}$</span>. This is equivalent<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> to there existing a Hamiltonian <span>$H$</span> s.t. the vector field <span>$X$</span> can be written as <span>$X = \mathbb{J}\nabla{}H$</span>.</p><p>If the full-order Hamiltonian is <span>$H^\mathrm{full}\equiv{}H$</span> we can obtain another Hamiltonian on the reduces space by simply setting: </p><p class="math-container">\[H^\mathrm{red}(\mathbf{x}_r(t;\mu)) = H(\mathbf{x}^\mathrm{reconstr}(t;\mu)) = H(\mathbf{x}^\mathrm{ref}(\mu) + \Psi^\mathrm{dec}(\mathbf{x}_r(t;\mu))).\]</p><p>The ODE associated to this Hamiltonian is also the one corresponding to <strong>Manifold Galerkin ROM</strong> (see (Lee and Carlberg, 2020)).</p><h2 id="Manifold-Galerkin-ROM"><a class="docs-heading-anchor" href="#Manifold-Galerkin-ROM">Manifold Galerkin ROM</a><a id="Manifold-Galerkin-ROM-1"></a><a class="docs-heading-anchor-permalink" href="#Manifold-Galerkin-ROM" title="Permalink"></a></h2><p>Define the <strong>FOM ODE residual</strong> as: </p><p class="math-container">\[r: (\mathbf{v}, \xi, \tau; \mu) \mapsto \mathbf{v} - f(\xi, \tau; \mu).\]</p><p>The reduced ODE is then defined to be: </p><p class="math-container">\[\dot{\hat{\mathbf{x}}}(t;\mu) = \mathrm{arg\,{}min}_{\hat{\mathbf{v}}\in\mathbb{R}^p}|| r(\mathcal{J}(\hat{\mathbf{x}}(t;\mu))\hat{\mathbf{v}},\hat{\mathbf{x}}^\mathrm{ref}(\mu) + \Psi^\mathrm{dec}(\hat{\mathbf{x}}(t;\mu)),t;\mu) ||_2^2,\]</p><p>where <span>$\mathcal{J}$</span> is the Jacobian of the decoder <span>$\Psi^\mathrm{dec}$</span>. This leads to: </p><p class="math-container">\[\mathcal{J}(\hat{\mathbf{x}}(t;\mu))\hat{\mathbf{v}} - f(\hat{\mathbf{x}}^\mathrm{ref}(\mu) + \Psi^\mathrm{dec}(\hat{\mathbf{x}}(t;\mu)), t; \mu) \overset{!}{=} 0 \implies 
\hat{\mathbf{v}} = \mathcal{J}(\hat{\mathbf{x}}(t;\mu))^+f(\hat{\mathbf{x}}^\mathrm{ref}(\mu) + \Psi^\mathrm{dec}(\hat{\mathbf{x}}(t;\mu)), t; \mu),\]</p><p>where <span>$\mathcal{J}(\hat{\mathbf{x}}(t;\mu))^+$</span> is the pseudoinverse of <span>$\mathcal{J}(\hat{\mathbf{x}}(t;\mu))$</span>. Because <span>$\mathcal{J}(\hat{\mathbf{x}}(t;\mu))$</span> is a symplectic matrix the pseudoinverse is the <strong>symplectic inverse</strong> (see (Peng and Mohseni, 2016)).</p><p>Furthermore, because <span>$f$</span> is Hamiltonian, the vector field describing <span>$dot{\hat{\mathbf{x}}}(t;\mu)$</span> will also be Hamiltonian. </p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>K. Lee and K. Carlberg. “Model reduction of dynamical systems on nonlinear manifolds using</li></ul><p>deep convolutional autoencoders”. In: Journal of Computational Physics 404 (2020), p. 108973.</p><ul><li>Peng L, Mohseni K. Symplectic model reduction of Hamiltonian systems[J]. SIAM Journal on Scientific Computing, 2016, 38(1): A1-A27.</li></ul><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Technically speaking the definitions are equivalent only for simply-connected manifolds, so also for vector spaces.   </li></ul></section></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Thursday 18 April 2024 15:51">Thursday 18 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
