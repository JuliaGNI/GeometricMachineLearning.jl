<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>References · GeometricMachineLearning.jl</title><meta name="title" content="References · GeometricMachineLearning.jl"/><meta property="og:title" content="References · GeometricMachineLearning.jl"/><meta property="twitter:title" content="References · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/references/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/references/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/references/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../tutorials/mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../tutorials/grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../tutorials/volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li class="is-active"><a class="tocitem" href>References</a></li><li><a class="tocitem" href="../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>References</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>References</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/references.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h1><div class="citation canonical"><dl><dt>[1]</dt><dd><div id="hairer2006geometric">E. Hairer, C. Lubich and G. Wanner. <em>Geometric Numerical integration: structure-preserving algorithms for ordinary differential equations</em> (Springer, Heidelberg, 2006).</div></dd><dt>[2]</dt><dd><div id="Kraus">M. Kraus. <a href="https://doi.org/10.5281/zenodo.3648325"><em>GeometricIntegrators.jl: Geometric Numerical Integration in Julia</em></a>, <a href="https://github.com/JuliaGNI/GeometricIntegrators.jl"><code>https://github.com/JuliaGNI/GeometricIntegrators.jl</code></a> (2020).</div></dd><dt>[3]</dt><dd><div id="brantner2023symplectic">B. Brantner and M. Kraus. <em>Symplectic autoencoders for Model Reduction of Hamiltonian Systems</em>, arXiv preprint arXiv:2312.10004 (2023).</div></dd><dt>[4]</dt><dd><div id="brantner2024volume">B. Brantner, G. de Romemont, M. Kraus and Z. Li. <em>Volume-Preserving Transformers for Learning Time Series Data with Structure</em>, arXiv preprint arXiv:2312:11166v2 (2024).</div></dd><dt>[5]</dt><dd><div id="jin2020sympnets">P. Jin, Z. Zhang, A. Zhu, Y. Tang and G. E. Karniadakis. <em>SympNets: Intrinsic structure-preserving symplectic networks for identifying Hamiltonian systems</em>. Neural Networks <strong>132</strong>, 166–179 (2020).</div></dd><dt>[6]</dt><dd><div id="greydanus2019hamiltonian">S. Greydanus, M. Dzamba and J. Yosinski. <em>Hamiltonian neural networks</em>. Advances in neural information processing systems <strong>32</strong> (2019).</div></dd><dt>[7]</dt><dd><div id="brantner2023generalizing">B. Brantner. <em>Generalizing Adam To Manifolds For Efficiently Training Transformers</em>, arXiv preprint arXiv:2305.16901 (2023).</div></dd><dt>[8]</dt><dd><div id="kong2023momentum">L. Kong, Y. Wang and M. Tao. <em>Momentum stiefel optimizer, with applications to suitably-orthogonal attention, and optimal transport</em>, arXiv preprint arXiv:2205.14173v3 (2023).</div></dd><dt>[9]</dt><dd><div id="zhang2021orthogonality">A. Zhang, A. Chan, Y. Tay, J. Fu, S. Wang, S. Zhang, H. Shao, S. Yao and R. K.-W. Lee. <em>On orthogonality constraints for transformers</em>. In: <em>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</em>, Vol. 2 (Association for Computational Linguistics, 2021); pp. 375–382.</div></dd><dt>[10]</dt><dd><div id="churavy2020kernel">V. Churavy. <em>KernelAbstractions.jl</em>, <a href="https://github.com/JuliaGPU/KernelAbstractions.jl"><code>https://github.com/JuliaGPU/KernelAbstractions.jl</code></a> (2024). Used on August 14, 2024.</div></dd><dt>[11]</dt><dd><div id="besard2018juliagpu">T. Besard, C. Foket and B. De Sutter. <em>Effective Extensible Programming: Unleashing Julia on GPUs</em>. <a href="https://doi.org/10.1109/TPDS.2018.2872064">IEEE Transactions on Parallel and Distributed Systems</a> (2018), <a href="https://arxiv.org/abs/1712.03112">arXiv:1712.03112 [cs.PL]</a>.</div></dd><dt>[12]</dt><dd><div id="besard2022metal">T. Besard and M. Hawkins. <em>Metal.jl</em>, <a href="https://github.com/JuliaGPU/Metal.jl"><code>https://github.com/JuliaGPU/Metal.jl</code></a> (2022). Used on August 14, 2024.</div></dd><dt>[13]</dt><dd><div id="besard2022one">T. Besard, <em>oneAPI.jl</em>, <a href="https://github.com/JuliaGPU/oneAPI.jl"><code>https://github.com/JuliaGPU/oneAPI.jl</code></a> (2022). Used on August 14, 2024.</div></dd><dt>[14]</dt><dd><div id="lipschutz1965general">S. Lipschutz. <em>General Topology</em> (McGraw-Hill Book Company, New York City, New York, 1965).</div></dd><dt>[15]</dt><dd><div id="lang2012fundamentals">S. Lang. <em>Fundamentals of differential geometry</em>. Vol. 191 (Springer Science &amp; Business Media, 2012).</div></dd><dt>[16]</dt><dd><div id="bishop1980tensor">S. I. Richard L. Bishop. <em>Tensor Analysis on Manifolds</em> (Dover Publications, Mineola, New York, 1980).</div></dd><dt>[17]</dt><dd><div id="lang2012real">S. Lang. <em>Real and functional analysis</em>. Vol. 142 (Springer Science &amp; Business Media, 2012).</div></dd><dt>[18]</dt><dd><div id="mezzadri2006generate">F. Mezzadri. <em>How to generate random matrices from the classical compact groups</em>, arXiv preprint math-ph/0609050 (2006).</div></dd><dt>[19]</dt><dd><div id="do1992riemannian">M. P. Do Carmo and J. Flaherty Francis. <em>Riemannian geometry</em>. Vol. 2 (Springer, 1992).</div></dd><dt>[20]</dt><dd><div id="absil2004riemannian">P.-A. Absil, R. Mahony and R. Sepulchre. <em>Riemannian geometry of Grassmann manifolds with a view on algorithmic computation</em>. Acta Applicandae Mathematica <strong>80</strong>, 199–220 (2004).</div></dd><dt>[21]</dt><dd><div id="holm2009geometric">D. D. Holm, T. Schmah and C. Stoica. <em>Geometric mechanics and symmetry: from finite to infinite dimensions</em>. Vol. 12 (Oxford University Press, Oxford, UK, 2009).</div></dd><dt>[22]</dt><dd><div id="absil2008optimization">P.-A. Absil, R. Mahony and R. Sepulchre. <em>Optimization algorithms on matrix manifolds</em> (Princeton University Press, Princeton, New Jersey, 2008).</div></dd><dt>[23]</dt><dd><div id="bendokat2020grassmann">T. Bendokat, R. Zimmermann and P.-A. Absil. <em>A Grassmann manifold handbook: Basic geometry and computational aspects</em>, arXiv preprint arXiv:2011.13699 (2020).</div></dd><dt>[24]</dt><dd><div id="moses2021reverse">W. S. Moses, V. Churavy, L. Paehler, J. Hückelheim, S. H. Narayanan, M. Schanen and J. Doerfert. <a href="https://doi.org/10.1145/3458817.3476165"><em>Reverse-Mode Automatic Differentiation and Optimization of GPU Kernels via Enzyme</em></a>. In: <a href="https://doi.org/10.1145/3458817.3476165"><em>Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</em></a>, <em>SC &#39;21</em> (Association for Computing Machinery, New York, NY, USA, 2021).</div></dd><dt>[25]</dt><dd><div id="betancourt2018geometric">M. Betancourt. <em>A geometric theory of higher-order automatic differentiation</em>, arXiv preprint arXiv:1812.11592 (2018).</div></dd><dt>[26]</dt><dd><div id="bolte2020mathematical">J. Bolte and E. Pauwels. <em>A mathematical model for automatic differentiation in machine learning</em>. Advances in Neural Information Processing Systems <strong>33</strong>, 10809–10819 (2020).</div></dd><dt>[27]</dt><dd><div id="arnold1978mathematical">V. I. Arnold. <em>Mathematical methods of classical mechanics</em>. Vol. 60 of <em>Graduate Texts in Mathematics</em> (Springer Verlag, Berlin, 1978).</div></dd><dt>[28]</dt><dd><div id="kraus2017gempic">M. Kraus, K. Kormann, P. J. Morrison and E. Sonnendrücker. <em>GEMPIC: geometric electromagnetic particle-in-cell methods</em>. Journal of Plasma Physics <strong>83</strong>, 905830401 (2017).</div></dd><dt>[29]</dt><dd><div id="ge1988lie">Z. Ge and J. E. Marsden. <em>Lie-poisson hamilton-jacobi theory and lie-poisson integrators</em>. Physics Letters A <strong>133</strong>, 134–139 (1988).</div></dd><dt>[30]</dt><dd><div id="hornik1989multilayer">K. Hornik, M. Stinchcombe and H. White. <em>Multilayer feedforward networks are universal approximators</em>. Neural networks <strong>2</strong>, 359–366 (1989).</div></dd><dt>[31]</dt><dd><div id="yun2019transformers">C. Yun, S. Bhojanapalli, A. S. Rawat, S. J. Reddi and S. Kumar. <em>Are transformers universal approximators of sequence-to-sequence functions?</em> arXiv preprint arXiv:1912.10077 (2019).</div></dd><dt>[32]</dt><dd><div id="zhou2020universality">D.-X. Zhou. <em>Universality of deep convolutional neural networks</em>. Applied and computational harmonic analysis <strong>48</strong>, 787–794 (2020).</div></dd><dt>[33]</dt><dd><div id="liu2024kan">Z. Liu, Y. Wang, S. Vaidya, F. Ruehle, J. Halverson, M. Soljačić, T. Y. Hou and M. Tegmark. <em>Kan: Kolmogorov-arnold networks</em>, arXiv preprint arXiv:2404.19756 (2024).</div></dd><dt>[34]</dt><dd><div id="burby2020fast">J. W. Burby, Q. Tang and R. Maulik. <em>Fast neural Poincaré maps for toroidal magnetic fields</em>. Plasma Physics and Controlled Fusion <strong>63</strong>, 024001 (2020).</div></dd><dt>[35]</dt><dd><div id="horn4555181generalized">P. Horn, V. Saz Ulibarrena, B. Koren and S. Portegies Zwart. <em>A Generalized Framework of Neural Networks for Hamiltonian Systems</em>. SSRN preprint SSRN:4555181 (2023).</div></dd><dt>[36]</dt><dd><div id="celledoni2021structure">E. Celledoni, M. J. Ehrhardt, C. Etmann, R. I. McLachlan, B. Owren, C.-B. Schonlieb and F. Sherry. <em>Structure-preserving deep learning</em>. European journal of applied mathematics <strong>32</strong>, 888–936 (2021).</div></dd><dt>[37]</dt><dd><div id="bendokat2021real">T. Bendokat and R. Zimmermann. <em>The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications</em>, arXiv preprint arXiv:2108.12447 (2021).</div></dd><dt>[38]</dt><dd><div id="gao2021riemannian">B. Gao, N. T. Son, P.-A. Absil and T. Stykel. <em>Riemannian optimization on the symplectic Stiefel manifold</em>. SIAM Journal on Optimization <strong>31</strong>, 1546–1575 (2021).</div></dd><dt>[39]</dt><dd><div id="o1983semi">B. O&#39;neill. <em>Semi-Riemannian geometry with applications to relativity</em> (Academic press, New York City, New York, 1983).</div></dd><dt>[40]</dt><dd><div id="celledoni2000approximating">E. Celledoni and A. Iserles. <em>Approximating the exponential from a Lie algebra to a Lie group</em>. Mathematics of Computation <strong>69</strong>, 1457–1480 (2000).</div></dd><dt>[41]</dt><dd><div id="fraikin2007optimization">C. Fraikin, K. Hüper and P. V. Dooren. <em>Optimization over the Stiefel manifold</em>. In: <em>PAMM: Proceedings in Applied Mathematics and Mechanics</em>, Vol. 7 no. 1 (Wiley Online Library, 2007); pp. 1062205–1062206.</div></dd><dt>[42]</dt><dd><div id="schlarb2024covariant">M. Schlarb. <em>Covariant Derivatives on Homogeneous Spaces: Horizontal Lifts and Parallel Transport</em>. The Journal of Geometric Analysis <strong>34</strong>, 1–43 (2024).</div></dd><dt>[43]</dt><dd><div id="goodfellow2016deep">I. Goodfellow, Y. Bengio and A. Courville. <em>Deep learning</em> (MIT press, Cambridge, MA, 2016).</div></dd><dt>[44]</dt><dd><div id="wright2006numerical">J. N. Stephen J. Wright. <em>Numerical optimization</em> (Springer Science+Business Media, New York, NY, 2006).</div></dd><dt>[45]</dt><dd><div id="2279304">A.Γ. (math.stackexchange user 253273). <em>Quasi-newton methods: Understanding DFP updating formula</em>, <a href="https://math.stackexchange.com/q/2279304"><code>https://math.stackexchange.com/q/2279304</code></a> (2017). Accessed on September 19, 2024.</div></dd><dt>[46]</dt><dd><div id="kenneweg2024improving">P. Kenneweg, T. Kenneweg and B. Hammer. <em>Improving Line Search Methods for Large Scale Neural Network Training</em>. In: <em>2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)</em> (IEEE, 2024); pp. 1–6.</div></dd><dt>[47]</dt><dd><div id="vaswani2019painless">S. Vaswani, A. Mishkin, I. Laradji, M. Schmidt, G. Gidel and S. Lacoste-Julien. <em>Painless stochastic gradient: Interpolation, line-search, and convergence rates</em>. Advances in neural information processing systems <strong>32</strong> (2019).</div></dd><dt>[48]</dt><dd><div id="huang2016riemannian">W. Huang, P.-A. Absil and K. A. Gallivan. <em>A Riemannian BFGS method for nonconvex optimization problems</em>. In: <em>Numerical Mathematics and Advanced Applications ENUMATH 2015</em> (Springer, 2016); pp. 627–634.</div></dd><dt>[49]</dt><dd><div id="gao2024symplectic">B. Gao, N. T. Son and T. Stykel. <em>Symplectic Stiefel manifold: tractable metrics, second-order geometry and Newton&#39;s methods</em>, arXiv preprint arXiv:2406.14299 (2024).</div></dd><dt>[50]</dt><dd><div id="bajars2023locally">J. Bajārs. <em>Locally-symplectic neural networks for learning volume-preserving dynamics</em>. Journal of Computational Physics <strong>476</strong>, 111911 (2023).</div></dd><dt>[51]</dt><dd><div id="kang1995volume">F. Kang and S. Zai-Jiu. <em>Volume-preserving algorithms for source-free dynamical systems</em>. Numerische Mathematik <strong>71</strong>, 451–463 (1995).</div></dd><dt>[52]</dt><dd><div id="cardot2011recurrent">H. Cardot. <em>Recurrent neural networks for temporal data processing</em> (BoD–Books on Demand, 2011).</div></dd><dt>[53]</dt><dd><div id="bahdanau2014neural">D. Bahdanau, K. Cho and Y. Bengio. <em>Neural machine translation by jointly learning to align and translate</em>, arXiv preprint arXiv:1409.0473 (2014).</div></dd><dt>[54]</dt><dd><div id="vaswani2017attention">A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser and I. Polosukhin. <em>Attention is all you need</em>. Advances in neural information processing systems <strong>30</strong> (2017).</div></dd><dt>[55]</dt><dd><div id="jacobs1992discrete">K. Jacobs. <em>Discrete Stochastics</em> (Birkhäuser Verlag, Basel, Switzerland, 1992).</div></dd><dt>[56]</dt><dd><div id="feng1998step">K. Feng. <em>The step-transition operators for multi-step methods of ODE&#39;s</em>. Journal of Computational Mathematics, 193–202 (1998).</div></dd><dt>[57]</dt><dd><div id="luong2015effective">M.-T. Luong, H. Pham and C. D. Manning. <em>Effective approaches to attention-based neural machine translation</em>, arXiv preprint arXiv:1508.04025 (2015).</div></dd><dt>[58]</dt><dd><div id="feng1987symplectic">K. Feng and M.-z. Qin. <em>The symplectic methods for the computation of Hamiltonian equations</em>. In: <em>Numerical Methods for Partial Differential Equations: Proceedings of a Conference held in Shanghai, PR China, March 25–29, 1987</em> (Springer, 1987); pp. 1–37.</div></dd><dt>[59]</dt><dd><div id="ge1988approximation">Z. Ge and K. Feng. <em>On the approximation of linear Hamiltonian systems</em>. Journal of Computational Mathematics, 88–97 (1988).</div></dd><dt>[60]</dt><dd><div id="blickhan2023registration">T. Blickhan. <em>A registration method for reduced basis problems using linear optimal transport</em>, arXiv preprint arXiv:2304.14884 (2023).</div></dd><dt>[61]</dt><dd><div id="fresca2021comprehensive">S. Fresca, L. Dede’ and A. Manzoni. <em>A comprehensive deep learning-based approach to reduced order modeling of nonlinear time-dependent parametrized PDEs</em>. Journal of Scientific Computing <strong>87</strong>, 1–36 (2021).</div></dd><dt>[62]</dt><dd><div id="lee2020model">K. Lee and K. T. Carlberg. <em>Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders</em>. Journal of Computational Physics <strong>404</strong>, 108973 (2020).</div></dd><dt>[63]</dt><dd><div id="gander2012euler">M. J. Gander and G. Wanner. <em>From Euler, Ritz, and Galerkin to modern computing</em>. Siam Review <strong>54</strong>, 627–666 (2012).</div></dd><dt>[64]</dt><dd><div id="arbes2023kolmogorov">F. Arbes, C. Greif and K. Urban. <em>The Kolmogorov N-width for linear transport: Exact representation and the influence of the data</em>, arXiv preprint arXiv:2305.00066 (2023).</div></dd><dt>[65]</dt><dd><div id="greif2019decay">C. Greif and K. Urban. <em>Decay of the Kolmogorov N-width for wave problems</em>. Applied Mathematics Letters <strong>96</strong>, 216–222 (2019).</div></dd><dt>[66]</dt><dd><div id="chatterjee2000introduction">A. Chatterjee. <em>An introduction to the proper orthogonal decomposition</em>. Current science, 808–817 (2000).</div></dd><dt>[67]</dt><dd><div id="volkwein2013proper">S. Volkwein. <em>Proper orthogonal decomposition: Theory and reduced-order modelling</em>. Lecture Notes, University of Konstanz <strong>4</strong>, 1–29 (2013).</div></dd><dt>[68]</dt><dd><div id="peng2016symplectic">L. Peng and K. Mohseni. <em>Symplectic model reduction of Hamiltonian systems</em>. SIAM Journal on Scientific Computing <strong>38</strong>, A1–A27 (2016).</div></dd><dt>[69]</dt><dd><div id="tyranowski2023symplectic">T. M. Tyranowski and M. Kraus. <em>Symplectic model reduction methods for the Vlasov equation</em>. Contributions to Plasma Physics <strong>63</strong>, e202200046 (2023).</div></dd><dt>[70]</dt><dd><div id="buchfink2023symplectic">P. Buchfink, S. Glas and B. Haasdonk. <em>Symplectic model reduction of Hamiltonian systems on nonlinear manifolds and approximation with weakly symplectic autoencoder</em>. SIAM Journal on Scientific Computing <strong>45</strong>, A289–A311 (2023).</div></dd><dt>[71]</dt><dd><div id="raissi2019physics">M. Raissi, P. Perdikaris and G. E. Karniadakis. <em>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</em>. Journal of Computational physics <strong>378</strong>, 686–707 (2019).</div></dd><dt>[72]</dt><dd><div id="yildiz2024data">S. Yıldız, P. Goyal, T. Bendokat and P. Benner. <em>Data-Driven Identification of Quadratic Representations for Nonlinear Hamiltonian Systems Using Weakly Symplectic Liftings</em>. Journal of Machine Learning for Modeling and Computing <strong>5</strong> (2024).</div></dd><dt>[73]</dt><dd><div id="van2014port">A. Van Der Schaft, D. Jeltsema and others. <em>Port-Hamiltonian systems theory: An introductory overview</em>. Foundations and Trends in Systems and Control <strong>1</strong>, 173–378 (2014).</div></dd><dt>[74]</dt><dd><div id="morandin2023modeling">R. Morandin. <em>Modeling and numerical treatment of port-Hamiltonian descriptor systems</em>. Ph.D. Thesis, Technische Universität Berlin (2023).</div></dd><dt>[75]</dt><dd><div id="yoshimura2006diracI">H. Yoshimura and J. E. Marsden. <em>Dirac structures in Lagrangian mechanics Part I: implicit Lagrangian systems</em>. Journal of Geometry and Physics <strong>57</strong>, 133–156 (2006).</div></dd><dt>[76]</dt><dd><div id="yoshimura2006diracII">H. Yoshimura and J. E. Marsden. <em>Dirac structures in Lagrangian mechanics Part II: Variational structures</em>. Journal of Geometry and Physics <strong>57</strong>, 209–250 (2006).</div></dd><dt>[77]</dt><dd><div id="kotyczka2019discrete">P. Kotyczka and L. Lefevre. <em>Discrete-time port-Hamiltonian systems: A definition based on symplectic integration</em>. Systems &amp; Control Letters <strong>133</strong>, 104530 (2019).</div></dd><dt>[78]</dt><dd><div id="mehrmann2019structure">V. Mehrmann and R. Morandin. <em>Structure-preserving discretization for port-Hamiltonian descriptor systems</em>. In: <em>2019 IEEE 58th Conference on Decision and Control (CDC)</em> (IEEE, 2019); pp. 6863–6868.</div></dd><dt>[79]</dt><dd><div id="moser2023structure">T. F. Moser. <em>Structure-Preserving Model Reduction of Port-Hamiltonian Descriptor Systems</em>. Ph.D. Thesis, Technische Universität München (2023).</div></dd><dt>[80]</dt><dd><div id="rettberg2024data">J. Rettberg, J. Kneifl, J. Herb, P. Buchfink, J. Fehr and B. Haasdonk. <em>Data-driven identification of latent port-Hamiltonian systems</em>, arXiv preprint arXiv:2408.08185 (2024).</div></dd><dt>[81]</dt><dd><div id="otto2023learning">S. E. Otto, G. R. Macchio and C. W. Rowley. <em>Learning nonlinear projections for reduced-order modeling of dynamical systems using constrained autoencoders</em>. Chaos: An Interdisciplinary Journal of Nonlinear Science <strong>33</strong> (2023).</div></dd><dt>[82]</dt><dd><div id="leimkuhler2004simulating">B. Leimkuhler and S. Reich. <em>Simulating hamiltonian dynamics</em>. No. 14 (Cambridge university press, 2004).</div></dd><dt>[83]</dt><dd><div id="hochreiter1997long">S. Hochreiter and J. Schmidhuber. <em>Long short-term memory</em>. Neural computation <strong>9</strong>, 1735–1780 (1997).</div></dd><dt>[84]</dt><dd><div id="hemmasian2023reduced">A. Hemmasian and A. Barati Farimani. <em>Reduced-order modeling of fluid flows with transformers</em>. Physics of Fluids <strong>35</strong> (2023).</div></dd><dt>[85]</dt><dd><div id="solera2023beta">A. Solera-Rico, C. S. Vila, M. Gómez, Y. Wang, A. Almashjary, S. Dawson and R. Vinuesa, <em><span>$\beta$</span>-Variational autoencoders and transformers for reduced-order modelling of fluid flows</em>, arXiv preprint arXiv:2304.03571 (2023).</div></dd><dt>[86]</dt><dd><div id="jin2022optimal">P. Jin, Z. Lin and B. Xiao. <em>Optimal unit triangular factorization of symplectic matrices</em>. Linear Algebra and its Applications (2022).</div></dd><dt>[87]</dt><dd><div id="patwardhan2023transformers">N. Patwardhan, S. Marrone and C. Sansone. <em>Transformers in the real world: A survey on nlp applications</em>. Information <strong>14</strong>, 242 (2023).</div></dd><dt>[88]</dt><dd><div id="dosovitskiy2020image">A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly and others. <em>An image is worth 16x16 words: Transformers for image recognition at scale</em>, arXiv preprint arXiv:2010.11929 (2020).</div></dd><dt>[89]</dt><dd><div id="toda1967vibration">M. Toda. <em>Vibration of a chain with nonlinear interaction</em>. Journal of the Physical Society of Japan <strong>22</strong>, 431–436 (1967).</div></dd><dt>[90]</dt><dd><div id="deng2012mnist">L. Deng. <em>The mnist database of handwritten digit images for machine learning research</em>. IEEE Signal Processing Magazine <strong>29</strong>, 141–142 (2012).</div></dd><dt>[91]</dt><dd><div id="villani2009optimal">C. Villani and others. <em>Optimal transport: old and new</em>. Vol. 338 (Springer, 2009).</div></dd><dt>[92]</dt><dd><div id="villani2021topics">C. Villani. <em>Topics in optimal transportation</em>. Vol. 58 (American Mathematical Soc., 2021).</div></dd><dt>[93]</dt><dd><div id="blickhan2023brenier">T. Blickhan. <em>BrenierTwoFluids.jl</em>, <a href="https://github.com/ToBlick/BrenierTwoFluids"><code>https://github.com/ToBlick/BrenierTwoFluids</code></a> (2023).</div></dd><dt>[94]</dt><dd><div class="jl-2018" id="Zygote">M. Innes. <a href="http://arxiv.org/abs/1810.07951"><em>Don&#39;t Unroll Adjoint: Differentiating SSA-Form Programs</em></a>. CoRR <strong>abs/1810.07951</strong> (2018), <a href="https://arxiv.org/abs/1810.07951">arXiv:1810.07951</a>.</div></dd><dt>[95]</dt><dd><div id="achiam2023gpt">J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat and others. <em>Gpt-4 technical report</em>, arXiv preprint arXiv:2303.08774 (2023).</div></dd><dt>[96]</dt><dd><div id="duan2019artificial">Y. Duan, J. S. Edwards and Y. K. Dwivedi. <em>Artificial intelligence for decision making in the era of Big Data–evolution, challenges and research agenda</em>. International journal of information management <strong>48</strong>, 63–71 (2019).</div></dd><dt>[97]</dt><dd><div id="psichogios1992hybrid">D. C. Psichogios and L. H. Ungar. <em>A hybrid neural network-first principles approach to process modeling</em>. AIChE Journal <strong>38</strong>, 1499–1511 (1992).</div></dd><dt>[98]</dt><dd><div id="baker2019workshop">N. Baker, F. Alexander, T. Bremer, A. Hagberg, Y. Kevrekidis, H. Najm, M. Parashar, A. Patra, J. Sethian, S. Wild and others. <em>Workshop report on basic research needs for scientific machine learning: Core technologies for artificial intelligence</em> (USDOE Office of Science (SC), Washington, DC (United States), 2019).</div></dd><dt>[99]</dt><dd><div id="arnold2006finite">D. N. Arnold, R. S. Falk and R. Winther. <em>Finite element exterior calculus, homological techniques, and applications</em>. Acta numerica <strong>15</strong>, 1–155 (2006).</div></dd><dt>[100]</dt><dd><div id="lishkova2023discrete">Y. Lishkova, P. Scherer, S. Ridderbusch, M. Jamnik, P. Liò, S. Ober-Blöbaum and C. Offen. <em>Discrete Lagrangian neural networks with automatic symmetry discovery</em>. IFAC-PapersOnLine <strong>56</strong>, 3203–3210 (2023).</div></dd><dt>[101]</dt><dd><div id="dierkes2023hamiltonian">E. Dierkes, C. Offen, S. Ober-Blöbaum and K. Flaßkamp. <em>Hamiltonian neural networks with automatic symmetry detection</em>. Chaos: An Interdisciplinary Journal of Nonlinear Science <strong>33</strong> (2023).</div></dd><dt>[102]</dt><dd><div id="brantner2020geometric">B. Brantner and M. Kraus. <em>GeometricMachineLearning.jl: Geometric Machine Learning in Julia</em>, <a href="https://github.com/JuliaGNI/GeometricMachineLearning.jl"><code>https://github.com/JuliaGNI/GeometricMachineLearning.jl</code></a> (2020).</div></dd><dt>[103]</dt><dd><div id="julia2024documentation">The Julia Company. <em>Documentation</em>, <a href="https://docs.julialang.org/en/v1/manual/documentation/"><code>https://docs.julialang.org/en/v1/manual/documentation/</code></a> (2024). Accessed on August 19, 2024.</div></dd><dt>[104]</dt><dd><div id="rtx4090">Nvidia Corporation. <em>GeForce RTX 4090</em>, <a href="https://www.nvidia.com/de-de/geforce/graphics-cards/40-series/rtx-4090/"><code>https://www.nvidia.com/de-de/geforce/graphics-cards/40-series/rtx-4090/</code></a> (2022). Accessed on August 13, 2024.</div></dd><dt>[105]</dt><dd><div id="actions">GitHub, Inc. <em>About GitHub-hosted runners</em>, <a href="https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners"><code>https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners</code></a> (2024). Accessed on August 13, 2024.</div></dd><dt>[106]</dt><dd><div id="DanischKrumbiegel2021">S. Danisch and J. Krumbiegel. <a href="https://doi.org/10.21105/joss.03349"><em>Makie.jl: Flexible high-performance data visualization for Julia</em></a>. <a href="https://doi.org/10.21105/joss.03349">Journal of Open Source Software <strong>6</strong>, 3349</a> (2021).</div></dd><dt>[107]</dt><dd><div id="bon2024optimal">D. Bon, G. Pai, G. Bellaard, O. Mula and R. Duits. <em>Optimal Transport on the Lie Group of Roto-translations</em>, arXiv preprint arXiv:2402.15322 (2024).</div></dd><dt>[108]</dt><dd><div id="kingma2014adam">D. Kingma. <em>Adam: a method for stochastic optimization</em>, arXiv preprint arXiv:1412.6980 (2014).</div></dd><dt>[109]</dt><dd><div id="frankel2011geometry">T. Frankel. <em>The geometry of physics: an introduction</em> (Cambridge university press, Cambridge, UK, 2011).</div></dd><dt>[110]</dt><dd><div id="li2020efficient">J. Li, L. Fuxin and S. Todorovic. <em>Efficient riemannian optimization on the stiefel manifold via the cayley transform</em>, arXiv preprint arXiv:2002.01113 (2020).</div></dd><dt>[111]</dt><dd><div id="huang2018orthogonal">L. Huang, X. Liu, B. Lang, A. Yu, Y. Wang and B. Li. <em>Orthogonal weight normalization: Solution to optimization over multiple dependent stiefel manifolds in deep neural networks</em>. In: <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 32 no. 1 (2018).</div></dd><dt>[112]</dt><dd><div id="xiong2020layer">R. Xiong, Y. Yang, D. He, K. Zheng, S. Zheng, C. Xing, H. Zhang, Y. Lan, L. Wang and T. Liu. <em>On layer normalization in the transformer architecture</em>. In: <em>International Conference on Machine Learning</em> (PMLR, 2020); pp. 10524–10533.</div></dd><dt>[113]</dt><dd><div id="fresca2022pod">S. Fresca and A. Manzoni. <em>POD-DL-ROM: Enhancing deep learning-based reduced order models for nonlinear parametrized PDEs by proper orthogonal decomposition</em>. Computer Methods in Applied Mechanics and Engineering <strong>388</strong>, 114181 (2022).</div></dd><dt>[114]</dt><dd><div id="morrison1986paradigm">P. J. Morrison. <em>A paradigm for joined Hamiltonian and dissipative systems</em>. Physica D: Nonlinear Phenomena <strong>18</strong>, 410–419 (1986).</div></dd><dt>[115]</dt><dd><div id="gruber2023energetically">A. Gruber, M. Gunzburger, L. Ju and Z. Wang. <em>Energetically consistent model reduction for metriplectic systems</em>. Computer Methods in Applied Mechanics and Engineering <strong>404</strong>, 115709 (2023).</div></dd><dt>[116]</dt><dd><div id="schulze2023structure">P. Schulze. <em>Structure-preserving model reduction for port-hamiltonian systems based on a special class of nonlinear approximation ansatzes</em>, arXiv preprint arXiv:2302.06479 (2023).</div></dd><dt>[117]</dt><dd><div id="mamunuzzaman2022structure">M. Mamunuzzaman and H. Zwart. <em>Structure preserving model order reduction of port-Hamiltonian systems</em>, arXiv preprint arXiv:2203.07751 (2022).</div></dd><dt>[118]</dt><dd><div id="duane1987hybrid">S. Duane, A. D. Kennedy, B. J. Pendleton and D. Roweth. <em>Hybrid monte carlo</em>. Physics letters B <strong>195</strong>, 216–222 (1987).</div></dd><dt>[119]</dt><dd><div id="cobb2021scaling">A. D. Cobb and B. Jalaian. <em>Scaling Hamiltonian Monte Carlo inference for Bayesian neural networks with symmetric splitting</em>. In: <em>Uncertainty in Artificial Intelligence</em> (PMLR, 2021); pp. 675–685.</div></dd><dt>[120]</dt><dd><div id="fichtner2018hamiltonian">A. Fichtner and S. Simutė. <em>Hamiltonian Monte Carlo inversion of seismic sources in complex media</em>. Journal of Geophysical Research: Solid Earth <strong>123</strong>, 2984–2999 (2018).</div></dd><dt>[121]</dt><dd><div id="wibisono2016variational">A. Wibisono, A. C. Wilson and M. I. Jordan. <em>A variational perspective on accelerated methods in optimization</em>, proceedings of the National Academy of Sciences <strong>113</strong>, E7351–E7358 (2016).</div></dd><dt>[122]</dt><dd><div id="duruisseaux2022accelerated">V. Duruisseaux and M. Leok. <em>Accelerated optimization on Riemannian manifolds via discrete constrained variational integrators</em>. Journal of Nonlinear Science <strong>32</strong>, 42 (2022).</div></dd><dt>[123]</dt><dd><div id="sato2019cholesky">H. Sato and K. Aihara. <em>Cholesky QR-based retraction on the generalized Stiefel manifold</em>. Computational Optimization and Applications <strong>72</strong>, 293–308 (2019).</div></dd><dt>[124]</dt><dd><div id="gao2024optimization">B. Gao, N. T. Son and T. Stykel. <em>Optimization on the symplectic Stiefel manifold: SR decomposition-based retraction and applications</em>. Linear Algebra and its Applications <strong>682</strong>, 50–85 (2024).</div></dd><dt>[125]</dt><dd><div id="brantner2023structure">B. Brantner, G. de Romemont, M. Kraus and Z. Li. <em>Structure-Preserving Transformers for Learning Parametrized Hamiltonian Systems</em>, arXiv preprint arXiv:2312:11166 (2023).</div></dd><dt>[126]</dt><dd><div id="lin2008riemannian">T. Lin and H. Zha. <em>Riemannian manifold learning</em>. IEEE transactions on pattern analysis and machine intelligence <strong>30</strong>, 796–809 (2008).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorials/optimizer_comparison/">« Comparing Optimizers</a><a class="docs-footer-nextpage" href="../docstring_index/">Index of Docstrings »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Tuesday 3 December 2024 11:51">Tuesday 3 December 2024</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
