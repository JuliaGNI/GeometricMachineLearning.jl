<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Global Tangent Spaces · GeometricMachineLearning.jl</title><meta name="title" content="Global Tangent Spaces · GeometricMachineLearning.jl"/><meta property="og:title" content="Global Tangent Spaces · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Global Tangent Spaces · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/arrays/global_tangent_spaces/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/arrays/global_tangent_spaces/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/arrays/global_tangent_spaces/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li class="is-active"><a class="tocitem" href>Global Tangent Spaces</a><ul class="internal"><li><a class="tocitem" href="#Global-Sections"><span>Global Sections</span></a></li><li><a class="tocitem" href="#The-Global-Tangent-Space-for-the-Stiefel-Manifold"><span>The Global Tangent Space for the Stiefel Manifold</span></a></li><li><a class="tocitem" href="#Global-Tangent-Space-for-the-Grassmann-Manifold"><span>Global Tangent Space for the Grassmann Manifold</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li><li class="toplevel"><a class="tocitem" href="#References-2"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../tensors/">Tensors</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../architectures/symplectic_transformer/">Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../tutorials/mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../tutorials/matrix_softmax/">Matrix Attention</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/symplectic_transformer/">Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Special Arrays and AD</a></li><li class="is-active"><a href>Global Tangent Spaces</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Global Tangent Spaces</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/arrays/global_tangent_spaces.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Global-Tangent-Spaces"><a class="docs-heading-anchor" href="#Global-Tangent-Spaces">Global Tangent Spaces</a><a id="Global-Tangent-Spaces-1"></a><a class="docs-heading-anchor-permalink" href="#Global-Tangent-Spaces" title="Permalink"></a></h1><p>In <code>GeometricMachineLearning</code> standard neural network optimizers are generalized to <a href="../../manifolds/homogeneous_spaces/#Homogeneous-Spaces">homogeneous spaces</a> by leveraging the special structure of the tangent spaces of this class of manifolds. When we introduced homogeneous spaces we already talked about that every tangent space to a homogeneous space <span>$T_Y\mathcal{M}$</span> is of the form: </p><p class="math-container">\[    T_Y\mathcal{M} = \mathfrak{g} \cdot Y := \{AY: A\in{}\mathfrak{g}\}.\]</p><p>We then have a decomposition of <span>$\mathfrak{g}$</span> into a vertical part <span>$\mathfrak{g}^{\mathrm{ver}, Y}$</span> and a horizontal part <span>$\mathfrak{g}^{\mathrm{hor}, Y}$</span> and the horizontal part is isomorphic to <span>$T_Y\mathcal{M}$</span> via:</p><p class="math-container">\[    \mathfrak{g}^{\mathrm{hor}, Y} = \{\Omega(\Delta): \Delta\in{}T_Y\mathcal{M} \}.\]</p><p>We now identify a special element <span>$E \in \mathcal{M}$</span> and designate the horizontal component <span>$\mathfrak{g}^{\mathrm{hor}, E}$</span> as our <em>global tangent space</em>. We will refer to this global tangent space by <span>$\mathfrak{g}^\mathrm{hor}$</span>. We can now find a transformation from any <span>$\mathfrak{g}^{\mathrm{hor}, Y}$</span> to <span>$\mathfrak{g}^\mathrm{hor}$</span> and vice-versa (these spaces are isomorphic).</p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>Let <span>$A\in{}G$</span> an element such that <span>$AE = Y$</span>. Then we have</p><p class="math-container">\[A^{-1}\cdot\mathfrak{g}^{\mathrm{hor},Y}\cdot{}A = \mathfrak{g}^\mathrm{hor},\]</p><p>i.e. for every element <span>$B\in\mathfrak{g}^\mathrm{hor}$</span> we can find a <span>$B^Y \in \mathfrak{g}^{\mathrm{hor},Y}$</span> s.t. <span>$B = A^{-1}B^YA$</span> (and vice-versa).</p></div></div><details class="admonition is-details"><summary class="admonition-header">Proof</summary><div class="admonition-body"><p>We first show that for every <span>$B^Y\in\mathfrak{g}^{\mathrm{hor},Y}$</span> the element <span>$A^{-1}B^YA$</span> is in <span>$\mathfrak{g}^{\mathrm{hor}}$</span>. First note that <span>$A^{-1}B^YA\in\mathfrak{g}$</span> by a fundamental theorem of Lie group theory (closedness of the Lie algebra under adjoint action). Now assume that <span>$A^{-1}B^YA$</span> is not fully contained in <span>$\mathfrak{g}^\mathrm{hor}$</span>, i.e. it also has a vertical component. So we would lose information when performing <span>$A^{-1}B^YA \mapsto A^{-1}B^YAE = A^{-1}B^YY$</span>, but this contradicts the fact that <span>$B^Y\in\mathfrak{g}^{\mathrm{hor},Y}.$</span> We now have to proof that for every <span>$B\in\mathfrak{g}^\mathrm{hor}$</span> we can find an element in <span>$\mathfrak{g}^{\mathrm{hor}, Y}$</span> such that this element is mapped to <span>$B$</span>. By a argument similar to the one above we can show that <span>$ABA^{-1}\in\mathfrak{g}^\mathrm{hor, Y}$</span> and this element maps to <span>$B$</span>. Proofing that the map is injective is now trivial.</p></div></details><p>We should note that we have written all Lie group and Lie algebra actions as simple matrix multiplications, like <span>$AE = Y$</span>. For some Lie groups and Lie algebras, as the Lie group of isomorphisms on some domain <span>$\mathcal{D}$</span>, this notation may not be appropriate [<a href="../../references/#holm2009geometric">21</a>]. These Lie groups are however not relevant for what we use in <code>GeometricMachineLearning</code> and we will stick to regular matrix notation.</p><h2 id="Global-Sections"><a class="docs-heading-anchor" href="#Global-Sections">Global Sections</a><a id="Global-Sections-1"></a><a class="docs-heading-anchor-permalink" href="#Global-Sections" title="Permalink"></a></h2><p>Note that the theorem above requires us to find an element <span>$A\in{}G$</span> such that <span>$AE = Y$</span>. We will call such a mapping <span>$\lambda:\mathcal{M}\to{}G$</span> a <em>global section</em><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. </p><div class="admonition is-info"><header class="admonition-header">Definition</header><div class="admonition-body"><p>We call a mapping <span>$\lambda$</span> from a homogeneous space <span>$\mathcal{M}$</span> to its associated Lie group <span>$G$</span> a <strong>global section</strong> if <span>$\forall{}Y\in\mathcal{M}$</span> it satisfies:</p><p class="math-container">\[\lambda(Y)E = Y,\]</p><p>where <span>$E$</span> is the distinct element of the homogeneous space.</p></div></div><p>Note that in general global sections are not unique because the rank of <span>$G$</span> is in general greater than that of <span>$\mathcal{M}$</span>. We give an example of how to construct such a global section for the Stiefel and the Grassmann manifolds below. </p><h2 id="The-Global-Tangent-Space-for-the-Stiefel-Manifold"><a class="docs-heading-anchor" href="#The-Global-Tangent-Space-for-the-Stiefel-Manifold">The Global Tangent Space for the Stiefel Manifold</a><a id="The-Global-Tangent-Space-for-the-Stiefel-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#The-Global-Tangent-Space-for-the-Stiefel-Manifold" title="Permalink"></a></h2><p>We now discuss the specific form of the global tangent space for the <a href="../../manifolds/homogeneous_spaces/#The-Stiefel-Manifold">Stiefel manifold</a>. We pick as distinct element <span>$E$</span> (which build by calling <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelProjection"><code>StiefelProjection</code></a>):</p><p class="math-container">\[E = \begin{bmatrix}
\mathbb{I}_n \\ 
\mathbb{O}
\end{bmatrix}\in{}St(n, N).\]</p><p>Based on this, elements of the vector space <span>$\mathfrak{g}^{\mathrm{hor}, E} =: \mathfrak{g}^{\mathrm{hor}}$</span> are: </p><p class="math-container">\[\bar{B} = \begin{pmatrix}
A &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where <span>$A$</span> is a skew-symmetric matrix of size <span>$n\times{}n$</span> and <span>$B$</span> is an arbitrary matrix of size <span>$(N - n)\times{}n$</span>. Arrays of type <span>$\mathfrak{g}^{\mathrm{hor}, E} \equiv \mathfrak{g}^\mathrm{hor}$</span> are implemented in <code>GeometricMachineLearning</code> under the name <a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a>.</p><p>We can call this with e.g. a skew-symmetric matrix <span>$A$</span> and an arbitrary matrix <span>$B$</span>:</p><pre><code class="language-julia hljs">N, n = 5, 2

A = rand(SkewSymMatrix, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 SkewSymMatrix{Float64, Vector{Float64}}:
 0.0       -0.759008
 0.759008   0.0</code></pre><pre><code class="language-julia hljs">B = rand(N - n, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×2 Matrix{Float64}:
 0.00407006  0.246893
 0.0739616   0.858875
 0.514135    0.0930704</code></pre><p>The constructor is then called as follows:</p><pre><code class="language-julia hljs">B̄ = StiefelLieAlgHorMatrix(A, B, N, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×5 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, Matrix{Float64}}:
 0.0         -0.759008   -0.00407006  -0.0739616  -0.514135
 0.759008     0.0        -0.246893    -0.858875   -0.0930704
 0.00407006   0.246893    0.0          0.0         0.0
 0.0739616    0.858875    0.0          0.0         0.0
 0.514135     0.0930704   0.0          0.0         0.0</code></pre><p>We can also call it with a matrix of shape <span>$N\times{}N$</span>:</p><pre><code class="language-julia hljs">B̄₂ = Matrix(B̄) # note that this does not have any special structure

StiefelLieAlgHorMatrix(B̄₂, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×5 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}}:
 0.0         -0.759008   -0.00407006  -0.0739616  -0.514135
 0.759008     0.0        -0.246893    -0.858875   -0.0930704
 0.00407006   0.246893    0.0          0.0         0.0
 0.0739616    0.858875    0.0          0.0         0.0
 0.514135     0.0930704   0.0          0.0         0.0</code></pre><p>Or we can call it on <span>$T_E\mathcal{M}\subset\mathbb{R}^{N\times{}n},$</span> i.e. a matrix of shape <span>$N\times{}n$</span>:</p><pre><code class="language-julia hljs">E = StiefelProjection(N, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×2 StiefelProjection{Float64, Matrix{Float64}}:
 1.0  0.0
 0.0  1.0
 0.0  0.0
 0.0  0.0
 0.0  0.0</code></pre><pre><code class="language-julia hljs">B̄₃ = B̄ * E

StiefelLieAlgHorMatrix(B̄₃, n)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×5 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}}:
 0.0         -0.759008   -0.00407006  -0.0739616  -0.514135
 0.759008     0.0        -0.246893    -0.858875   -0.0930704
 0.00407006   0.246893    0.0          0.0         0.0
 0.0739616    0.858875    0.0          0.0         0.0
 0.514135     0.0930704   0.0          0.0         0.0</code></pre><p>We now demonstrate how to map from an element of <span>$\mathfrak{g}^{\mathrm{hor}, Y}$</span> to an element of <span>$\mathfrak{g}^\mathrm{hor}$</span>:</p><pre><code class="language-julia hljs">using GeometricMachineLearning: Ω

Y = rand(StiefelManifold, N, n)
Δ = rgrad(Y, rand(N, n))
ΩΔ = Ω(Y, Δ)
λY = GlobalSection(Y)

λY_mat = Matrix(λY)

round.(λY_mat&#39; * ΩΔ * λY_mat; digits = 3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×5 Matrix{Float64}:
 -0.0    -1.35    0.141  -0.279   0.389
  1.35    0.0     0.098  -0.099  -0.185
 -0.141  -0.098   0.0    -0.0     0.0
  0.279   0.099   0.0     0.0    -0.0
 -0.389   0.185  -0.0     0.0     0.0</code></pre><p>Performing this computation directly is computationally very inefficient however and the user is strongly discouraged to call <code>Matrix</code> on an instance of <a href="#GeometricMachineLearning.GlobalSection"><code>GlobalSection</code></a>. The better option is calling <a href="#GeometricMachineLearning.global_rep"><code>global_rep</code></a>:</p><pre><code class="language-julia hljs">_round(global_rep(λY, Δ); digits = 3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×5 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, Matrix{Float64}}:
  0.0    -1.35   0.141  -0.279   0.389
  1.35    0.0    0.098  -0.099  -0.185
 -0.141  -0.098  0.0     0.0     0.0
  0.279   0.099  0.0     0.0     0.0
 -0.389   0.185  0.0     0.0     0.0</code></pre><p>Internally <a href="#GeometricMachineLearning.GlobalSection"><code>GlobalSection</code></a> calls the function <a href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.global_section</code></a> which does the following for the Stiefel manifold: </p><pre><code class="language-julia hljs">A = randn(N, N - n) # or the gpu equivalent
A = A - Y * (Y&#39; * A)
Y⟂ = qr(A).Q[1:N, 1:(N - n)]</code></pre><p>So we draw <span>$(N - n)$</span> new columns randomly, subtract the part that is spanned by the columns of <span>$Y$</span> and then perform a <span>$QR$</span> composition on the resulting matrix. The <span>$Q$</span> part of the decomposition is a matrix of <span>$(N - n)$</span> columns that is orthogonal to <span>$Y$</span> and is typically referred to as <span>$Y_\perp$</span>  [<a href="../../references/#absil2004riemannian">20</a>, <a href="../../references/#absil2008optimization">22</a>, <a href="../../references/#bendokat2020grassmann">23</a>]. We can easily check that this <span>$Y_\perp$</span> is indeed orthogonal to <span>$Y$</span>.</p><div class="admonition is-info"><header class="admonition-header">Theorem</header><div class="admonition-body"><p>The matrix <span>$Y_\perp$</span> constructed with the algorithm above satisfies</p><p class="math-container">\[Y^TY_\perp = \mathbb{O}_{n\times{}n},\]</p><p>and</p><p class="math-container">\[(Y_\perp)^TY_\perp = \mathbb{I}_n,\]</p><p>i.e. all the columns in the big matrix <span>$[Y, Y_\perp]\in\mathbb{R}^{N\times{}N}$</span> are mutually orthonormal and it therefore is an element of <span>$SO(N)$</span>.</p></div></div><details class="admonition is-details"><summary class="admonition-header">Proof</summary><div class="admonition-body"><p>The second property is trivially satisfied because the <span>$Q$</span> component of a <span>$QR$</span> decomposition is an orthogonal matrix. For the first property note that <span>$Y^TQR = \mathbb{O}$</span> is zero because we have subtracted the <span>$Y$</span> component from the matrix <span>$QR$</span>. The matrix <span>$R\in\mathbb{R}^{N\times{}(N-n)}$</span> further has the property <span>$[R]_{ij} = 0$</span> for <span>$i &gt; j$</span> and we have that </p><p class="math-container">\[(Y^TQ)R = [r_{11}(Y^TQ)_{1\bullet}, r_{12}(Y^TQ)_{1\bullet} + r_{22}(Y^TQ)_{2\bullet}, \ldots, \sum_{i=1}^{N-n}r_{i(N-n)}(Y^TQ)_{i\bullet}].\]</p><p>Now all the coefficients <span>$r_{ii}$</span> are non-zero because the matrix we performed the <span>$QR$</span> decomposition on has full rank and we can see that if <span>$(Y^TQ)R$</span> is zero <span>$Y^TQ$</span> also has to be zero.</p></div></details><p>The function <a href="#GeometricMachineLearning.global_rep"><code>global_rep</code></a> furthermore makes use of the following:</p><p class="math-container">\[    \mathtt{global\_rep}(Y) = \lambda(Y)^T\Omega(Y,\Delta)\lambda(Y) = EY^T\Delta{}E^T + \begin{bmatrix} \mathbb{O} \\ \bar{\lambda}^T\Delta{}E^T \end{bmatrix} - \begin{bmatrix} \mathbb{O} &amp; E\Delta^T\bar{\lambda} \end{bmatrix},\]</p><p>where <span>$\lambda(Y) = [Y, \bar{\lambda}].$</span></p><details class="admonition is-details"><summary class="admonition-header">Proof</summary><div class="admonition-body"><p>We derive the expression above: </p><p class="math-container">\[\begin{aligned}
\lambda(Y)^T\Omega(Y,\Delta)\lambda(Y)  &amp; = \lambda(Y)^T[(\mathbb{I} - \frac{1}{2}YY^T)\Delta{}Y^T - Y\Delta^T(\mathbb{I} - \frac{1}{2}YY^T)]\lambda(Y) \\
                                        &amp; = \lambda(Y)^T[(\mathbb{I} - \frac{1}{2}YY^T)\Delta{}E^T - Y\Delta^T(\lambda(Y) - \frac{1}{2}YE^T)] \\
                                        &amp; = \lambda(Y)^T\Delta{}E^T - \frac{1}{2}EY^T\Delta{}E^T - E\Delta^T\lambda(Y) + \frac{1}{2}E\Delta^TYE^T \\ 
                                        &amp; = \begin{bmatrix} Y^T\Delta{}E^T \\ \bar{\lambda}\Delta{}E^T \end{bmatrix} - \frac{1}{2}EY^T\Delta{}E - \begin{bmatrix} E\Delta^TY &amp; E\Delta^T\bar{\lambda} \end{bmatrix} + \frac{1}{2}E\Delta^TYE^T \\
                                        &amp; = \begin{bmatrix} Y^T\Delta{}E^T \\ \bar{\lambda}\Delta{}E^T \end{bmatrix} + E\Delta^TYE^T - \begin{bmatrix}E\Delta^TY &amp; E\Delta^T\bar{\lambda} \end{bmatrix} \\
                                                &amp; = EY^T\Delta{}E^T + E\Delta^TYE^T - E\Delta^TYE^T + \begin{bmatrix} \mathbb{O} \\ \bar{\lambda}\Delta{}E^T \end{bmatrix} - \begin{bmatrix} \mathbb{O} &amp; E\Delta^T\bar{\lambda} \end{bmatrix} \\
                                        &amp; = EY^T\Delta{}E^T + \begin{bmatrix} \mathbb{O}_{n\times{}N} \\ \bar{\lambda}\Delta{}E^T \end{bmatrix} - \begin{bmatrix} \mathbb{O}_{N\times{}n} &amp; E\Delta^T\bar{\lambda} \end{bmatrix},
\end{aligned}\]</p><p>which proofs our assertion.</p></div></details><p>This expression of <a href="#GeometricMachineLearning.global_rep"><code>global_rep</code></a> means we only need <span>$Y^T\Delta$</span> and <span>$\bar{\lambda}^T\Delta$</span> and this is what is used internally.</p><p>We now discuss the global tangent space for the Grassmann manifold. This is similar to the Stiefel case.</p><h2 id="Global-Tangent-Space-for-the-Grassmann-Manifold"><a class="docs-heading-anchor" href="#Global-Tangent-Space-for-the-Grassmann-Manifold">Global Tangent Space for the Grassmann Manifold</a><a id="Global-Tangent-Space-for-the-Grassmann-Manifold-1"></a><a class="docs-heading-anchor-permalink" href="#Global-Tangent-Space-for-the-Grassmann-Manifold" title="Permalink"></a></h2><p>In the case of the Grassmann manifold we construct the global tangent space with respect to the distinct element <span>$\mathcal{E}=\mathrm{span}(E)\in{}Gr(n,N)$</span>, where <span>$E$</span> is again the same matrix.</p><p>The tangent tangent space <span>$T_\mathcal{E}Gr(n,N)$</span> can be represented through matrices: </p><p class="math-container">\[\begin{pmatrix}
    0 &amp; \cdots &amp; 0 \\
    \cdots &amp; \cdots &amp; \cdots \\ 
    0 &amp; \cdots &amp; 0 \\
    b_{11} &amp; \cdots &amp; b_{1n} \\
    \cdots &amp; \cdots &amp; \cdots \\ 
    b_{(N-n)1} &amp; \cdots &amp; b_{(N-n)n}
\end{pmatrix}.\]</p><p>This representation is based on the identification <span>$T_\mathcal{E}Gr(n,N)\to{}T_E\mathcal{S}_E$</span> that was discussed in the section on the <a href="../../manifolds/homogeneous_spaces/#The-Grassmann-Manifold">Grassmann manifold</a><sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>. We use the following notation:</p><p class="math-container">\[\mathfrak{g}^\mathrm{hor} = \mathfrak{g}^{\mathrm{hor},\mathcal{E}} = \left\{\begin{pmatrix} 0 &amp; -B^T \\ B &amp; 0 \end{pmatrix}: \text{$B\in\mathbb{R}^{(N-n)\times{}n}$ is arbitrary}\right\}.\]</p><p>This is equivalent to the horizontal component of <span>$\mathfrak{g}$</span> for the Stiefel manifold for the case when <span>$A$</span> is zero. This is a reflection of the rotational invariance of the Grassmann manifold: the skew-symmetric matrices <span>$A$</span> are connected to the group of rotations <span>$O(n)$</span> which is factored out in the Grassmann manifold <span>$Gr(n,N)\simeq{}St(n,N)/O(n)$</span>. In <code>GeometricMachineLearning</code> we thus treat the Grassmann manifold as being embedded in the Stiefel manifold. In [<a href="../../references/#bendokat2020grassmann">23</a>] viewing the Grassmann manifold as a quotient space of the Stiefel manifold is important for &quot;feasibility&quot; in &quot;practical computations&quot;. </p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AbstractLieAlgHorMatrix" href="#GeometricMachineLearning.AbstractLieAlgHorMatrix"><code>GeometricMachineLearning.AbstractLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AbstractLieAlgHorMatrix &lt;: AbstractMatrix</code></pre><p><code>AbstractLieAlgHorMatrix</code> is a supertype for various horizontal components of Lie algebras. We usually call this <span>$\mathfrak{g}^\mathrm{hor}$</span>.</p><p>See <a href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>StiefelLieAlgHorMatrix</code></a> and <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a> for concrete examples.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/arrays/abstract_lie_algebra_horizontal.jl#LL1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">StiefelLieAlgHorMatrix(A::SkewSymMatrix, B::AbstractMatrix, N::Integer, n::Integer)</code></pre><p>Build an instance of <code>StiefelLieAlgHorMatrix</code> based on a skew-symmetric matrix <code>A</code> and an arbitrary matrix <code>B</code>.</p><p>An element of StiefelLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where <span>$A$</span> is skew-symmetric (this is <a href="../skew_symmetric_matrix/#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> in <code>GeometricMachineLearning</code>).</p><p>Also see <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p><p><strong>Extended help</strong></p><p><code>StiefelLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric).</p><p>The projection here is: <span>$\pi:S \to SE$</span> where </p><p class="math-container">\[E = \begin{bmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{bmatrix}.\]</p><p>The matrix <span>$E$</span> is implemented under <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelProjection"><code>StiefelProjection</code></a> in <code>GeometricMachineLearning</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/arrays/stiefel_lie_algebra_horizontal.jl#LL1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.StiefelLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}" href="#GeometricMachineLearning.StiefelLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}"><code>GeometricMachineLearning.StiefelLieAlgHorMatrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">StiefelLieAlgHorMatrix(D::AbstractMatrix, n::Integer)</code></pre><p>Take a big matrix as input and build an instance of <code>StiefelLieAlgHorMatrix</code>.</p><p>The integer <span>$N$</span> in <span>$St(n, N)$</span> is the number of rows of <code>D</code>.</p><p><strong>Extended help</strong></p><p>If the constructor is called with a big <span>$N\times{}N$</span> matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\mathrm{skew}(A) &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>The operation <span>$\mathrm{skew}:\mathbb{R}^{n\times{}n}\to\mathcal{S}_\mathrm{skew}(n)$</span> is the skew-symmetrization operation. This is equivalent to calling of <a href="../skew_symmetric_matrix/#GeometricMachineLearning.SkewSymMatrix"><code>SkewSymMatrix</code></a> with an <span>$n\times{}n$</span> matrix.</p><p>This can also be seen as the operation:</p><p class="math-container">\[D \mapsto \Omega(E, DE) = \mathrm{skew}\left(2 \left(\mathbb{I} - \frac{1}{2} E E^T \right) DE E^T\right).\]</p><p>Also see <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/arrays/stiefel_lie_algebra_horizontal.jl#LL41-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GrassmannLieAlgHorMatrix(B::AbstractMatrix, N::Integer, n::Integer)</code></pre><p>Build an instance of <code>GrassmannLieAlgHorMatrix</code> based on an arbitrary matrix <code>B</code> of size <span>$(N-n)\times{}n$</span>.</p><p><code>GrassmannLieAlgHorMatrix</code> is the <em>horizontal component of the Lie algebra of skew-symmetric matrices</em> (with respect to the canonical metric).</p><p><strong>Extended help</strong></p><p>The projection here is: <span>$\pi:S \to SE/\sim$</span> where </p><p class="math-container">\[E = \begin{bmatrix} \mathbb{I}_{n} \\ \mathbb{O}_{(N-n)\times{}n}  \end{bmatrix},\]</p><p>and the equivalence relation is </p><p class="math-container">\[V_1 \sim V_2 \iff \exists A\in\mathcal{S}_\mathrm{skew}(n) \text{ such that } V_2 = V_1 + \begin{bmatrix} A \\ \mathbb{O} \end{bmatrix}\]</p><p>An element of GrassmannLieAlgMatrix takes the form: </p><p class="math-container">\[\begin{pmatrix}
\bar{\mathbb{O}} &amp; B^T \\ B &amp; \mathbb{O}
\end{pmatrix},\]</p><p>where <span>$\bar{\mathbb{O}}\in\mathbb{R}^{n\times{}n}$</span> and <span>$\mathbb{O}\in\mathbb{R}^{(N - n)\times(N-n)}.$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/arrays/grassmann_lie_algebra_horizontal.jl#LL1-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GrassmannLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}" href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix-Tuple{AbstractMatrix, Int64}"><code>GeometricMachineLearning.GrassmannLieAlgHorMatrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GrassmannLieAlgHorMatrix(D::AbstractMatrix, n::Integer)</code></pre><p>Take a big matrix as input and build an instance of <code>GrassmannLieAlgHorMatrix</code>.</p><p>The integer <span>$N$</span> in <span>$Gr(n, N)$</span> here is the number of rows of <code>D</code>.</p><p><strong>Extended help</strong></p><p>If the constructor is called with a big <span>$N\times{}N$</span> matrix, then the projection is performed the following way: </p><p class="math-container">\[\begin{pmatrix}
A &amp; B_1  \\
B_2 &amp; D
\end{pmatrix} \mapsto 
\begin{pmatrix}
\bar{\mathbb{O}} &amp; -B_2^T \\ 
B_2 &amp; \mathbb{O}
\end{pmatrix}.\]</p><p>This can also be seen as the operation:</p><p class="math-container">\[D \mapsto \Omega(E, DE - EE^TDE),\]</p><p>where <span>$\Omega$</span> is the horizontal lift <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/arrays/grassmann_lie_algebra_horizontal.jl#LL43-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.GlobalSection" href="#GeometricMachineLearning.GlobalSection"><code>GeometricMachineLearning.GlobalSection</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GlobalSection(Y)</code></pre><p>Construct a global section for <code>Y</code>.  </p><p>A global section <span>$\lambda$</span> is a mapping from a homogeneous space <span>$\mathcal{M}$</span> to the corresponding Lie group <span>$G$</span> such that </p><p class="math-container">\[\lambda(Y)E = Y,\]</p><p>Also see <a href="#GeometricMachineLearning.apply_section"><code>apply_section</code></a> and <a href="#GeometricMachineLearning.global_rep"><code>global_rep</code></a>.</p><p><strong>Implementation</strong></p><p>For an implementation of <code>GlobalSection</code> for a custom array (especially manifolds), the function <a href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>global_section</code></a> has to be generalized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.Matrix-Tuple{GlobalSection}" href="#Base.Matrix-Tuple{GlobalSection}"><code>Base.Matrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Matrix(λY::GlobalSection)</code></pre><p>Put <code>λY</code> into matrix form. </p><p>This is not recommended if speed is important!</p><p>Use <a href="#GeometricMachineLearning.apply_section"><code>apply_section</code></a> and <a href="#GeometricMachineLearning.global_rep"><code>global_rep</code></a> instead!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL37-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_section" href="#GeometricMachineLearning.apply_section"><code>GeometricMachineLearning.apply_section</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">apply_section(λY::GlobalSection{T, AT}, Y₂::AT) where {T, AT &lt;: StiefelManifold{T}}</code></pre><p>Apply <code>λY</code> to <code>Y₂</code>.</p><p>Mathematically this is the group action of the element <span>$\lambda{}Y\in{}G$</span> on the element <span>$Y_2$</span> of the homogeneous space <span>$\mathcal{M}$</span>.</p><p>Internally it calls <a href="#GeometricMachineLearning.apply_section!"><code>apply_section!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL59-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.apply_section!" href="#GeometricMachineLearning.apply_section!"><code>GeometricMachineLearning.apply_section!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">apply_section!(Y::AT, λY::GlobalSection{T, AT}, Y₂::AT) where {T, AT&lt;:StiefelManifold{T}}</code></pre><p>Apply <code>λY</code> to <code>Y₂</code> and store the result in <code>Y</code>.</p><p>This is the inplace version of <a href="#GeometricMachineLearning.apply_section"><code>apply_section</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL75-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:*-Tuple{GlobalSection, Manifold}" href="#Base.:*-Tuple{GlobalSection, Manifold}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">λY * Y</code></pre><p>Apply the element <code>λY</code> onto <code>Y</code>.</p><p>Here <code>λY</code> is an element of a Lie group and <code>Y</code> is an element of a homogeneous space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL50-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.global_section</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">global_section(Y::StiefelManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>This matrix is also called <span>$Y_\perp$</span> [<a href="../../references/#absil2004riemannian">20</a>, <a href="../../references/#absil2008optimization">22</a>, <a href="../../references/#bendokat2020grassmann">23</a>].</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: global_section
import Random

Random.seed!(123)

Y = StiefelManifold([1. 0.; 0. 1.; 0. 0.; 0. 0.])

round.(Matrix(global_section(Y)); digits = 3)

# output

4×2 Matrix{Float64}:
 0.0    -0.0
 0.0     0.0
 0.936  -0.353
 0.353   0.936</code></pre><p>Further note that we convert the <code>QRCompactWYQ</code> object to a <code>Matrix</code> before we display it.</p><p><strong>Implementation</strong></p><p>The implementation is done with a QR decomposition (<code>LinearAlgebra.qr!</code>). Internally we do: </p><pre><code class="language-julia hljs">A = randn(N, N - n) # or the gpu equivalent
A = A - Y.A * (Y.A&#39; * A)
qr!(A).Q</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/manifolds/stiefel_manifold.jl#LL89-L129">source</a></section><section><div><pre><code class="language-julia hljs">global_section(Y::GrassmannManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>The method <code>global_section</code> for the Grassmann manifold is equivalent to that for the <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> (we represent the Grassmann manifold as an embedding in the Stiefel manifold). </p><p>See the documentation for <a href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>global_section(Y::StiefelManifold{T}) where T</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/manifolds/grassmann_manifold.jl#LL68-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_section-Union{Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T" href="#GeometricMachineLearning.global_section-Union{Tuple{GrassmannManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>GeometricMachineLearning.global_section</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">global_section(Y::StiefelManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>This matrix is also called <span>$Y_\perp$</span> [<a href="../../references/#absil2004riemannian">20</a>, <a href="../../references/#absil2008optimization">22</a>, <a href="../../references/#bendokat2020grassmann">23</a>].</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: global_section
import Random

Random.seed!(123)

Y = StiefelManifold([1. 0.; 0. 1.; 0. 0.; 0. 0.])

round.(Matrix(global_section(Y)); digits = 3)

# output

4×2 Matrix{Float64}:
 0.0    -0.0
 0.0     0.0
 0.936  -0.353
 0.353   0.936</code></pre><p>Further note that we convert the <code>QRCompactWYQ</code> object to a <code>Matrix</code> before we display it.</p><p><strong>Implementation</strong></p><p>The implementation is done with a QR decomposition (<code>LinearAlgebra.qr!</code>). Internally we do: </p><pre><code class="language-julia hljs">A = randn(N, N - n) # or the gpu equivalent
A = A - Y.A * (Y.A&#39; * A)
qr!(A).Q</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/manifolds/stiefel_manifold.jl#LL89-L129">source</a></section><section><div><pre><code class="language-julia hljs">global_section(Y::GrassmannManifold)</code></pre><p>Compute a matrix of size <span>$N\times(N-n)$</span> whose columns are orthogonal to the columns in <code>Y</code>.</p><p>The method <code>global_section</code> for the Grassmann manifold is equivalent to that for the <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a> (we represent the Grassmann manifold as an embedding in the Stiefel manifold). </p><p>See the documentation for <a href="#GeometricMachineLearning.global_section-Union{Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}}, Tuple{T}} where T"><code>global_section(Y::StiefelManifold{T}) where T</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/manifolds/grassmann_manifold.jl#LL68-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.global_rep" href="#GeometricMachineLearning.global_rep"><code>GeometricMachineLearning.global_rep</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">global_rep(λY::GlobalSection{T, AT}, Δ::AbstractMatrix{T}) where {T, AT&lt;:StiefelManifold{T}}</code></pre><p>Express <code>Δ</code> (an the tangent space of <code>Y</code>) as an instance of <code>StiefelLieAlgHorMatrix</code>.</p><p>This maps an element from <span>$T_Y\mathcal{M}$</span> to an element of <span>$\mathfrak{g}^\mathrm{hor}$</span>. </p><p>These two spaces are isomorphic where the isomorphism where the isomorphism is established through <span>$\lambda(Y)\in{}G$</span> via:</p><p class="math-container">\[T_Y\mathcal{M} \to \mathfrak{g}^{\mathrm{hor}}, \Delta \mapsto \lambda(Y)^{-1}\Omega(Y, \Delta)\lambda(Y).\]</p><p>Also see <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.Ω-Union{Tuple{T}, Tuple{StiefelManifold{T, AT} where AT&lt;:AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>GeometricMachineLearning.Ω</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round
import Random 

Random.seed!(123)

Y = rand(StiefelManifold, 6, 3)
Δ = rgrad(Y, randn(6, 3))
λY = GlobalSection(Y)

_round(global_rep(λY, Δ); digits = 3)

# output

6×6 StiefelLieAlgHorMatrix{Float64, SkewSymMatrix{Float64, Vector{Float64}}, Matrix{Float64}}:
  0.0     0.679   1.925   0.981  -2.058   0.4
 -0.679   0.0     0.298  -0.424   0.733  -0.919
 -1.925  -0.298   0.0    -1.815   1.409   1.085
 -0.981   0.424   1.815   0.0     0.0     0.0
  2.058  -0.733  -1.409   0.0     0.0     0.0
 -0.4     0.919  -1.085   0.0     0.0     0.0</code></pre><p><strong>Implementation</strong></p><p>The function <code>global_rep</code> does in fact not perform the entire map <span>$\lambda(Y)^{-1}\Omega(Y, \Delta)\lambda(Y)$</span> but only</p><p class="math-container">\[\Delta \mapsto \mathrm{skew}(Y^T\Delta),\]</p><p>to get the small skew-symmetric matrix <span>$A\in\mathcal{S}_\mathrm{skew}(n)$</span> and </p><p class="math-container">\[\Delta \mapsto (\lambda(Y)_{[1:N, n:N]}^T \Delta)_{[1:(N-n), 1:n]},\]</p><p>to get the arbitrary matrix <span>$B\in\mathbb{R}^{(N-n)\times{}n}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL127-L183">source</a></section><section><div><pre><code class="language-julia hljs">global_rep(λY::GlobalSection{T, AT}, Δ::AbstractMatrix{T}) where {T, AT&lt;:GrassmannManifold{T}}</code></pre><p>Express <code>Δ</code> (an element of the tangent space of <code>Y</code>) as an instance of <a href="#GeometricMachineLearning.GrassmannLieAlgHorMatrix"><code>GrassmannLieAlgHorMatrix</code></a>.</p><p>The method <code>global_rep</code> for <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.GrassmannManifold"><code>GrassmannManifold</code></a> is similar to that for <a href="../../manifolds/homogeneous_spaces/#GeometricMachineLearning.StiefelManifold"><code>StiefelManifold</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: _round
import Random 

Random.seed!(123)

Y = rand(GrassmannManifold, 6, 3)
Δ = rgrad(Y, randn(6, 3))
λY = GlobalSection(Y)

_round(global_rep(λY, Δ); digits = 3)

# output

6×6 GrassmannLieAlgHorMatrix{Float64, Matrix{Float64}}:
  0.0     0.0     0.0     0.981  -2.058   0.4
  0.0     0.0     0.0    -0.424   0.733  -0.919
  0.0     0.0     0.0    -1.815   1.409   1.085
 -0.981   0.424   1.815   0.0     0.0     0.0
  2.058  -0.733  -1.409   0.0     0.0     0.0
 -0.4     0.919  -1.085   0.0     0.0     0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/756f5ba5823a6951e42327905292a860fc7dbfcd/src/optimizers/manifold_related/global_sections.jl#LL194-L226">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[20]</dt><dd><div>P.-A. Absil, R. Mahony and R. Sepulchre. <em>Riemannian geometry of Grassmann manifolds with a view on algorithmic computation</em>. Acta Applicandae Mathematica <strong>80</strong>, 199–220 (2004).</div></dd><dt>[22]</dt><dd><div>P.-A. Absil, R. Mahony and R. Sepulchre. <em>Optimization algorithms on matrix manifolds</em> (Princeton University Press, Princeton, New Jersey, 2008).</div></dd><dt>[23]</dt><dd><div>T. Bendokat, R. Zimmermann and P.-A. Absil. <em>A Grassmann manifold handbook: Basic geometry and computational aspects</em>, arXiv preprint arXiv:2011.13699 (2020).</div></dd><dt>[7]</dt><dd><div>B. Brantner. <em>Generalizing Adam To Manifolds For Efficiently Training Transformers</em>, arXiv preprint arXiv:2305.16901 (2023).</div></dd><dt>[109]</dt><dd><div>T. Frankel. <em>The geometry of physics: an introduction</em> (Cambridge university press, Cambridge, UK, 2011).</div></dd></dl></div><!--<h1 id="References-2"><a class="docs-heading-anchor" href="#References-2">References</a><a class="docs-heading-anchor-permalink" href="#References-2" title="Permalink"></a></h1><div class="citation noncanonical"><dl><dt>[14]</dt><dd><div>S. Lipschutz. <em>General Topology</em> (McGraw-Hill Book Company, New York City, New York, 1965).</div></dd><dt>[17]</dt><dd><div>S. Lang. <em>Real and functional analysis</em>. Vol. 142 (Springer Science &amp; Business Media, 2012).</div></dd><dt>[15]</dt><dd><div>S. Lang. <em>Fundamentals of differential geometry</em>. Vol. 191 (Springer Science &amp; Business Media, 2012).</div></dd><dt>[16]</dt><dd><div>S. I. Richard L. Bishop. <em>Tensor Analysis on Manifolds</em> (Dover Publications, Mineola, New York, 1980).</div></dd><dt>[19]</dt><dd><div>M. P. Do Carmo and J. Flaherty Francis. <em>Riemannian geometry</em>. Vol. 2 (Springer, 1992).</div></dd><dt>[20]</dt><dd><div>P.-A. Absil, R. Mahony and R. Sepulchre. <em>Riemannian geometry of Grassmann manifolds with a view on algorithmic computation</em>. Acta Applicandae Mathematica <strong>80</strong>, 199–220 (2004).</div></dd><dt>[23]</dt><dd><div>T. Bendokat, R. Zimmermann and P.-A. Absil. <em>A Grassmann manifold handbook: Basic geometry and computational aspects</em>, arXiv preprint arXiv:2011.13699 (2020).</div></dd><dt>[109]</dt><dd><div>T. Frankel. <em>The geometry of physics: an introduction</em> (Cambridge university press, Cambridge, UK, 2011).</div></dd><dt>[39]</dt><dd><div>B. O&#39;neill. <em>Semi-Riemannian geometry with applications to relativity</em> (Academic press, New York City, New York, 1983).</div></dd><dt>[37]</dt><dd><div>T. Bendokat and R. Zimmermann. <em>The real symplectic Stiefel and Grassmann manifolds: metrics, geodesics and applications</em>, arXiv preprint arXiv:2108.12447 (2021).</div></dd></dl></div>--><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Global sections are also crucial for <a href="../../optimizers/manifold_related/parallel_transport/#Parallel-Transport">parallel transport</a> in <code>GeometricMachineLearning</code>. A global section is first updated, i.e. <span>$\Lambda^{(t)} \gets \mathrm{update}(\Lambda^{(t-1)});$</span> and on the basis of this we then update the element of the manifold <span>$Y\in\mathcal{M}$</span> and the tangent vector <span>$\Delta\in{}T\mathcal{M}$</span>.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>We derived the following expression for the Riemannian gradient of the Grassmann manifold: <span>$\mathrm{grad}_\mathcal{Y}^{Gr}L = \nabla_Y{}L - YY^T\nabla_YL$</span>. The tangent space to the element <span>$\mathcal{E}$</span> can thus be written as <span>$\bar{B} - EE^T\bar{B}$</span> where <span>$B\in\mathbb{R}^{N\times{}n}$</span> and the matrices in this tangent space have the desired form. </li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../skew_symmetric_matrix/">« Symmetric and Skew-Symmetric Matrices</a><a class="docs-footer-nextpage" href="../tensors/">Tensors »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Wednesday 19 February 2025 16:01">Wednesday 19 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
