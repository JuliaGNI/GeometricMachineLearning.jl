@doc raw"""
    BFGSOptimizer(Î·, Î´)

Make an instance of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) optimizer. 

`Î·` is the *learning rate*.
`Î´` is a stabilization parameter.
"""
struct BFGSOptimizer{T<:Real} <: OptimizerMethod{T}
    Î·::T
    Î´::T

    function BFGSOptimizer(Î·::T = 1f-2, Î´=1f-8) where T 
        new{T}(Î·, T(Î´))
    end
end

@doc raw"""
    update!(o::Optimizer{<:BFGSOptimizer}, C, B)

Peform an update with the BFGS optimizer. 

`C` is the cache, `B` contains the gradient information (the output of [`global_rep`](@ref) in general).

First we compute the *final velocity* with
```julia
vecS = -o.method.Î· * C.H * vec(B)
```
and then we update `H`
```julia
C.H .= (ð•€ - Ï * SY) * C.H * (ð•€ - Ï * SY') + Ï * vecS * vecS'
```
where `SY` is `vecS * Y'` and `ð•€` is the idendity. 

# Implementation

For stability we use `Î´` for computing `Ï`:
```julia
Ï = 1. / (vecS' * Y + o.method.Î´)
```

This is similar to the [`AdamOptimizer`](@ref)

# Extended help 

If we have weights on a [`Manifold`](@ref) than the updates are slightly more difficult.
In this case the [`vec`](@ref) operation has to be generalized to the corresponding *global tangent space*.
"""
function update!(o::Optimizer{<:BFGSOptimizer}, C::BFGSCache, B::AbstractArray)
    T = eltype(o)
    # in the first step we compute the difference between the current and the previous mapped gradients:
    Y = vec(B - C.B)
    # compute the descent direction
    P = -C.H * vec(B)
    # compute S 
    vecS = o.method.Î· * P
    # store gradient
    assign!(C.B, copy(B))
    # output final velocity
    assign!(vec(B), copy(vecS))
    # compute SY and HY
    Ï = one(T) / (vecS' * Y + o.method.Î´)
    SY = vecS * Y'
    ð•€ = one(SY)
    # compute H
    C.H .= (ð•€ - Ï * SY) * C.H * (ð•€ - Ï * SY') + Ï * vecS * vecS'
end