<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Volume-Preserving Transformer for the Rigid Body · GeometricMachineLearning.jl</title><meta name="title" content="Volume-Preserving Transformer for the Rigid Body · GeometricMachineLearning.jl"/><meta property="og:title" content="Volume-Preserving Transformer for the Rigid Body · GeometricMachineLearning.jl"/><meta property="twitter:title" content="Volume-Preserving Transformer for the Rigid Body · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_transformer_rigid_body/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_transformer_rigid_body/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/tutorials/volume_preserving_transformer_rigid_body/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../../reduced_order_modeling/reduced_order_modeling/">General Framework</a></li><li><a class="tocitem" href="../../reduced_order_modeling/pod_autoencoders/">POD and Autoencoders</a></li><li><a class="tocitem" href="../../reduced_order_modeling/losses/">Losses and Errors</a></li><li><a class="tocitem" href="../../reduced_order_modeling/symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../architectures/symplectic_transformer/">Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../matrix_softmax/">Matrix Attention</a></li><li class="is-active"><a class="tocitem" href>Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../symplectic_transformer/">Symplectic Transformer</a></li><li><a class="tocitem" href="../adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Volume-Preserving Transformer for the Rigid Body</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Volume-Preserving Transformer for the Rigid Body</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/tutorials/volume_preserving_transformer_rigid_body.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Volume-Preserving-Transformer-for-the-Rigid-Body"><a class="docs-heading-anchor" href="#The-Volume-Preserving-Transformer-for-the-Rigid-Body">The Volume-Preserving Transformer for the Rigid Body</a><a id="The-Volume-Preserving-Transformer-for-the-Rigid-Body-1"></a><a class="docs-heading-anchor-permalink" href="#The-Volume-Preserving-Transformer-for-the-Rigid-Body" title="Permalink"></a></h1><p>Here we train a <a href="../../architectures/volume_preserving_feedforward/#Volume-Preserving-Feedforward-Neural-Network">volume-preserving feedforward neural network</a>, a <a href="../../architectures/transformer/#Standard-Transformer">standard transformer</a> and a <a href="../../architectures/volume_preserving_transformer/#Volume-Preserving-Transformer">volume-preserving transformer</a> on a rigid body [<a href="../../references/#hairer2006geometric">1</a>, <a href="../../references/#arnold1978mathematical">27</a>]. These are also the results presented in [<a href="../../references/#brantner2024volume">4</a>]. The ODE that describes the rigid body is: </p><p class="math-container">\[\frac{d}{dt}\begin{pmatrix} z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} Az_2z_3 \\ Bz_1z_3 \\ Cz_1z_2 \end{pmatrix}.\]</p><p>In the following we use <span>$A = 1,$</span> <span>$B = 1/2$</span> and <span>$C = -1/2.$</span> For a derivation of this equation see [<a href="../../references/#brantner2024volume">4</a>]. </p><p>We first generate the data. The initial conditions that we use are:</p><p class="math-container">\[\mathtt{ics} = \left\{ \begin{pmatrix} \sin(\alpha) \\ 0 \\ \cos(\alpha) \end{pmatrix}, \begin{pmatrix} 0 \\ \sin(\alpha) \\ \cos(\alpha) \end{pmatrix}: \alpha = 0.1\mathtt{:}0.01\mathtt{:}2\pi \right\}.\]</p><p>We build these initial conditions by concatenating <span>$\mathtt{ics}_1$</span> and <span>$\mathtt{ics}_2$</span>:</p><pre><code class="language-julia hljs">const ics₁ = [[sin(val), 0., cos(val)] for val in .1:.01:(2*π)]
const ics₂ = [[0., sin(val), cos(val)] for val in .1:.01:(2*π)]
const ics = [ics₁..., ics₂...]</code></pre><p>We now generate the data by integrating with:</p><pre><code class="language-julia hljs">const tstep = .2
const tspan = (0., 20.)</code></pre><p>The rigid body is implemented in <a href="https://github.com/JuliaGNI/GeometricProblems.jl"><code>GeometricProblems</code></a>:</p><pre><code class="language-julia hljs">using GeometricIntegrators: integrate, ImplicitMidpoint
using GeometricProblems.RigidBody: odeproblem, odeensemble, default_parameters

ensemble_problem = odeensemble(ics; tspan = tspan, tstep = tstep, parameters = default_parameters)
ensemble_solution = integrate(ensemble_problem, ImplicitMidpoint())

dl_cpu = DataLoader(ensemble_solution; suppress_info = true)</code></pre><p>We plot the trajectories for some of the initial conditions to get and idea of what the data look like:</p><pre><code class="language-julia hljs">const n_trajectories_to_plot = 5
indices = Int.(ceil.(size(dl_cpu.input, 3) * rand(n_trajectories_to_plot)))

trajectories = [dl_cpu.input[:, :, index] for index in indices]</code></pre><p><img src="../rigid_body_trajectories_light.png" alt="A sample of rigid body trajectories. This system has two conserved quantities."/> <img src="../rigid_body_trajectories_dark.png" alt="A sample of rigid body trajectories. This system has two conserved quantities."/></p><p>The rigid body has two conserved quantities:</p><ol><li>one conserved quantity is the <a href="../../structure_preservation/symplecticity/#Symplectic-Systems">Hamiltonian of the system</a>: <span>$H(z_1, z_2, z_3) = \frac{1}{2}\left( \frac{z_1^2}{I_1} + \frac{z_2^2}{I_2} + \frac{z_3^2}{I_3} \right),$</span></li><li>the second one is the quadratic invariant: <span>$I(z_1, z_2, z_3) = z_1^2 + z_2^2 + z_3^2.$</span></li></ol><p>The coefficients <span>$I_1,$</span> <span>$I_2$</span> and <span>$I_3$</span> can be obtained through</p><p class="math-container">\[\begin{aligned}
A = \frac{I_2 - I_3}{I_2I_3}, \\ 
B = \frac{I_3 - I_1}{I_3I_1}, \\ 
C = \frac{I_1 - I_2}{I_1I_2}.
\end{aligned}\]</p><p>The second conserved invariant <span>$I(\cdot, \cdot, \cdot)$</span> is visualized through the sphere in the figure above. The conserved Hamiltonian is the reason for why the curves are closed.</p><p>The rigid body has Poisson structure [<a href="../../references/#hairer2006geometric">1</a>], but does not have canonical Hamiltonian structure. We can thus not use <a href="../../architectures/sympnet/#SympNet-Architecture">SympNets</a> or <a href="../../architectures/linear_symplectic_transformer/#Linear-Symplectic-Transformer">symplectic transformers</a> here, but the ODE is clearly divergence-free. We use this to demonstrate the efficacy of the <a href="../../architectures/volume_preserving_transformer/#Volume-Preserving-Transformer">volume-preserving transformer</a>. We set up our networks:</p><pre><code class="language-julia hljs"># hyperparameters concerning the architectures
const sys_dim = size(dl_cpu.input, 1)
const n_heads = 1
const L = 3 # transformer blocks
const activation = tanh
const resnet_activation = tanh
const n_linear = 1
const n_blocks = 2
const skew_sym = false
const seq_length = 3

arch_vpff = VolumePreservingFeedForward(sys_dim, n_blocks * L, n_linear, resnet_activation)
arch_vpt = VolumePreservingTransformer(sys_dim, seq_length;
                                            n_blocks = n_blocks,
                                            n_linear = n_linear,
                                            L = L,
                                            activation = resnet_activation,
                                            skew_sym = skew_sym)
arch_st = StandardTransformerIntegrator(sys_dim;    n_heads = n_heads,
                                                    transformer_dim = sys_dim,
                                                    n_blocks = n_blocks,
                                                    L = L,
                                                    resnet_activation = resnet_activation,
                                                    add_connection = false)</code></pre><p>Note that we set the keyword <code>skew_sym</code> to <code>false</code> here. This is different from what we did in [<a href="../../references/#brantner2024volume">4</a>], where it was set to true<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. We allocate the networks on GPU:</p><pre><code class="language-julia hljs">using CUDA
backend = CUDABackend()</code></pre><pre><code class="language-julia hljs">T = Float32

dl = DataLoader(dl_cpu, backend, T)
nn_vpff = NeuralNetwork(arch_vpff, backend, T)
nn_vpt = NeuralNetwork(arch_vpt, backend, T)
nn_st = NeuralNetwork(arch_st, backend, T)

(parameterlength(nn_vpff), parameterlength(nn_vpt), parameterlength(nn_st))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(135, 180, 189)</code></pre><p>We now train the various networks. For this we use <a href="../../optimizers/optimizer_methods/#GeometricMachineLearning.AdamOptimizerWithDecay"><code>AdamOptimizerWithDecay</code></a>:</p><pre><code class="language-julia hljs">const n_epochs = 500000
const batch_size = 16384
const feedforward_batch = Batch(batch_size)
const transformer_batch = Batch(batch_size, seq_length, seq_length)
const opt_method = AdamOptimizerWithDecay(n_epochs, T; η₁ = 1e-2, η₂ = 1e-6)

o_vpff = Optimizer(opt_method, nn_vpff)
o_vpt = Optimizer(opt_method, nn_vpt)
o_st = Optimizer(opt_method, nn_st)</code></pre><pre><code class="language-julia hljs">o_vpff(nn_vpff, dl, feedforward_batch, n_epochs)
o_vpt(nn_vpt, dl, transformer_batch, n_epochs)
o_st(nn_st, dl, transformer_batch, n_epochs)</code></pre><p>After the networks have been trained we map the parameters to cpu:</p><pre><code class="language-julia hljs">const mtc = GeometricMachineLearning.map_to_cpu
nn_vpff = mtc(nn_vpff)
nn_vpt = mtc(nn_vpt)
nn_st = mtc(nn_st)</code></pre><p>After this we use <a href="../../architectures/neural_network_integrators/#Base.iterate-Union{Tuple{BT}, Tuple{AT}, Tuple{T}, Tuple{NeuralNetwork{&lt;:NeuralNetworkIntegrator}, BT}} where {T, AT&lt;:AbstractVector{T}, BT&lt;:@NamedTuple{q::AT, p::AT}}"><code>iterate</code></a> to obtain predicted orbits:</p><pre><code class="language-julia hljs">ics_val₁ = [0., sin(0.9), cos(0.9 + π)]
ics_val₂ = [0., sin(1.1), cos(1.1)]
const t_validation = 120

function produce_trajectory(ics_val)
    problem = odeproblem(ics_val;   tspan = (0, t_validation),
                                    tstep = tstep,
                                    parameters = default_parameters)
    solution = integrate(problem, ImplicitMidpoint())
    trajectory = Float32.(DataLoader(solution; suppress_info = true).input)
    nn_vpff_solution = iterate(nn_vpff, trajectory[:, 1];
                                            n_points = Int(floor(t_validation / tstep)) + 1)
    nn_vpt_solution = iterate(nn_vpt, trajectory[:, 1:seq_length];
                                            n_points = Int(floor(t_validation / tstep)) + 1)
    nn_st_solution = iterate(nn_st, trajectory[:, 1:seq_length];
                                            n_points = Int(floor(t_validation / tstep)) + 1)
    trajectory, nn_vpff_solution, nn_vpt_solution, nn_st_solution
end

trajectory₁, nn_vpff_solution₁, nn_vpt_solution₁, nn_st_solution₁ = produce_trajectory(ics_val₁)
trajectory₂, nn_vpff_solution₂, nn_vpt_solution₂, nn_st_solution₂ = produce_trajectory(ics_val₂)</code></pre><p><img src="../rigid_body_evaluation_light.png" alt="Evaluation of the three different networks for an interval (0, 120)."/> <img src="../rigid_body_evaluation_dark.png" alt="Evaluation of the three different networks for an interval (0, 120)."/></p><p>We can see that the volume-preserving transformer performs much better than the volume-preserving feedforward neural network and the standard transformer. It is especially noteworthy that its curves stick to the sphere at all times, which is not the case for the standard transformer. We also see that the standard transformer seems to perform better for one of the curves shown, but completely fails for the other. Why this is should be further investigated. </p><p>We also compare the times it takes to integrate the system with (i) implicit midpoint, (ii) the volume-preserving transformer and (iii) the standard transformer:</p><pre><code class="language-julia hljs">@time &quot;Implicit Midpoint&quot; solution = integrate(problem, ImplicitMidpoint())
trajectory = Float32.(DataLoader(solution; suppress_info = true).input)
@time &quot;VPT&quot; iterate(nn_vpt, trajectory[:, 1:seq_length]; n_points = Int(floor(t_validation / tstep)) + 1)
@time &quot;ST&quot; iterate(nn_st, trajectory[:, 1:seq_length]; n_points = Int(floor(t_validation / tstep)) + 1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Implicit Midpoint: 0.005996 seconds (15.61 k allocations: 3.157 MiB)
VPT: 0.003584 seconds (113.61 k allocations: 4.509 MiB)
ST: 0.000765 seconds (25.41 k allocations: 1.329 MiB)</code></pre><p>Here we see that standard transformer is the fastest, followed by the volume-preserving transformers. Both neural network integrators are however faster than implicit midpoint (as evaluating them is completely explicit). The ODE we treated here is a very simple one. For <a href="../symplectic_autoencoder/#Symplectic-Autoencoders-and-the-Toda-Lattice">more complicated cases</a> the speed-up we gain by using neural networks can be up to a factor 1000.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>A detailed discussion of the consequences of setting this keyword is presented <a href="../volume_preserving_attention/#Comparing-Different-VolumePreservingAttention-Mechanisms">as a separate example</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../matrix_softmax/">« Matrix Attention</a><a class="docs-footer-nextpage" href="../linear_symplectic_transformer/">Linear Symplectic Transformer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.11.4 on <span class="colophon-date" title="Wednesday 4 June 2025 09:27">Wednesday 4 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
