
using Pkg
#cd("../../../SplineFEEC.jl")
#cd("../../../SplineNN")
Pkg.activate("../../../../SplineFEEC.jl")


using MLUtils: DataLoader,splitobs
using Lux:Chain,Dense,relu
using Optimisers
using Zygote:pullback,gradient
using SplineFEEC:stiffness_matrix,mass_matrix,circ_ones,circ_id
using FileIO:load
using StaticArrays
using SplineFEEC
using Lux
using Random
using Plots    
using Statistics
using Flux:loadmodel!,loadparams!
using GeometricMachineLearning
using ProgressMeter:@showprogress
using Printf
using JLD2
using LinearAlgebra:cond 
# aj_loaded = load(filename,"aj_list");
# a0_loaded = load(filename,"a0_list");
# bj_loaded = load(filename,"bj_list");

k=4
N=10
el=1
interval = 0..1
basis = PeriodicBSpline(interval, k, N)
xx, Cm = col_mat(basis, 100)
global R = 1/N .* circ_ones(N)
global P = circ_id(N) - R

#Δ[end,:] .= 1
#fh[end] = 0
#uh = -(Δ) \ (fh)
# stiffness_matrix(basis')
global Stiff_mat = Matrix(stiffness_matrix(basis'))
global Mass_mat = Matrix(mass_matrix(basis))

# println(cond(Stiff_mat+R))


# filename="k=4_N=10_el=1_num=1000_26052023.jld2" # use the 3rd weak loss,data 
                                                #generated by solving the fem instead of l2 projection

filename="k=4_N=10_el=1_num=1000_20052023.jld2"
# filename = "k=4_N=50_el=1_num=1000_25052023.jld2"
# filename = "k=4_N=100_el=1_num=1000_25052023.jld2"

#label
uh_loaded = load(filename,"uh_list");
uh_loaded = [collect(uh_loaded[i]) for i in 1:1000];
uh_loaded = hcat(uh_loaded...);
#input
fh_loaded = load(filename,"fh_list");
fh_loaded = [collect(fh_loaded[i]) for i in 1:1000];
fh_loaded = hcat(fh_loaded...);

function dataset_load(batchsize=20,train_split=0.8,filename=filename)
    
    #label
    uh_loaded = load(filename,"uh_list");
    uh_loaded = [collect(uh_loaded[i]) for i in 1:1000];
    uh_loaded = hcat(uh_loaded...);
    #input
    fh_loaded = load(filename,"fh_list");
    fh_loaded = [collect(fh_loaded[i]) for i in 1:1000];  
    fh_loaded = hcat(fh_loaded...);

    (x_train,y_train),(x_test,y_test) = splitobs((fh_loaded,uh_loaded),at=train_split) # x_train size:10*(1000*train_split)
    return (
        DataLoader((data = x_train,label = y_train),batchsize=batchsize,shuffle = false),
        DataLoader((data = x_test,label = y_test),batchsize=batchsize,shuffle = false)
    )
end

function create_model(N)
    if N == 10
        model = Chain(Dense(N => 150, relu),Dense(150=> 150, relu),Dense(150 => N))
    elseif N == 50
        model = Chain(Dense(N => 150, relu),Dense(150=> 150, relu),Dense(150=> 150, relu ),
        Dense(150 => N))
    elseif N == 100
        model = Chain(Dense(N => 150, relu),Dense(150=> 150, relu),Dense(150=> 150, relu),
        Dense(150=> 150, relu),Dense(150 => N))
    else
        error("N should be a value from [10,50,100]")
    end
    rng = Random.default_rng()
    Random.seed!(rng, 0)

    ps, st = Lux.setup(rng, model)
    return model,ps,st
end

 
function mean_squared_error(y_pred::Matrix{Float64},y::Matrix{Float64})
    mean(sqrt.(sum(abs2,y_pred-y,dims=1)))
end


function mse_loss(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    return mean_squared_error(y_pred, y), st
end

function equation_weak_error(y_pred::Matrix{Float64},x::Matrix{Float64})
    error = 0
    for j in 1:size(y_pred,2)
        error += sqrt.(sum(abs2,Mass_mat*x[:,j]+Stiff_mat*y_pred[:,j],dims=1))[1]
    end
    error = error./size(y_pred,2)
    return error
end
 

function weak_loss(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    loss = equation_weak_error(y_pred,x)
    return loss, st
end

function equation_weak_error2(y_pred::Matrix{Float64},x::Matrix{Float64})
    error = 0
    for j in 1:size(y_pred,2)
        error += sqrt.(sum(abs2,P*(Mass_mat*x[:,j])+(Stiff_mat+R)*y_pred[:,j],dims=1))[1]
    end
    error = error./size(y_pred,2)
    # print("using weak 2")

    return error
end
 

function weak_loss2(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    loss = equation_weak_error2(y_pred,x)
    return loss, st
end
#####################################################3
function equation_weak_error3(y_pred,x)#::Matrix{Float64}
    error = 0
    for j in 1:size(y_pred,2)
        error += sum(abs.(P*x[:,j]+(Stiff_mat+R)*y_pred[:,j]),dims=1)[1]
    end
    error = error./size(y_pred,2)
    return error
end
 

function weak_loss3(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    @assert equation_weak_error3(y,x) <1e-10 "Residual wrong!"
    loss = equation_weak_error3(y_pred,x)
    # println("truth: ",equation_weak_error3(y,x), "    NN pre: ",loss)
    return loss, st
end

# Training
begin 
    k=4
    N=10
    el=1
    interval = 0..1
    basis = PeriodicBSpline(interval, k, N)
    xx, Cm = col_mat(basis, 100)
    
    weak_error_list=[]
    mse_error_list=[]
    test_weak_error_list=[]
    test_mse_error_list=[]
    mse_savemodel_error = 100

    model, ps, st = create_model(N)
    train_dataloader, test_dataloader = dataset_load()

    train_loader_len = length(train_dataloader)
    test_loader_len = length(test_dataloader)

    n_epochs = 80

    # initial_lr=0.001
    # opt = Optimisers.ADAM(initial_lr)
    # st_opt = Optimisers.setup(opt, ps)

    method = GeometricMachineLearning.AdamOptimizer(0.001,0.9,0.99)
    opt = GeometricMachineLearning.Optimizer(method, model)

    # lr_list = range(start = initial_lr,stop = 0.0005*initial_lr,length=n_epochs)

    # @showprogress 
    for epoch in 1:n_epochs 
        weak_error_per_sample = 0
        mse_error_per_sample = 0

        # o.η = lr_list[epoch]
        # Optimisers.adjust!(st_opt,lr_list[epoch])

        for (x,y) in train_dataloader
            # (l, st), back = pullback(p -> mse_loss(x, y, model, p, st), ps)
            # (l, st), back = pullback(p -> weak_loss(x, y, model, p, st), ps)
            # gs = back((one(l), nothing))[1]            
            # st_opt, ps = Optimisers.update(st_opt, ps, gs)

            # model(x, ps, st)[1]
            # gs = gradient(p -> mse_loss(x, y, model, p, st)[1], ps)[1]
            gs = gradient(p -> weak_loss(x, y, model, p, st)[1], ps)[1]
            # gs = gradient(p -> weak_loss2(x, y, model, p, st)[1], ps)[1]
            # gs = gradient(p -> weak_loss3(x, y, model, p, st)[1], ps)[1]
            GeometricMachineLearning.optimization_step!(opt, model, ps, gs)

            # weak_error_per_sample += weak_loss3(x, y, model, ps, st)[1]/train_loader_len
            weak_error_per_sample += weak_loss(x, y, model, ps, st)[1]/train_loader_len
            mse_error_per_sample += mse_loss(x, y, model, ps, st)[1]/train_loader_len
        end

        test_weak_error_per_sample = 0 
        test_mse_error_per_sample = 0
        for (x,y) in test_dataloader
            # test_weak_error_per_sample += weak_loss3(x, y, model, ps, st)[1]/test_loader_len
            test_weak_error_per_sample += weak_loss(x, y, model, ps, st)[1]/test_loader_len
            test_mse_error_per_sample += mse_loss(x, y, model, ps, st)[1]/test_loader_len
        end

        push!(weak_error_list,weak_error_per_sample)
        push!(mse_error_list,mse_error_per_sample)

        push!(test_weak_error_list,test_weak_error_per_sample)
        push!(test_mse_error_list,test_mse_error_per_sample)
        
        # if mse_error_per_sample < mse_savemodel_error
        #     println("=====Epoch: $epoch SAVE MODEL with mse error : $mse_error_per_sample")
        #     JLD2.jldsave("./k=$k,N=$N,earlystopmodel,weakloss.jld2";ps)
        #     mse_savemodel_error = mse_error_per_sample
        # end

        if epoch % 10 == 0
            println("Epoch: $epoch")
            println("---Train weak error per sample: ",weak_error_per_sample)
            println("---Train mse error per sample: ",mse_error_per_sample)
            println("---Test weak error per sample: ",test_weak_error_per_sample)
            println("---Test mse error per sample: ",test_mse_error_per_sample)
            # println("---Current Learning Rate: ",st_opt.layer_1.weight.rule.eta)
            # println("---Current Learning Rate: ",o.η)

        end

    end
    println("===Finish training with $n_epochs epochs===")
    println("Min weak error per_sample: ",minimum(weak_error_list))
    println("Min mse error per_sample: ",minimum(mse_error_list))
    println("TEST Min weak error per_sample: ",minimum(test_weak_error_list))
    println("TEST Min mse error per_sample: ",minimum(test_mse_error_list))

end

plot(weak_error_list)
plot!(test_weak_error_list)
plot!(xscale=:log10, yscale=:log10, minorgrid=true)
title!("Weak Error")
# savefig("weak3train_N=$N.svg")

plot(mse_error_list)
plot!(test_mse_error_list)
plot!(xscale=:log10, yscale=:log10, minorgrid=true)
title!("Mse Error")
# savefig("mseerror_weak3train.svg")

plot(weak_error_list,label = "weak")
plot!(mse_error_list,label = "mse")
plot!(xscale=:log10, yscale=:log10, minorgrid=true)
title!("Weak Error VS Mse error")


equation_weak_error3(model(fh_loaded[:,1],ps,st)[1],fh_loaded[:,1])

begin
    test_pred_y = model(fh_loaded[:,1], ps, st)[1]
    plot_target_u = Cm * uh_loaded[:,1]
    plot_pred_u = Cm * test_pred_y
    max_error = maximum(abs.(plot_target_u-plot_pred_u))
    resi = abs.(plot_target_u-plot_pred_u)

    loc = (argmax(abs.(plot_target_u-plot_pred_u))-1)*0.01
    plot(xx,plot_target_u,label="Truth" )
    plot!(xx,plot_pred_u,label="NN predict" )
    plot!(xx,resi,label="abs(u-uhat)" )
    vline!([loc],linestyle=:dash)
    title!("NN with weakloss3\n max: $max_error")
end

# savefig("uplot_weak3train_N=$N.svg")

JLD2.jldsave("./k=$k,N=$N,epoch=$n_epochs,weak3,01062023.jld2";ps)

new_model,ldps,ldst = create_model(10)
mse_loaded_model_ps = JLD2.load("k=4,N=10,epoch=8000,weak3,01062023.jld2","ps")
loadparams!(new_model,mse_loaded_model_ps)
equation_weak_error3(new_model(fh_loaded[:,1],mse_loaded_model_ps,ldst)[1],fh_loaded[:,1])

new_model == model
st == ldst
mse_loaded_model_ps == ps


begin
    mse_loaded_model_ps = JLD2.load("k=4,N=10,earlystopmodel,weakloss.jld2","ps")
    mse_new_model,ldps,ldst = create_model(10)
    loadparams!(mse_new_model,mse_loaded_model_ps)

    loaded_result = mse_new_model(fh_loaded[:,1], mse_loaded_model_ps, ldst)[1]
    plot_target_u = Cm * uh_loaded[:,1]
    loaded_plot_pred_u = Cm * loaded_result
    loaded_max_error = maximum(abs.(plot_target_u-loaded_plot_pred_u))
    loaded_resi = abs.(plot_target_u-loaded_plot_pred_u)
    # resi = @sprintf("%.5f", resi[1])

    loaded_loc = (argmax(abs.(plot_target_u-loaded_plot_pred_u))-1)*0.01

    plot(xx,plot_target_u,label="Truth" )
    plot!(xx,loaded_plot_pred_u,label="NN predict" )
    plot!(xx,loaded_resi,label="abs(u-uhat)" )
    vline!([loaded_loc],linestyle=:dash)
    title!("NN with weak loss,early stop \n max: $loaded_max_error")

end