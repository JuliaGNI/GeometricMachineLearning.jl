<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>POD and Autoencoders · GeometricMachineLearning.jl</title><meta name="title" content="POD and Autoencoders · GeometricMachineLearning.jl"/><meta property="og:title" content="POD and Autoencoders · GeometricMachineLearning.jl"/><meta property="twitter:title" content="POD and Autoencoders · GeometricMachineLearning.jl"/><meta name="description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="twitter:description" content="Documentation for GeometricMachineLearning.jl."/><meta property="og:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/reduced_order_modeling/pod_autoencoders/"/><meta property="twitter:url" content="https://juliagni.github.io/GeometricMachineLearning.jl/reduced_order_modeling/pod_autoencoders/"/><link rel="canonical" href="https://juliagni.github.io/GeometricMachineLearning.jl/reduced_order_modeling/pod_autoencoders/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/extra_styles.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="GeometricMachineLearning.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="GeometricMachineLearning.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Manifolds</span><ul><li><a class="tocitem" href="../../manifolds/basic_topology/">Concepts from General Topology</a></li><li><a class="tocitem" href="../../manifolds/metric_and_vector_spaces/">Metric and Vector Spaces</a></li><li><a class="tocitem" href="../../manifolds/inverse_function_theorem/">Foundations of Differential Manifolds</a></li><li><a class="tocitem" href="../../manifolds/manifolds/">General Theory on Manifolds</a></li><li><a class="tocitem" href="../../manifolds/existence_and_uniqueness_theorem/">Differential Equations and the EAU theorem</a></li><li><a class="tocitem" href="../../manifolds/riemannian_manifolds/">Riemannian Manifolds</a></li><li><a class="tocitem" href="../../manifolds/homogeneous_spaces/">Homogeneous Spaces</a></li></ul></li><li><span class="tocitem">Special Arrays and AD</span><ul><li><a class="tocitem" href="../../arrays/skew_symmetric_matrix/">Symmetric and Skew-Symmetric Matrices</a></li><li><a class="tocitem" href="../../arrays/global_tangent_spaces/">Global Tangent Spaces</a></li><li><a class="tocitem" href="../../arrays/tensors/">Tensors</a></li><li><a class="tocitem" href="../../pullbacks/computation_of_pullbacks/">Pullbacks</a></li></ul></li><li><span class="tocitem">Structure-Preservation</span><ul><li><a class="tocitem" href="../../structure_preservation/symplecticity/">Symplecticity</a></li><li><a class="tocitem" href="../../structure_preservation/volume_preservation/">Volume-Preservation</a></li><li><a class="tocitem" href="../../structure_preservation/structure_preserving_neural_networks/">Structure-Preserving Neural Networks</a></li></ul></li><li><span class="tocitem">Optimizer</span><ul><li><a class="tocitem" href="../../optimizers/optimizer_framework/">Optimizers</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/retractions/">Retractions</a></li><li><a class="tocitem" href="../../optimizers/manifold_related/parallel_transport/">Parallel Transport</a></li><li><a class="tocitem" href="../../optimizers/optimizer_methods/">Optimizer Methods</a></li><li><a class="tocitem" href="../../optimizers/bfgs_optimizer/">BFGS Optimizer</a></li></ul></li><li><span class="tocitem">Special Neural Network Layers</span><ul><li><a class="tocitem" href="../../layers/sympnet_gradient/">Sympnet Layers</a></li><li><a class="tocitem" href="../../layers/volume_preserving_feedforward/">Volume-Preserving Layers</a></li><li><a class="tocitem" href="../../layers/attention_layer/">(Volume-Preserving) Attention</a></li><li><a class="tocitem" href="../../layers/multihead_attention_layer/">Multihead Attention</a></li><li><a class="tocitem" href="../../layers/linear_symplectic_attention/">Linear Symplectic Attention</a></li></ul></li><li><span class="tocitem">Reduced Order Modeling</span><ul><li><a class="tocitem" href="../reduced_order_modeling/">General Framework</a></li><li class="is-active"><a class="tocitem" href>POD and Autoencoders</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Autoencoders"><span>Autoencoders</span></a></li><li><a class="tocitem" href="#The-Reduced-Equations-for-the-Autoencoder"><span>The Reduced Equations for the Autoencoder</span></a></li><li><a class="tocitem" href="#Library-Functions"><span>Library Functions</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../losses/">Losses and Errors</a></li><li><a class="tocitem" href="../symplectic_mor/">Symplectic Model Order Reduction</a></li></ul></li><li><a class="tocitem" href="../../port_hamiltonian_systems/">port-Hamiltonian Systems</a></li><li><span class="tocitem">Architectures</span><ul><li><a class="tocitem" href="../../architectures/abstract_neural_networks/">Using Architectures with <code>NeuralNetwork</code></a></li><li><a class="tocitem" href="../../architectures/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../architectures/neural_network_integrators/">Neural Network Integrators</a></li><li><a class="tocitem" href="../../architectures/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../architectures/sympnet/">SympNet</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_feedforward/">Volume-Preserving FeedForward</a></li><li><a class="tocitem" href="../../architectures/transformer/">Standard Transformer</a></li><li><a class="tocitem" href="../../architectures/volume_preserving_transformer/">Volume-Preserving Transformer</a></li><li><a class="tocitem" href="../../architectures/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../architectures/symplectic_transformer/">Symplectic Transformer</a></li></ul></li><li><span class="tocitem">Data Loader</span><ul><li><a class="tocitem" href="../../data_loader/snapshot_matrix/">Snapshot matrix &amp; tensor</a></li><li><a class="tocitem" href="../../data_loader/data_loader/">Routines</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/sympnet_tutorial/">SympNets</a></li><li><a class="tocitem" href="../../tutorials/hamiltonian_neural_network/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../tutorials/symplectic_autoencoder/">Symplectic Autoencoders</a></li><li><a class="tocitem" href="../../tutorials/mnist/mnist_tutorial/">MNIST</a></li><li><a class="tocitem" href="../../tutorials/grassmann_layer/">Grassmann Manifold</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_attention/">Volume-Preserving Attention</a></li><li><a class="tocitem" href="../../tutorials/matrix_softmax/">Matrix Attention</a></li><li><a class="tocitem" href="../../tutorials/volume_preserving_transformer_rigid_body/">Volume-Preserving Transformer for the Rigid Body</a></li><li><a class="tocitem" href="../../tutorials/linear_symplectic_transformer/">Linear Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/symplectic_transformer/">Symplectic Transformer</a></li><li><a class="tocitem" href="../../tutorials/adjusting_the_loss_function/">Adjusting the Loss Function</a></li><li><a class="tocitem" href="../../tutorials/optimizer_comparison/">Comparing Optimizers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li><li><a class="tocitem" href="../../docstring_index/">Index of Docstrings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reduced Order Modeling</a></li><li class="is-active"><a href>POD and Autoencoders</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>POD and Autoencoders</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/main/docs/src/reduced_order_modeling/pod_autoencoders.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Proper-Orthogonal-Decomposition"><a class="docs-heading-anchor" href="#Proper-Orthogonal-Decomposition">Proper Orthogonal Decomposition</a><a id="Proper-Orthogonal-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Proper-Orthogonal-Decomposition" title="Permalink"></a></h1><p>Proper orthogonal decomposition (POD, [<a href="../../references/#chatterjee2000introduction">66</a>]) is perhaps the most widely-used technique for <a href="../reduced_order_modeling/#Basic-Concepts-of-Reduced-Order-Modeling">data-driven reduced order modeling</a>. POD approximates the reduction and the reconstruction through linear maps. Assume that the big discretized space has dimension <span>$N$</span> and we try to model the solution manifold with an <span>$n$</span>-dimensional subspace. POD then models the reduction <span>$\mathcal{P}:\mathbb{R}^N\to\mathbb{R}^n$</span> through a matrix <span>$\in\mathbb{R}^{n\times{}N}$</span> and the reconstruction <span>$\mathcal{R}:\mathbb{R}^n\to\mathbb{R}^N$</span> through a matrix <span>$\in\mathbb{R}^{N\times{}n}.$</span> If we are given a <a href="../../data_loader/snapshot_matrix/#Snapshot-Matrix">snapshot matrix</a> finding <span>$\mathcal{P}$</span> and <span>$\mathcal{R}$</span> amounts to a simple application of <em>singular value decomposition</em> (SVD).</p><div class="admonition is-info" id="Theorem-225524d32937f2c0"><header class="admonition-header">Theorem<a class="admonition-anchor" href="#Theorem-225524d32937f2c0" title="Permalink"></a></header><div class="admonition-body"><p>Given a snapshot matrix <span>$M = [u_1, \ldots, u_\mathtt{nts}] \in\mathbb{R}^{N\times\mathtt{nts}},$</span> where <span>$\mathtt{nts}$</span> is the <em>number of time steps</em>, the ideal linear subspace that can best approximate the data stored in <span>$M$</span> are the first <span>$n$</span> columns of the <span>$V$</span> matrix in an SVD: <span>$M = VDU^T.$</span> The problem of finding this subspace can either be phrased as a maximization problem:</p><p class="math-container">\[    \max_{\psi_1, \ldots, \psi_n\in\mathbb{R}^N} \sum_{i = 1}^n \sum_{j = 1}^{\mathtt{nts}}| \langle u_j, \psi_i \rangle_{\mathbb{R}^N} |^2 \text{ s.t. $\langle \psi_i, \psi_j \rangle = \delta_{ij}$ for $1 \leq i$, $j \leq n$,}\]</p><p>or as a minimization problem:</p><p class="math-container">\[    \min_{\psi_1, \ldots, \psi_n\in\mathbb{R}^N} \sum_{j = 1}^{\mathtt{nts}} | u_j - \sum_{i = 1}^n \psi_i\langle u_j, u_i \rangle |^2\text{ s.t. $\langle \psi_i, \psi_j \rangle = \delta_{ij}$ for $1 \leq i$, $j \leq n$.}\]</p><p>In both these cases we have </p><p class="math-container">\[    [\psi_1, \psi_2, \ldots, \psi_n] = V\mathtt{[1:N, 1:n]},\]</p><p>where <span>$V$</span> is obtained via an SVD of <span>$M$</span>.</p></div></div><p>A proof of the statement above can be found in e.g. [<a href="../../references/#volkwein2013proper">67</a>]. We can obtain the reduced equations via <a href="../reduced_order_modeling/#Obtaining-the-Reduced-System-via-Galerkin-Projection">Galerkin projection</a>:</p><div class="admonition is-info" id="Theorem-77201462ac2eb8df"><header class="admonition-header">Theorem<a class="admonition-anchor" href="#Theorem-77201462ac2eb8df" title="Permalink"></a></header><div class="admonition-body"><p>Consider a full-order model on <span>$\mathbb{R}^N$</span> described by the vector field <span>${\hat{u}}&#39;(t) = X(\hat{u}(t))$</span>. For a POD basis the reduced vector field, obtained via Galerkin projection, is:</p><p class="math-container">\[    u&#39;(t) = V^TX(Vu(t)),\]</p><p>where we used <span>$\{\tilde{\psi}_i = Ve_i\}_{i = 1,\ldots, n}$</span> as test functions. <span>$e_i\in\mathbb{R}^n$</span> is the vector that is zero everywhere except for the <span>$i$</span>-th entry, where it is one.</p></div></div><details class="admonition is-details" id="Proof-99878b48a02a848e"><summary class="admonition-header">Proof<a class="admonition-anchor" href="#Proof-99878b48a02a848e" title="Permalink"></a></summary><div class="admonition-body"><p>If we take as test function <span>$\tilde{\psi}_i = Ve_i$</span>, then we get:</p><p class="math-container">\[    e_i^TV^TX(Vu(t)) \overset{!}{=} e_i^TV^TVu&#39;(t) = e_i^Tu&#39;(t),\]</p><p>and since this must be true for every <span>$i = 1, \ldots, n$</span> we obtain the desired expression for the reduced vector field.</p></div></details><p>In recent years another approach to model <span>$\mathcal{P}$</span> and <span>$\mathcal{R}$</span> has become popular, namely to use neural networks to do so.</p><h1 id="Autoencoders"><a class="docs-heading-anchor" href="#Autoencoders">Autoencoders</a><a id="Autoencoders-1"></a><a class="docs-heading-anchor-permalink" href="#Autoencoders" title="Permalink"></a></h1><p>Autoencoders are a popular tool in machine learning to perform <em>data compression</em> [<a href="../../references/#goodfellow2016deep">43</a>]. The idea is always to find a low-dimensional representation of high-dimensional data. This is also referred to as <em>learning a feature space</em>. This idea straightforwardly lends itself towards an application in reduced order modeling. In this setting we <em>learn</em> two mappings that are modeled with neural networks:</p><div class="admonition is-info" id="Definition-f6486f3a566d6661"><header class="admonition-header">Definition<a class="admonition-anchor" href="#Definition-f6486f3a566d6661" title="Permalink"></a></header><div class="admonition-body"><p>An <strong>autoencoder</strong> is a tuple of two mappings <span>$(\mathcal{P}, \mathcal{R})$</span> called the <strong>reduction</strong> and the <strong>reconstruction</strong>:</p><ol><li>The reduction <span>$\mathcal{P}:\mathbb{R}^N\to\mathbb{R}^n$</span> is modeled with a neural network that maps high-dimensional data to a low-dimensional feature space. This network is also referred to as the <strong>encoder</strong> and we routinely denote it by <span>$\Psi^\mathrm{enc}_{\theta_1}$</span> to stress the parameter-dependence on <span>$\theta_1$</span>.</li><li>The reconstruction <span>$\mathcal{R}:\mathbb{R}^n\to\mathbb{R}^N$</span> is modeled with a neural network that maps inputs from the low-dimensional feature space to the high-dimensional space in which the original data were collected. This network is also referred to as the <strong>decoder</strong> and we routinely denote it by <span>$\Psi^\mathrm{dec}_{\theta_2}$</span> to stress the parameter-dependence on <span>$\theta_2$</span>.</li></ol><p>During training we optimize the autoencoder for minimizing the <em>projection error</em>.</p></div></div><p>Unlike in the POD case we have to resort to using <a href="../../optimizers/optimizer_framework/#Neural-Network-Optimizers">neural network optimizers</a> in order to adapt the neural network to the data at hand as opposed to simply using SVD. The use of autoencoders instead of POD is extremely advantageous in the case when we deal with problems that exhibit a slowly-decaying Kolmogorov <span>$n$</span>-width. During training we minimize the <a href="../losses/#Projection-Error">projection error</a>.</p><div class="admonition is-success" id="Remark-91ef04b3dc31b62e"><header class="admonition-header">Remark<a class="admonition-anchor" href="#Remark-91ef04b3dc31b62e" title="Permalink"></a></header><div class="admonition-body"><p>Note that POD can be seen as a special case of an autoencoder where the encoder and the decoder both consist of only one matrix. If we restrict this matrix to be orthonormal, i.e. optimize on the Stiefel manifold, then the best solution we can obtain is equivalent to applying SVD and finding the POD basis.</p></div></div><h2 id="The-Reduced-Equations-for-the-Autoencoder"><a class="docs-heading-anchor" href="#The-Reduced-Equations-for-the-Autoencoder">The Reduced Equations for the Autoencoder</a><a id="The-Reduced-Equations-for-the-Autoencoder-1"></a><a class="docs-heading-anchor-permalink" href="#The-Reduced-Equations-for-the-Autoencoder" title="Permalink"></a></h2><p>Equivalently to the POD case, we get a reduced vector field when we reduce with the autoencoder:</p><div class="admonition is-info" id="Theorem-8df43e885043e451"><header class="admonition-header">Theorem<a class="admonition-anchor" href="#Theorem-8df43e885043e451" title="Permalink"></a></header><div class="admonition-body"><p>Consider a full-order model on <span>$\mathbb{R}^N$</span> described by the vector field <span>${\hat{u}}&#39;(t) = X(\hat{u}(t))$</span>. If we reduce with an autoencoder <span>$(\Psi^\mathrm{enc}, \Psi^\mathrm{dec})$</span> we obtain a reduced vector field via Galerkin projection:</p><p class="math-container">\[    u&#39;(t) = (\nabla\Psi^\mathrm{dec})^TX(\Psi^\mathrm{dec}(u(t))),\]</p><p>where we used <span>$\{\tilde{\psi}_i = \Psi^\mathrm{dec}(e_i)\}_{i = 1,\ldots, n}$</span> as test functions. <span>$e_i\in\mathbb{R}^n$</span> is the vector that is zero everywhere except for the <span>$i$</span>-th entry, where it is one.</p></div></div><details class="admonition is-details" id="Proof-737f58a5f863249b"><summary class="admonition-header">Proof<a class="admonition-anchor" href="#Proof-737f58a5f863249b" title="Permalink"></a></summary><div class="admonition-body"><p>If we take as test function <span>$\tilde{\psi}_i = (\nabla\Psi^\mathrm{dec})e_i$</span> we get:</p><p class="math-container">\[    e_i^T(\Psi^\mathrm{dec})^+X(\Psi^\mathrm{dec}(u(t))) \overset{!}{=} e_i^T(\Psi^\mathrm{dec})^+(\nabla\Psi^\mathrm{dec})u&#39;(t) = e_i^Tu&#39;(t),\]</p><p>and since this must be true for every <span>$i = 1, \ldots, n$</span> we obtain the desired expression for the reduced vector field.</p></div></details><p>Both POD and standard autoencoders suffer from the problem that they completely neglect the structure of the differential equation and the data they are applied to. This can have grave consequences [<a href="../../references/#peng2016symplectic">68</a>–<a href="../../references/#buchfink2023symplectic">70</a>]. <a href="../symplectic_mor/#Hamiltonian-Model-Order-Reduction">Hamiltonian model order reduction</a> can improve the approximation significantly in these situations.</p><h2 id="Library-Functions"><a class="docs-heading-anchor" href="#Library-Functions">Library Functions</a><a id="Library-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Library-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.AutoEncoder" href="#GeometricMachineLearning.AutoEncoder"><code>GeometricMachineLearning.AutoEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoEncoder &lt;: Architecture</code></pre><p>The abstract <code>AutoEncoder</code> type.</p><p>An autoencoder [<a href="../../references/#goodfellow2016deep">43</a>] is a neural network consisting of an encoder <span>$\Psi^e$</span> and a decoder <span>$\Psi^d$</span>. In the simplest case they are trained on some data set <span>$\mathcal{D}$</span> to reduce the following error: </p><p class="math-container">\[||\Psi^d\circ\Psi^e(\mathcal{D}) - \mathcal{D}||,\]</p><p>which we call the <em>reconstruction error</em>, <em>projection error</em> or <em>autoencoder error</em> (see the docs for <a href="../losses/#GeometricMachineLearning.AutoEncoderLoss"><code>AutoEncoderLoss</code></a>) and <span>$||\cdot||$</span> is some norm.</p><p><strong>Implementation</strong></p><p><code>AutoEncoder</code> is an abstract type. If a custom <code>&lt;:AutoEncoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code>, <code>n_encoder_blocks</code> and <code>n_decoder_blocks</code>. </p><p><code>n_encoder_blocks</code> and <code>n_decoder_blocks</code> indicate how often the dimension is changed in the encoder (respectively the decoder).</p><p>Further the routines <a href="#GeometricMachineLearning.encoder"><code>encoder</code></a> and <a href="#GeometricMachineLearning.decoder"><code>decoder</code></a> should be extended.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Encoder" href="#GeometricMachineLearning.Encoder"><code>GeometricMachineLearning.Encoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Encoder &lt;: Architecture</code></pre><p>This is the abstract <code>Encoder</code> type. </p><p>Most often this should not be called directly, but rather through the <a href="#GeometricMachineLearning.encoder"><code>encoder</code></a> function.</p><p><strong>Implementation</strong></p><p>If a custom <code>&lt;:Encoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_encoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL24-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.Decoder" href="#GeometricMachineLearning.Decoder"><code>GeometricMachineLearning.Decoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Decoder &lt;: Architecture</code></pre><p>This is the abstract <code>Decoder</code> type. </p><p>Most often this should not be called directly, but rather through the <a href="#GeometricMachineLearning.decoder"><code>decoder</code></a> function.</p><p><strong>Implementation</strong></p><p>If a custom <code>&lt;:Decoder</code> architecture is implemented it should have the fields <code>full_dim</code>, <code>reduced_dim</code> and <code>n_decoder_blocks</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL37-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.UnknownEncoder" href="#GeometricMachineLearning.UnknownEncoder"><code>GeometricMachineLearning.UnknownEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UnknownEncoder(full_dim, reduced_dim, n_encoder_blocks)</code></pre><p>Make an instance of <code>UnknownEncoder</code>.</p><p>This should be used if one wants to use an <a href="#GeometricMachineLearning.Encoder"><code>Encoder</code></a> that does not have any specific structure.</p><p><strong>Examples</strong></p><p>We show how to make an encoder from a custom architecture:</p><pre><code class="language-julia hljs">using GeometricMachineLearning
using GeometricMachineLearning: UnknownEncoder, params

model = Chain(Dense(5, 3, tanh; use_bias = false), Dense(3, 2, identity; use_bias = false))
nn = NeuralNetwork(UnknownEncoder(5, 2, 2), model, params(NeuralNetwork(model)), CPU())

typeof(nn) &lt;: NeuralNetwork{&lt;:GeometricMachineLearning.Encoder}

# output

true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL72-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.UnknownDecoder" href="#GeometricMachineLearning.UnknownDecoder"><code>GeometricMachineLearning.UnknownDecoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UnknownDecoder(full_dim, reduced_dim, n_encoder_blocks)</code></pre><p>Make an instance of <code>UnknownDecoder</code>.</p><p>This should be used if one wants to use an <a href="#GeometricMachineLearning.Decoder"><code>Decoder</code></a> that does not have any specific structure.</p><p>An example of using this can be constructed analogously to <a href="#GeometricMachineLearning.UnknownDecoder"><code>UnknownDecoder</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL103-L111">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.encoder" href="#GeometricMachineLearning.encoder"><code>GeometricMachineLearning.encoder</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">encoder(nn::NeuralNetwork{&lt;:AutoEncoder})</code></pre><p>Obtain the <em>encoder</em> from an <a href="#GeometricMachineLearning.AutoEncoder"><code>AutoEncoder</code></a> neural network. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL198-L202">source</a></section><section><div><pre><code class="language-julia hljs">encoder(nn)</code></pre><p>Make a neural network of type <a href="#GeometricMachineLearning.Encoder"><code>Encoder</code></a> out of an arbitrary neural network.</p><p><strong>Implementation</strong></p><p>Internally this allocates a new nerual network of type <a href="#GeometricMachineLearning.UnknownEncoder"><code>UnknownEncoder</code></a> and takes the parameters and the backend from <code>nn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL217-L225">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GeometricMachineLearning.decoder" href="#GeometricMachineLearning.decoder"><code>GeometricMachineLearning.decoder</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">decoder(nn::NeuralNetwork{&lt;:AutoEncoder})</code></pre><p>Obtain the <em>decoder</em> from an <a href="#GeometricMachineLearning.AutoEncoder"><code>AutoEncoder</code></a> neural network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL230-L234">source</a></section><section><div><pre><code class="language-julia hljs">decoder(nn)</code></pre><p>Make a neural network of type <a href="#GeometricMachineLearning.Decoder"><code>Decoder</code></a> out of an arbitrary neural network.</p><p><strong>Implementation</strong></p><p>Internally this allocates a new nerual network of type <a href="#GeometricMachineLearning.UnknownDecoder"><code>UnknownDecoder</code></a> and takes the parameters and the backend from <code>nn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGNI/GeometricMachineLearning.jl/blob/c1f877aded567da7282df9cbfd737fd178d68fa6/src/architectures/autoencoder.jl#LL243-L251">source</a></section></article><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[66]</dt><dd><div>A. Chatterjee. <em>An introduction to the proper orthogonal decomposition</em>. Current science, 808–817 (2000).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../reduced_order_modeling/">« General Framework</a><a class="docs-footer-nextpage" href="../losses/">Losses and Errors »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.11.4 on <span class="colophon-date" title="Thursday 5 June 2025 10:27">Thursday 5 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
